# openapi

<!-- Start SDK Installation -->
## SDK Installation

### NPM

```bash
npm add openapi
```

### Yarn

```bash
yarn add openapi
```
<!-- End SDK Installation -->

<!-- Start SDK Example Usage -->
## SDK Example Usage

```typescript
import { SDK, WithSecurity} from "openapi";
import { VideointelligenceVideosAnnotateRequest, VideointelligenceVideosAnnotateResponse } from "openapi/src/sdk/models/operations";
import { AxiosError } from "axios";


const sdk = new SDK();
    
const req: VideointelligenceVideosAnnotateRequest = {
  security: {
    oauth2: {
      authorization: "Bearer YOUR_ACCESS_TOKEN_HERE",
    }
    oauth2c: {
      authorization: "Bearer YOUR_ACCESS_TOKEN_HERE",
    },
  },
  queryParams: {
    dollarXgafv: "1",
    accessToken: "iusto",
    alt: "json",
    callback: "animi",
    fields: "aperiam",
    key: "odio",
    oauthToken: "repellat",
    prettyPrint: true,
    quotaUser: "doloribus",
    uploadType: "porro",
    uploadProtocol: "sequi",
  },
  request: {
    features: [
      "TEXT_DETECTION",
      "SHOT_CHANGE_DETECTION",
      "LOGO_RECOGNITION",
    ],
    inputContent: "sed",
    inputUri: "qui",
    locationId: "dolores",
    outputUri: "sed",
    videoContext: {
      explicitContentDetectionConfig: {
        model: "quibusdam",
      },
      faceDetectionConfig: {
        includeAttributes: true,
        includeBoundingBoxes: false,
        model: "rerum",
      },
      labelDetectionConfig: {
        frameConfidenceThreshold: 28.200001,
        labelDetectionMode: "SHOT_AND_FRAME_MODE",
        model: "illo",
        stationaryCamera: true,
        videoConfidenceThreshold: 25.200001,
      },
      objectTrackingConfig: {
        model: "maxime",
      },
      personDetectionConfig: {
        includeAttributes: true,
        includeBoundingBoxes: false,
        includePoseLandmarks: false,
      },
      segments: [
        {
          endTimeOffset: "velit",
          startTimeOffset: "quia",
        },
        {
          endTimeOffset: "non",
          startTimeOffset: "ab",
        },
      ],
      shotChangeDetectionConfig: {
        model: "eos",
      },
      speechTranscriptionConfig: {
        audioTracks: [
          3315239506547643892,
          2170068001213528811,
          1582343921395994185,
        ],
        diarizationSpeakerCount: 4542759901218261428,
        enableAutomaticPunctuation: true,
        enableSpeakerDiarization: true,
        enableWordConfidence: true,
        filterProfanity: true,
        languageCode: "accusamus",
        maxAlternatives: 3595861241565795942,
        speechContexts: [
          {
            phrases: [
              "est",
            ],
          },
          {
            phrases: [
              "et",
              "ducimus",
            ],
          },
          {
            phrases: [
              "officiis",
            ],
          },
        ],
      },
      textDetectionConfig: {
        languageHints: [
          "est",
          "voluptas",
          "quis",
        ],
        model: "in",
      },
    },
  },
};

sdk.videos.videointelligenceVideosAnnotate(req).then((res: VideointelligenceVideosAnnotateResponse | AxiosError) => {
   // handle response
});
```
<!-- End SDK Example Usage -->

<!-- Start SDK Available Operations -->
## SDK Available Operations

### videos

* `videointelligenceVideosAnnotate` - Performs asynchronous video annotation. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `AnnotateVideoProgress` (progress). `Operation.response` contains `AnnotateVideoResponse` (results).

<!-- End SDK Available Operations -->

### SDK Generated by [Speakeasy](https://docs.speakeasyapi.dev/docs/using-speakeasy/client-sdks)
