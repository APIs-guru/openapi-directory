# openapi

<!-- Start SDK Installation -->
## SDK Installation

### NPM

```bash
npm add openapi
```

### Yarn

```bash
yarn add openapi
```
<!-- End SDK Installation -->

<!-- Start SDK Example Usage -->
## SDK Example Usage

```typescript
import { SDK, WithSecurity} from "openapi";
import { VideointelligenceVideosAnnotateRequest, VideointelligenceVideosAnnotateResponse } from "openapi/src/sdk/models/operations";
import { AxiosError } from "axios";


const sdk = new SDK();
    
const req: VideointelligenceVideosAnnotateRequest = {
  security: {
    oauth2: {
      authorization: "Bearer YOUR_ACCESS_TOKEN_HERE",
    }
    oauth2c: {
      authorization: "Bearer YOUR_ACCESS_TOKEN_HERE",
    },
  },
  queryParams: {
    dollarXgafv: "2",
    accessToken: "quisquam",
    alt: "json",
    callback: "aut",
    fields: "qui",
    key: "voluptas",
    oauthToken: "rerum",
    prettyPrint: true,
    quotaUser: "quaerat",
    uploadType: "aut",
    uploadProtocol: "minima",
  },
  request: {
    features: [
      "TEXT_DETECTION",
    ],
    inputContent: "debitis",
    inputUri: "voluptatem",
    locationId: "cumque",
    outputUri: "dolor",
    videoContext: {
      explicitContentDetectionConfig: {
        model: "laudantium",
      },
      faceDetectionConfig: {
        includeAttributes: false,
        includeBoundingBoxes: false,
        model: "ab",
      },
      labelDetectionConfig: {
        frameConfidenceThreshold: 63.200001,
        labelDetectionMode: "LABEL_DETECTION_MODE_UNSPECIFIED",
        model: "perferendis",
        stationaryCamera: true,
        videoConfidenceThreshold: 69.099998,
      },
      objectTrackingConfig: {
        model: "est",
      },
      personDetectionConfig: {
        includeAttributes: false,
        includeBoundingBoxes: true,
        includePoseLandmarks: true,
      },
      segments: [
        {
          endTimeOffset: "eum",
          startTimeOffset: "sint",
        },
        {
          endTimeOffset: "et",
          startTimeOffset: "totam",
        },
      ],
      shotChangeDetectionConfig: {
        model: "voluptatum",
      },
      speechTranscriptionConfig: {
        audioTracks: [
          9061832994296693596,
          2724327517837439364,
        ],
        diarizationSpeakerCount: 2602192978294191992,
        enableAutomaticPunctuation: true,
        enableSpeakerDiarization: true,
        enableWordConfidence: true,
        filterProfanity: false,
        languageCode: "doloribus",
        maxAlternatives: 6273747709307585794,
        speechContexts: [
          {
            phrases: [
              "similique",
              "facere",
            ],
          },
          {
            phrases: [
              "sequi",
              "ut",
            ],
          },
          {
            phrases: [
              "dolorum",
              "rerum",
              "officia",
            ],
          },
        ],
      },
      textDetectionConfig: {
        languageHints: [
          "neque",
        ],
        model: "ut",
      },
    },
  },
};

sdk.videos.videointelligenceVideosAnnotate(req).then((res: VideointelligenceVideosAnnotateResponse | AxiosError) => {
   // handle response
});
```
<!-- End SDK Example Usage -->

<!-- Start SDK Available Operations -->
## SDK Available Operations

### videos

* `videointelligenceVideosAnnotate` - Performs asynchronous video annotation. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `AnnotateVideoProgress` (progress). `Operation.response` contains `AnnotateVideoResponse` (results).

<!-- End SDK Available Operations -->

### SDK Generated by [Speakeasy](https://docs.speakeasyapi.dev/docs/using-speakeasy/client-sdks)
