# openapi

<!-- Start SDK Installation -->
## SDK Installation

### NPM

```bash
npm add openapi
```

### Yarn

```bash
yarn add openapi
```
<!-- End SDK Installation -->

<!-- Start SDK Example Usage -->
## SDK Example Usage

```typescript
import { SDK, WithSecurity} from "openapi";
import { VideointelligenceVideosAnnotateRequest, VideointelligenceVideosAnnotateResponse } from "openapi/src/sdk/models/operations";
import { AxiosError } from "axios";


const sdk = new SDK();
    
const req: VideointelligenceVideosAnnotateRequest = {
  security: {
    oauth2: {
      authorization: "Bearer YOUR_ACCESS_TOKEN_HERE",
    }
    oauth2c: {
      authorization: "Bearer YOUR_ACCESS_TOKEN_HERE",
    },
  },
  queryParams: {
    dollarXgafv: "2",
    accessToken: "eos",
    alt: "media",
    callback: "eligendi",
    fields: "cumque",
    key: "autem",
    oauthToken: "et",
    prettyPrint: true,
    quotaUser: "assumenda",
    uploadType: "consectetur",
    uploadProtocol: "aut",
  },
  request: {
    features: [
      "LOGO_RECOGNITION",
      "LABEL_DETECTION",
    ],
    inputContent: "voluptatem",
    inputUri: "tenetur",
    locationId: "nostrum",
    outputUri: "quia",
    videoContext: {
      explicitContentDetectionConfig: {
        model: "dolores",
      },
      faceDetectionConfig: {
        includeAttributes: true,
        includeBoundingBoxes: true,
        model: "unde",
      },
      labelDetectionConfig: {
        frameConfidenceThreshold: 21.100000,
        labelDetectionMode: "SHOT_AND_FRAME_MODE",
        model: "nisi",
        stationaryCamera: true,
        videoConfidenceThreshold: 47.099998,
      },
      objectTrackingConfig: {
        model: "molestiae",
      },
      personDetectionConfig: {
        includeAttributes: false,
        includeBoundingBoxes: false,
        includePoseLandmarks: true,
      },
      segments: [
        {
          endTimeOffset: "quo",
          startTimeOffset: "sapiente",
        },
        {
          endTimeOffset: "quis",
          startTimeOffset: "corporis",
        },
      ],
      shotChangeDetectionConfig: {
        model: "numquam",
      },
      speechTranscriptionConfig: {
        audioTracks: [
          8962893094305007659,
          5704955519581026449,
        ],
        diarizationSpeakerCount: 5830924068923634366,
        enableAutomaticPunctuation: true,
        enableSpeakerDiarization: false,
        enableWordConfidence: true,
        filterProfanity: false,
        languageCode: "sint",
        maxAlternatives: 7175661597140912085,
        speechContexts: [
          {
            phrases: [
              "voluptas",
            ],
          },
        ],
      },
      textDetectionConfig: {
        languageHints: [
          "quam",
          "et",
          "commodi",
        ],
        model: "nisi",
      },
    },
  },
};

sdk.videos.videointelligenceVideosAnnotate(req).then((res: VideointelligenceVideosAnnotateResponse | AxiosError) => {
   // handle response
});
```
<!-- End SDK Example Usage -->

<!-- Start SDK Available Operations -->
## SDK Available Operations

### videos

* `videointelligenceVideosAnnotate` - Performs asynchronous video annotation. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `AnnotateVideoProgress` (progress). `Operation.response` contains `AnnotateVideoResponse` (results).

<!-- End SDK Available Operations -->

### SDK Generated by [Speakeasy](https://docs.speakeasyapi.dev/docs/using-speakeasy/client-sdks)
