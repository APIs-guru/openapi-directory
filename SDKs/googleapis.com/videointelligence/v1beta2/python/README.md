# openapi

<!-- Start SDK Installation -->
## SDK Installation

```bash
pip install openapi
```
<!-- End SDK Installation -->

<!-- Start SDK Example Usage -->
## SDK Example Usage

```python
import sdk
from sdk.models import operations, shared

s = sdk.SDK()
    
req = operations.VideointelligenceVideosAnnotateRequest(
    security=operations.VideointelligenceVideosAnnotateSecurity(
        oauth2=shared.SchemeOauth2(
            authorization="Bearer YOUR_ACCESS_TOKEN_HERE",
        )
        oauth2c=shared.SchemeOauth2c(
            authorization="Bearer YOUR_ACCESS_TOKEN_HERE",
        ),
    ),
    query_params=operations.VideointelligenceVideosAnnotateQueryParams(
        dollar_xgafv="2",
        access_token="eos",
        alt="media",
        callback="eligendi",
        fields="cumque",
        key="autem",
        oauth_token="et",
        pretty_print=True,
        quota_user="assumenda",
        upload_type="consectetur",
        upload_protocol="aut",
    ),
    request=shared.GoogleCloudVideointelligenceV1beta2AnnotateVideoRequest(
        features=[
            "LOGO_RECOGNITION",
            "LABEL_DETECTION",
        ],
        input_content="voluptatem",
        input_uri="tenetur",
        location_id="nostrum",
        output_uri="quia",
        video_context=shared.GoogleCloudVideointelligenceV1beta2VideoContext(
            explicit_content_detection_config=shared.GoogleCloudVideointelligenceV1beta2ExplicitContentDetectionConfig(
                model="dolores",
            ),
            face_detection_config=shared.GoogleCloudVideointelligenceV1beta2FaceDetectionConfig(
                include_attributes=True,
                include_bounding_boxes=True,
                model="unde",
            ),
            label_detection_config=shared.GoogleCloudVideointelligenceV1beta2LabelDetectionConfig(
                frame_confidence_threshold=21.100000,
                label_detection_mode="SHOT_AND_FRAME_MODE",
                model="nisi",
                stationary_camera=True,
                video_confidence_threshold=47.099998,
            ),
            object_tracking_config=shared.GoogleCloudVideointelligenceV1beta2ObjectTrackingConfig(
                model="molestiae",
            ),
            person_detection_config=shared.GoogleCloudVideointelligenceV1beta2PersonDetectionConfig(
                include_attributes=False,
                include_bounding_boxes=False,
                include_pose_landmarks=True,
            ),
            segments=[
                shared.GoogleCloudVideointelligenceV1beta2VideoSegment(
                    end_time_offset="quo",
                    start_time_offset="sapiente",
                ),
                shared.GoogleCloudVideointelligenceV1beta2VideoSegment(
                    end_time_offset="quis",
                    start_time_offset="corporis",
                ),
            ],
            shot_change_detection_config=shared.GoogleCloudVideointelligenceV1beta2ShotChangeDetectionConfig(
                model="numquam",
            ),
            speech_transcription_config=shared.GoogleCloudVideointelligenceV1beta2SpeechTranscriptionConfig(
                audio_tracks=[
                    8962893094305007659,
                    5704955519581026449,
                ],
                diarization_speaker_count=5830924068923634366,
                enable_automatic_punctuation=True,
                enable_speaker_diarization=False,
                enable_word_confidence=True,
                filter_profanity=False,
                language_code="sint",
                max_alternatives=7175661597140912085,
                speech_contexts=[
                    shared.GoogleCloudVideointelligenceV1beta2SpeechContext(
                        phrases=[
                            "voluptas",
                        ],
                    ),
                ],
            ),
            text_detection_config=shared.GoogleCloudVideointelligenceV1beta2TextDetectionConfig(
                language_hints=[
                    "quam",
                    "et",
                    "commodi",
                ],
                model="nisi",
            ),
        ),
    ),
)
    
res = s.videos.videointelligence_videos_annotate(req)

if res.google_longrunning_operation is not None:
    # handle response
```
<!-- End SDK Example Usage -->

<!-- Start SDK Available Operations -->
## SDK Available Operations

### videos

* `videointelligence_videos_annotate` - Performs asynchronous video annotation. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `AnnotateVideoProgress` (progress). `Operation.response` contains `AnnotateVideoResponse` (results).

<!-- End SDK Available Operations -->

### SDK Generated by [Speakeasy](https://docs.speakeasyapi.dev/docs/using-speakeasy/client-sdks)
