# openapi

<!-- Start SDK Installation -->
## SDK Installation

### NPM

```bash
npm add openapi
```

### Yarn

```bash
yarn add openapi
```
<!-- End SDK Installation -->

<!-- Start SDK Example Usage -->
## SDK Example Usage

```typescript
import { SDK, WithSecurity} from "openapi";
import { VideointelligenceVideosAnnotateRequest, VideointelligenceVideosAnnotateResponse } from "openapi/src/sdk/models/operations";
import { AxiosError } from "axios";


const sdk = new SDK();
    
const req: VideointelligenceVideosAnnotateRequest = {
  security: {
    oauth2: {
      authorization: "Bearer YOUR_ACCESS_TOKEN_HERE",
    }
    oauth2c: {
      authorization: "Bearer YOUR_ACCESS_TOKEN_HERE",
    },
  },
  queryParams: {
    dollarXgafv: "1",
    accessToken: "delectus",
    alt: "proto",
    callback: "autem",
    fields: "aperiam",
    key: "similique",
    oauthToken: "molestiae",
    prettyPrint: false,
    quotaUser: "ipsum",
    uploadType: "sit",
    uploadProtocol: "nisi",
  },
  request: {
    features: [
      "LOGO_RECOGNITION",
      "OBJECT_TRACKING",
      "FACE_DETECTION",
    ],
    inputContent: "labore",
    inputUri: "consequatur",
    locationId: "enim",
    outputUri: "molestias",
    videoContext: {
      explicitContentDetectionConfig: {
        model: "nam",
      },
      faceDetectionConfig: {
        includeAttributes: false,
        includeBoundingBoxes: true,
        model: "qui",
      },
      labelDetectionConfig: {
        frameConfidenceThreshold: 44.200001,
        labelDetectionMode: "LABEL_DETECTION_MODE_UNSPECIFIED",
        model: "deserunt",
        stationaryCamera: true,
        videoConfidenceThreshold: 72.099998,
      },
      objectTrackingConfig: {
        model: "alias",
      },
      personDetectionConfig: {
        includeAttributes: true,
        includeBoundingBoxes: false,
        includePoseLandmarks: false,
      },
      segments: [
        {
          endTimeOffset: "doloribus",
          startTimeOffset: "blanditiis",
        },
        {
          endTimeOffset: "maiores",
          startTimeOffset: "aliquid",
        },
      ],
      shotChangeDetectionConfig: {
        model: "a",
      },
      speechTranscriptionConfig: {
        audioTracks: [
          1532090172114569710,
        ],
        diarizationSpeakerCount: 1203560969764169467,
        enableAutomaticPunctuation: true,
        enableSpeakerDiarization: false,
        enableWordConfidence: true,
        filterProfanity: false,
        languageCode: "delectus",
        maxAlternatives: 5800051945060985895,
        speechContexts: [
          {
            phrases: [
              "sed",
              "veniam",
            ],
          },
          {
            phrases: [
              "voluptas",
            ],
          },
        ],
      },
      textDetectionConfig: {
        languageHints: [
          "sint",
          "autem",
        ],
        model: "vel",
      },
    },
  },
};

sdk.videos.videointelligenceVideosAnnotate(req).then((res: VideointelligenceVideosAnnotateResponse | AxiosError) => {
   // handle response
});
```
<!-- End SDK Example Usage -->

<!-- Start SDK Available Operations -->
## SDK Available Operations

### videos

* `videointelligenceVideosAnnotate` - Performs asynchronous video annotation. Progress and results can be retrieved through the `google.longrunning.Operations` interface. `Operation.metadata` contains `AnnotateVideoProgress` (progress). `Operation.response` contains `AnnotateVideoResponse` (results).

<!-- End SDK Available Operations -->

### SDK Generated by [Speakeasy](https://docs.speakeasyapi.dev/docs/using-speakeasy/client-sdks)
