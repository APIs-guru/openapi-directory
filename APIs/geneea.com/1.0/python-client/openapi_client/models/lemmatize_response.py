# coding: utf-8

"""
    Geneea Natural Language Processing

    <div class=\"api-description\">     <h2>Authentication</h2>     <p>For all calls, supply your API key. <a href=\"https://www.geneea.com/pricing\">Sign up to <em>obtain the key</em></a>.</p>     <p>         Our API supports both <em>unencrypted (HTTP)</em> and <em>encrypted (HTTPS)</em> protocols.         However, for security reasons, we strongly encourage using only the encrypted version.     </p>     <p>The API key should be supplied as either a request parameter <code>user_key</code> or in <code>Authorization</code> header.</p>     <pre><code>Authorization: user_key &lt;YOUR_API_KEY&gt;</code></pre>      <h2>API operations</h2>     <p>         All API operations can perform analysis on supplied raw text or on text extracted from a given URL.         Optionally, one can supply additional information which can make the result more precise. An example         of such information would be the language of text or a particular text extractor for URL resources.     </p>     <p>The supported types of analyses are:</p>     <ul>         <li><strong>lemmatization</strong> &longrightarrow;             Finds out lemmata (basic forms) of all the words in the document.         </li>         <li><strong>correction</strong> &longrightarrow;             Performs correction (diacritization) on all the words in the document.         </li>         <li><strong>topic detection</strong> &longrightarrow;             Determines a topic of the document, e.g. finance or sports.         </li>         <li><strong>sentiment analysis</strong> &longrightarrow;             Determines a sentiment of the document, i.e. how positive or negative the document is.         </li>         <li><strong>named entity recognition</strong> &longrightarrow;             Finds named entities (like person, location, date etc.) mentioned the the document.         </li>     </ul>      <h2>Encoding</h2>     <p>The supplied text is expected to be in UTF-8 encoding, this is especially important for non-english texts.</p>      <h2>Returned values</h2>     <p>The API calls always return objects in serialized JSON format in UTF-8 encoding.</p>     <p>         If any error occurs, the HTTP response code will be in the range <code>4xx</code> (client-side error) or         <code>5xx</code> (server-side error). In this situation, the body of the response will contain information         about the error in JSON format, with <code>exception</code> and <code>message</code> values.     </p>      <h2>URL limitations</h2>     <p>         All the requests are semantically <code>GET</code>. However, for longer texts, you may run into issues         with URL length limit. Therefore, it's possible to always issue a <code>POST</code> request with all         the parameters encoded as a JSON in the request body.     </p>     <p>Example:</p>     <pre><code>         POST /s1/sentiment         Content-Type: application/json          {\"text\":\"There is no harm in being sometimes wrong - especially if one is promptly found out.\"}     </code></pre>     <p>This is equivalent to <code>GET /s1/sentiment?text=There%20is%20no%20harm...</code></p>      <h2>Request limitations</h2>     <p>         The API has other limitations concerning the size of the HTTP requests. The maximum allowed size of any         POST request body is <em>512 KiB</em>. For request with a URL resource, the maximum allowed number of         extracted characters from each such resource is <em>100,000</em>.     </p>      <h2>Terms of Service</h2>     <p>         By using the API, you agree to our         <a href=\"https://www.geneea.com/terms.html\" target=\"_blank\">Terms of Service Agreement</a>.     </p>      <h2>More information</h2>     <p>         <a href=\"https://help.geneea.com/index.html\" target=\"_blank\">         The Interpretor Public Documentation         </a>     </p> </div> 

    The version of the OpenAPI document: 1.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from typing import Optional, Set
from typing_extensions import Self

class LemmatizeResponse(BaseModel):
    """
    Response for the lemmatization
    """ # noqa: E501
    id: Optional[StrictStr] = Field(default=None, description="Unique identifier of the document")
    language: StrictStr = Field(description="The used language of the document")
    lemmatized_text: StrictStr = Field(description="Lemmatized text of the document, individual tokens are separated by a space and sentences are separated by a new-line character", alias="lemmatizedText")
    text: Optional[StrictStr] = Field(default=None, description="The raw text of the document which has been analysed")
    __properties: ClassVar[List[str]] = ["id", "language", "lemmatizedText", "text"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of LemmatizeResponse from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of LemmatizeResponse from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "id": obj.get("id"),
            "language": obj.get("language"),
            "lemmatizedText": obj.get("lemmatizedText"),
            "text": obj.get("text")
        })
        return _obj


