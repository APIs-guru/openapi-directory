# coding: utf-8

"""
    NamSor API v2

    NamSor API v2 : enpoints to process personal names (gender, cultural origin or ethnicity) in all alphabets or languages. By default, enpoints use 1 unit per name (ex. Gender), but Ethnicity classification uses 10 to 20 units per name depending on taxonomy. Use GET methods for small tests, but prefer POST methods for higher throughput (batch processing of up to 100 names at a time). Need something you can't find here? We have many more features coming soon. Let us know, we'll do our best to add it! 

    The version of the OpenAPI document: 2.0.24
    Contact: contact@namsor.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional, Union
from typing_extensions import Annotated
from openapi_client.models.first_last_name_out import FirstLastNameOut
from typing import Optional, Set
from typing_extensions import Self

class PersonalNameParsedOut(BaseModel):
    """
    PersonalNameParsedOut
    """ # noqa: E501
    first_last_name: Optional[FirstLastNameOut] = Field(default=None, alias="firstLastName")
    id: Optional[StrictStr] = None
    name: Optional[StrictStr] = Field(default=None, description="The input name")
    name_parser_type: Optional[StrictStr] = Field(default=None, description="Name parsing is addressed as a classification problem, for example FN1LN1 means a first then last name order.", alias="nameParserType")
    name_parser_type_alt: Optional[StrictStr] = Field(default=None, description="Second best alternative parsing. Name parsing is addressed as a classification problem, for example FN1LN1 means a first then last name order.", alias="nameParserTypeAlt")
    score: Optional[Union[Annotated[float, Field(le=100, strict=True, ge=0)], Annotated[int, Field(le=100, strict=True, ge=0)]]] = Field(default=None, description="Higher score is better, but score is not normalized. Use calibratedProbability if available. ")
    script: Optional[StrictStr] = None
    __properties: ClassVar[List[str]] = ["firstLastName", "id", "name", "nameParserType", "nameParserTypeAlt", "score", "script"]

    @field_validator('name_parser_type')
    def name_parser_type_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['FN1LN1', 'LN1FN1', 'FN1LN2', 'LN2FN1', 'FN1LNx', 'LNxFN1', 'FN2LN1', 'LN1FN2', 'FN2LN2', 'LN2FN2', 'FN2LNx', 'LNxFN2', 'FNxLN1', 'LN1FNx', 'FNxLN2', 'LN2FNx', 'FNxLNx', 'LNxFNx']):
            raise ValueError("must be one of enum values ('FN1LN1', 'LN1FN1', 'FN1LN2', 'LN2FN1', 'FN1LNx', 'LNxFN1', 'FN2LN1', 'LN1FN2', 'FN2LN2', 'LN2FN2', 'FN2LNx', 'LNxFN2', 'FNxLN1', 'LN1FNx', 'FNxLN2', 'LN2FNx', 'FNxLNx', 'LNxFNx')")
        return value

    @field_validator('name_parser_type_alt')
    def name_parser_type_alt_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['FN1LN1', 'LN1FN1', 'FN1LN2', 'LN2FN1', 'FN1LNx', 'LNxFN1', 'FN2LN1', 'LN1FN2', 'FN2LN2', 'LN2FN2', 'FN2LNx', 'LNxFN2', 'FNxLN1', 'LN1FNx', 'FNxLN2', 'LN2FNx', 'FNxLNx', 'LNxFNx']):
            raise ValueError("must be one of enum values ('FN1LN1', 'LN1FN1', 'FN1LN2', 'LN2FN1', 'FN1LNx', 'LNxFN1', 'FN2LN1', 'LN1FN2', 'FN2LN2', 'LN2FN2', 'FN2LNx', 'LNxFN2', 'FNxLN1', 'LN1FNx', 'FNxLN2', 'LN2FNx', 'FNxLNx', 'LNxFNx')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of PersonalNameParsedOut from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of first_last_name
        if self.first_last_name:
            _dict['firstLastName'] = self.first_last_name.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of PersonalNameParsedOut from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "firstLastName": FirstLastNameOut.from_dict(obj["firstLastName"]) if obj.get("firstLastName") is not None else None,
            "id": obj.get("id"),
            "name": obj.get("name"),
            "nameParserType": obj.get("nameParserType"),
            "nameParserTypeAlt": obj.get("nameParserTypeAlt"),
            "score": obj.get("score"),
            "script": obj.get("script")
        })
        return _obj


