# coding: utf-8

"""
    Mux API

    Mux is how developers build online video. This API encompasses both Mux Video and Mux Data functionality to help you build your video-related projects better and faster than ever before.

    The version of the OpenAPI document: v1
    Contact: devex@mux.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictFloat, StrictInt, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional, Union
from openapi_client.models.asset_generated_subtitle_settings import AssetGeneratedSubtitleSettings
from openapi_client.models.input_settings_overlay_settings import InputSettingsOverlaySettings
from typing import Optional, Set
from typing_extensions import Self

class InputSettings(BaseModel):
    """
    An array of objects that each describe an input file to be used to create the asset. As a shortcut, `input` can also be a string URL for a file when only one input file is used. See `input[].url` for requirements.
    """ # noqa: E501
    closed_captions: Optional[StrictBool] = Field(default=None, description="Indicates the track provides Subtitles for the Deaf or Hard-of-hearing (SDH). This optional parameter should be used for tracks with `type` of `text` and `text_type` set to `subtitles`.")
    end_time: Optional[Union[StrictFloat, StrictInt]] = Field(default=None, description="The time offset in seconds from the beginning of the video, indicating the clip's ending marker. The default value is the duration of the video when not included. This parameter is only applicable for creating clips when `input.url` has `mux://assets/{asset_id}` format.")
    generated_subtitles: Optional[List[AssetGeneratedSubtitleSettings]] = Field(default=None, description="Generate subtitle tracks using automatic speech recognition using this configuration. This may only be provided for the first input object (the main input file). For direct uploads, this first input should omit the url parameter, as the main input file is provided via the direct upload. This will create subtitles based on the audio track ingested from that main input file. Note that subtitle generation happens after initial ingest, so the generated tracks will be in the `preparing` state when the asset transitions to `ready`.")
    language_code: Optional[StrictStr] = Field(default=None, description="The language code value must be a valid [BCP 47](https://tools.ietf.org/html/bcp47) specification compliant value. For example, `en` for English or `en-US` for the US version of English. This parameter is required for `text` and `audio` track types.")
    name: Optional[StrictStr] = Field(default=None, description="The name of the track containing a human-readable description. This value must be unique within each group of `text` or `audio` track types. The HLS manifest will associate a subtitle text track with this value. For example, the value should be \"English\" for a subtitle text track with `language_code` set to `en`. This optional parameter should be used only for `text` and `audio` type tracks. This parameter can be optionally provided for the first video input to denote the name of the muxed audio track if present. If this parameter is not included, Mux will auto-populate based on the `input[].language_code` value.")
    overlay_settings: Optional[InputSettingsOverlaySettings] = None
    passthrough: Optional[StrictStr] = Field(default=None, description="This optional parameter should be used tracks with `type` of `text` and `text_type` set to `subtitles`.")
    start_time: Optional[Union[StrictFloat, StrictInt]] = Field(default=None, description="The time offset in seconds from the beginning of the video indicating the clip's starting marker. The default value is 0 when not included. This parameter is only applicable for creating clips when `input.url` has `mux://assets/{asset_id}` format.")
    text_type: Optional[StrictStr] = Field(default=None, description="Type of text track. This parameter only supports subtitles value. For more information on Subtitles / Closed Captions, [see this blog post](https://mux.com/blog/subtitles-captions-webvtt-hls-and-those-magic-flags/). This parameter is required for `text` type tracks.")
    type: Optional[StrictStr] = Field(default=None, description="This parameter is required for `text` type tracks.")
    url: Optional[StrictStr] = Field(default=None, description="The URL of the file that Mux should download and use. * For the main input file, this should be the URL to the muxed file for Mux to download, for example an MP4, MOV, MKV, or TS file. Mux supports most audio/video file formats and codecs, but for fastest processing, you should [use standard inputs wherever possible](https://docs.mux.com/guides/video/minimize-processing-time). * For `audio` tracks, the URL is the location of the audio file for Mux to download, for example an M4A, WAV, or MP3 file. Mux supports most audio file formats and codecs, but for fastest processing, you should [use standard inputs wherever possible](https://docs.mux.com/guides/video/minimize-processing-time). * For `text` tracks, the URL is the location of subtitle/captions file. Mux supports [SubRip Text (SRT)](https://en.wikipedia.org/wiki/SubRip) and [Web Video Text Tracks](https://www.w3.org/TR/webvtt1/) formats for ingesting Subtitles and Closed Captions. * For Watermarking or Overlay, the URL is the location of the watermark image. * When creating clips from existing Mux assets, the URL is defined with `mux://assets/{asset_id}` template where `asset_id` is the Asset Identifier for creating the clip from. The url property may be omitted on the first input object when providing asset settings for LiveStream and Upload objects, in order to configure settings related to the primary (live stream or direct upload) input. ")
    __properties: ClassVar[List[str]] = ["closed_captions", "end_time", "generated_subtitles", "language_code", "name", "overlay_settings", "passthrough", "start_time", "text_type", "type", "url"]

    @field_validator('text_type')
    def text_type_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['subtitles']):
            raise ValueError("must be one of enum values ('subtitles')")
        return value

    @field_validator('type')
    def type_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['video', 'audio', 'text']):
            raise ValueError("must be one of enum values ('video', 'audio', 'text')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of InputSettings from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in generated_subtitles (list)
        _items = []
        if self.generated_subtitles:
            for _item_generated_subtitles in self.generated_subtitles:
                if _item_generated_subtitles:
                    _items.append(_item_generated_subtitles.to_dict())
            _dict['generated_subtitles'] = _items
        # override the default output from pydantic by calling `to_dict()` of overlay_settings
        if self.overlay_settings:
            _dict['overlay_settings'] = self.overlay_settings.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of InputSettings from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "closed_captions": obj.get("closed_captions"),
            "end_time": obj.get("end_time"),
            "generated_subtitles": [AssetGeneratedSubtitleSettings.from_dict(_item) for _item in obj["generated_subtitles"]] if obj.get("generated_subtitles") is not None else None,
            "language_code": obj.get("language_code"),
            "name": obj.get("name"),
            "overlay_settings": InputSettingsOverlaySettings.from_dict(obj["overlay_settings"]) if obj.get("overlay_settings") is not None else None,
            "passthrough": obj.get("passthrough"),
            "start_time": obj.get("start_time"),
            "text_type": obj.get("text_type"),
            "type": obj.get("type"),
            "url": obj.get("url")
        })
        return _obj


