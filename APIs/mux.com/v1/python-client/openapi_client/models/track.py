# coding: utf-8

"""
    Mux API

    Mux is how developers build online video. This API encompasses both Mux Video and Mux Data functionality to help you build your video-related projects better and faster than ever before.

    The version of the OpenAPI document: v1
    Contact: devex@mux.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictFloat, StrictInt, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional, Union
from typing import Optional, Set
from typing_extensions import Self

class Track(BaseModel):
    """
    Track
    """ # noqa: E501
    closed_captions: Optional[StrictBool] = Field(default=None, description="Indicates the track provides Subtitles for the Deaf or Hard-of-hearing (SDH). This parameter is only set tracks where `type` is `text` and `text_type` is `subtitles`.")
    duration: Optional[Union[StrictFloat, StrictInt]] = Field(default=None, description="The duration in seconds of the track media. This parameter is not set for `text` type tracks. This field is optional and may not be set. The top level `duration` field of an asset will always be set.")
    id: Optional[StrictStr] = Field(default=None, description="Unique identifier for the Track")
    language_code: Optional[StrictStr] = Field(default=None, description="The language code value represents [BCP 47](https://tools.ietf.org/html/bcp47) specification compliant value. For example, `en` for English or `en-US` for the US version of English. This parameter is only set for `text` and `audio` track types.")
    max_channel_layout: Optional[StrictStr] = Field(default=None, description="Only set for the `audio` type track.")
    max_channels: Optional[StrictInt] = Field(default=None, description="The maximum number of audio channels the track supports. Only set for the `audio` type track.")
    max_frame_rate: Optional[Union[StrictFloat, StrictInt]] = Field(default=None, description="The maximum frame rate available for the track. Only set for the `video` type track. This field may return `-1` if the frame rate of the input cannot be reliably determined.")
    max_height: Optional[StrictInt] = Field(default=None, description="The maximum height in pixels available for the track. Only set for the `video` type track.")
    max_width: Optional[StrictInt] = Field(default=None, description="The maximum width in pixels available for the track. Only set for the `video` type track.")
    name: Optional[StrictStr] = Field(default=None, description="The name of the track containing a human-readable description. The HLS manifest will associate a subtitle `text` or `audio` track with this value. For example, the value should be \"English\" for a subtitle text track for the `language_code` value of `en-US`. This parameter is only set for `text` and `audio` track types.")
    passthrough: Optional[StrictStr] = Field(default=None, description="Arbitrary user-supplied metadata set for the track either when creating the asset or track. This parameter is only set for `text` type tracks. Max 255 characters.")
    status: Optional[StrictStr] = Field(default=None, description="The status of the track. This parameter is only set for `text` type tracks.")
    text_source: Optional[StrictStr] = Field(default=None, description="The source of the text contained in a Track of type `text`. Valid `text_source` values are listed below. * `uploaded`: Tracks uploaded to Mux as caption or subtitle files using the Create Asset Track API. * `embedded`: Tracks extracted from an embedded stream of CEA-608 closed captions. * `generated_vod`: Tracks generated by automatic speech recognition on an on-demand asset. * `generated_live`: Tracks generated by automatic speech recognition on a live stream configured with `generated_subtitles`. If an Asset has both `generated_live` and `generated_live_final` tracks that are `ready`, then only the `generated_live_final` track will be included during playback. * `generated_live_final`: Tracks generated by automatic speech recognition on a live stream using `generated_subtitles`. The accuracy, timing, and formatting of these subtitles is improved compared to the corresponding `generated_live` tracks. However, `generated_live_final` tracks will not be available in `ready` status until the live stream ends. If an Asset has both `generated_live` and `generated_live_final` tracks that are `ready`, then only the `generated_live_final` track will be included during playback. ")
    text_type: Optional[StrictStr] = Field(default=None, description="This parameter is only set for `text` type tracks.")
    type: Optional[StrictStr] = Field(default=None, description="The type of track")
    __properties: ClassVar[List[str]] = ["closed_captions", "duration", "id", "language_code", "max_channel_layout", "max_channels", "max_frame_rate", "max_height", "max_width", "name", "passthrough", "status", "text_source", "text_type", "type"]

    @field_validator('status')
    def status_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['preparing', 'ready', 'errored', 'deleted']):
            raise ValueError("must be one of enum values ('preparing', 'ready', 'errored', 'deleted')")
        return value

    @field_validator('text_source')
    def text_source_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['uploaded', 'embedded', 'generated_live', 'generated_live_final']):
            raise ValueError("must be one of enum values ('uploaded', 'embedded', 'generated_live', 'generated_live_final')")
        return value

    @field_validator('text_type')
    def text_type_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['subtitles']):
            raise ValueError("must be one of enum values ('subtitles')")
        return value

    @field_validator('type')
    def type_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['video', 'audio', 'text']):
            raise ValueError("must be one of enum values ('video', 'audio', 'text')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of Track from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of Track from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "closed_captions": obj.get("closed_captions"),
            "duration": obj.get("duration"),
            "id": obj.get("id"),
            "language_code": obj.get("language_code"),
            "max_channel_layout": obj.get("max_channel_layout"),
            "max_channels": obj.get("max_channels"),
            "max_frame_rate": obj.get("max_frame_rate"),
            "max_height": obj.get("max_height"),
            "max_width": obj.get("max_width"),
            "name": obj.get("name"),
            "passthrough": obj.get("passthrough"),
            "status": obj.get("status"),
            "text_source": obj.get("text_source"),
            "text_type": obj.get("text_type"),
            "type": obj.get("type")
        })
        return _obj


