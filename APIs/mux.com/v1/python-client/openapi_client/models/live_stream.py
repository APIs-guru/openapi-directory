# coding: utf-8

"""
    Mux API

    Mux is how developers build online video. This API encompasses both Mux Video and Mux Data functionality to help you build your video-related projects better and faster than ever before.

    The version of the OpenAPI document: v1
    Contact: devex@mux.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional, Union
from typing_extensions import Annotated
from openapi_client.models.create_asset_request import CreateAssetRequest
from openapi_client.models.live_stream_embedded_subtitle_settings import LiveStreamEmbeddedSubtitleSettings
from openapi_client.models.live_stream_generated_subtitle_settings import LiveStreamGeneratedSubtitleSettings
from openapi_client.models.live_stream_status import LiveStreamStatus
from openapi_client.models.playback_id import PlaybackID
from openapi_client.models.simulcast_target import SimulcastTarget
from typing import Optional, Set
from typing_extensions import Self

class LiveStream(BaseModel):
    """
    LiveStream
    """ # noqa: E501
    active_asset_id: Optional[StrictStr] = Field(default=None, description="The Asset that is currently being created if there is an active broadcast.")
    audio_only: Optional[StrictBool] = Field(default=None, description="The live stream only processes the audio track if the value is set to true. Mux drops the video track if broadcasted.")
    created_at: Optional[StrictStr] = Field(default=None, description="Time the Live Stream was created, defined as a Unix timestamp (seconds since epoch).")
    embedded_subtitles: Optional[List[LiveStreamEmbeddedSubtitleSettings]] = Field(default=None, description="Describes the embedded closed caption configuration of the incoming live stream.")
    generated_subtitles: Optional[List[LiveStreamGeneratedSubtitleSettings]] = Field(default=None, description="Configure the incoming live stream to include subtitles created with automatic speech recognition. Each Asset created from a live stream with `generated_subtitles` configured will automatically receive two text tracks. The first of these will have a `text_source` value of `generated_live`, and will be available with `ready` status as soon as the stream is live. The second text track will have a `text_source` value of `generated_live_final` and will contain subtitles with improved accuracy, timing, and formatting. However, `generated_live_final` tracks will not be available in `ready` status until the live stream ends. If an Asset has both `generated_live` and `generated_live_final` tracks that are `ready`, then only the `generated_live_final` track will be included during playback.")
    id: Optional[StrictStr] = Field(default=None, description="Unique identifier for the Live Stream. Max 255 characters.")
    latency_mode: Optional[StrictStr] = Field(default=None, description="Latency is the time from when the streamer transmits a frame of video to when you see it in the player. Set this as an alternative to setting low latency or reduced latency flags. The Low Latency value is a beta feature. Read more here: https://mux.com/blog/introducing-low-latency-live-streaming/")
    low_latency: Optional[StrictBool] = Field(default=None, description="This field is deprecated. Please use `latency_mode` instead. Latency is the time from when the streamer transmits a frame of video to when you see it in the player. Setting this option will enable compatibility with the LL-HLS specification for low-latency streaming. This typically has lower latency than Reduced Latency streams, and cannot be combined with Reduced Latency.")
    max_continuous_duration: Optional[Annotated[int, Field(le=43200, strict=True, ge=60)]] = Field(default=43200, description="The time in seconds a live stream may be continuously active before being disconnected. Defaults to 12 hours.")
    new_asset_settings: Optional[CreateAssetRequest] = None
    passthrough: Optional[StrictStr] = Field(default=None, description="Arbitrary user-supplied metadata set for the asset. Max 255 characters.")
    playback_ids: Optional[List[PlaybackID]] = Field(default=None, description="An array of Playback ID objects. Use these to create HLS playback URLs. See [Play your videos](https://docs.mux.com/guides/video/play-your-videos) for more details.")
    recent_asset_ids: Optional[List[StrictStr]] = Field(default=None, description="An array of strings with the most recent Asset IDs that were created from this Live Stream. The most recently generated Asset ID is the last entry in the list.")
    reconnect_slate_url: Optional[StrictStr] = Field(default=None, description="The URL of the image file that Mux should download and use as slate media during interruptions of the live stream media. This file will be downloaded each time a new recorded asset is created from the live stream. If this is not set, the default slate media will be used.")
    reconnect_window: Optional[Union[Annotated[float, Field(le=1800, strict=True, ge=0)], Annotated[int, Field(le=1800, strict=True, ge=0)]]] = Field(default=60, description="When live streaming software disconnects from Mux, either intentionally or due to a drop in the network, the Reconnect Window is the time in seconds that Mux should wait for the streaming software to reconnect before considering the live stream finished and completing the recorded asset. **Max**: 1800s (30 minutes).  If not specified directly, Standard Latency streams have a Reconnect Window of 60 seconds; Reduced and Low Latency streams have a default of 0 seconds, or no Reconnect Window. For that reason, we suggest specifying a value other than zero for Reduced and Low Latency streams.  Reduced and Low Latency streams with a Reconnect Window greater than zero will insert slate media into the recorded asset while waiting for the streaming software to reconnect or when there are brief interruptions in the live stream media. When using a Reconnect Window setting higher than 60 seconds with a Standard Latency stream, we highly recommend enabling slate with the `use_slate_for_standard_latency` option. ")
    reduced_latency: Optional[StrictBool] = Field(default=None, description="This field is deprecated. Please use `latency_mode` instead. Latency is the time from when the streamer transmits a frame of video to when you see it in the player. Set this if you want lower latency for your live stream. See the [Reduce live stream latency guide](https://docs.mux.com/guides/video/reduce-live-stream-latency) to understand the tradeoffs.")
    simulcast_targets: Optional[List[SimulcastTarget]] = Field(default=None, description="Each Simulcast Target contains configuration details to broadcast (or \"restream\") a live stream to a third-party streaming service. [See the Stream live to 3rd party platforms guide](https://docs.mux.com/guides/video/stream-live-to-3rd-party-platforms).")
    status: Optional[LiveStreamStatus] = None
    stream_key: Optional[StrictStr] = Field(default=None, description="Unique key used for streaming to a Mux RTMP endpoint. This should be considered as sensitive as credentials, anyone with this stream key can begin streaming.")
    test: Optional[StrictBool] = Field(default=None, description="True means this live stream is a test live stream. Test live streams can be used to help evaluate the Mux Video APIs for free. There is no limit on the number of test live streams, but they are watermarked with the Mux logo, and limited to 5 minutes. The test live stream is disabled after the stream is active for 5 mins and the recorded asset also deleted after 24 hours.")
    use_slate_for_standard_latency: Optional[StrictBool] = Field(default=False, description="By default, Standard Latency live streams do not have slate media inserted while waiting for live streaming software to reconnect to Mux. Setting this to true enables slate insertion on a Standard Latency stream.")
    __properties: ClassVar[List[str]] = ["active_asset_id", "audio_only", "created_at", "embedded_subtitles", "generated_subtitles", "id", "latency_mode", "low_latency", "max_continuous_duration", "new_asset_settings", "passthrough", "playback_ids", "recent_asset_ids", "reconnect_slate_url", "reconnect_window", "reduced_latency", "simulcast_targets", "status", "stream_key", "test", "use_slate_for_standard_latency"]

    @field_validator('latency_mode')
    def latency_mode_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['low', 'reduced', 'standard']):
            raise ValueError("must be one of enum values ('low', 'reduced', 'standard')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of LiveStream from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in embedded_subtitles (list)
        _items = []
        if self.embedded_subtitles:
            for _item_embedded_subtitles in self.embedded_subtitles:
                if _item_embedded_subtitles:
                    _items.append(_item_embedded_subtitles.to_dict())
            _dict['embedded_subtitles'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in generated_subtitles (list)
        _items = []
        if self.generated_subtitles:
            for _item_generated_subtitles in self.generated_subtitles:
                if _item_generated_subtitles:
                    _items.append(_item_generated_subtitles.to_dict())
            _dict['generated_subtitles'] = _items
        # override the default output from pydantic by calling `to_dict()` of new_asset_settings
        if self.new_asset_settings:
            _dict['new_asset_settings'] = self.new_asset_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in playback_ids (list)
        _items = []
        if self.playback_ids:
            for _item_playback_ids in self.playback_ids:
                if _item_playback_ids:
                    _items.append(_item_playback_ids.to_dict())
            _dict['playback_ids'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in simulcast_targets (list)
        _items = []
        if self.simulcast_targets:
            for _item_simulcast_targets in self.simulcast_targets:
                if _item_simulcast_targets:
                    _items.append(_item_simulcast_targets.to_dict())
            _dict['simulcast_targets'] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of LiveStream from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "active_asset_id": obj.get("active_asset_id"),
            "audio_only": obj.get("audio_only"),
            "created_at": obj.get("created_at"),
            "embedded_subtitles": [LiveStreamEmbeddedSubtitleSettings.from_dict(_item) for _item in obj["embedded_subtitles"]] if obj.get("embedded_subtitles") is not None else None,
            "generated_subtitles": [LiveStreamGeneratedSubtitleSettings.from_dict(_item) for _item in obj["generated_subtitles"]] if obj.get("generated_subtitles") is not None else None,
            "id": obj.get("id"),
            "latency_mode": obj.get("latency_mode"),
            "low_latency": obj.get("low_latency"),
            "max_continuous_duration": obj.get("max_continuous_duration") if obj.get("max_continuous_duration") is not None else 43200,
            "new_asset_settings": CreateAssetRequest.from_dict(obj["new_asset_settings"]) if obj.get("new_asset_settings") is not None else None,
            "passthrough": obj.get("passthrough"),
            "playback_ids": [PlaybackID.from_dict(_item) for _item in obj["playback_ids"]] if obj.get("playback_ids") is not None else None,
            "recent_asset_ids": obj.get("recent_asset_ids"),
            "reconnect_slate_url": obj.get("reconnect_slate_url"),
            "reconnect_window": obj.get("reconnect_window") if obj.get("reconnect_window") is not None else 60,
            "reduced_latency": obj.get("reduced_latency"),
            "simulcast_targets": [SimulcastTarget.from_dict(_item) for _item in obj["simulcast_targets"]] if obj.get("simulcast_targets") is not None else None,
            "status": obj.get("status"),
            "stream_key": obj.get("stream_key"),
            "test": obj.get("test"),
            "use_slate_for_standard_latency": obj.get("use_slate_for_standard_latency") if obj.get("use_slate_for_standard_latency") is not None else False
        })
        return _obj


