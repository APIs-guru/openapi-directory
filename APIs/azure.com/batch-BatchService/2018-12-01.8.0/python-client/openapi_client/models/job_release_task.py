# coding: utf-8

"""
    BatchService

    A client for issuing REST requests to the Azure Batch service.

    The version of the OpenAPI document: 2018-12-01.8.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.environment_setting import EnvironmentSetting
from openapi_client.models.resource_file import ResourceFile
from openapi_client.models.task_container_settings import TaskContainerSettings
from openapi_client.models.user_identity import UserIdentity
from typing import Optional, Set
from typing_extensions import Self

class JobReleaseTask(BaseModel):
    """
    The Job Release task runs when the job ends, because of one of the following: The user calls the Terminate Job API, or the Delete Job API while the job is still active, the job's maximum wall clock time constraint is reached, and the job is still active, or the job's Job Manager task completed, and the job is configured to terminate when the Job Manager completes. The Job Release task runs on each compute node where tasks of the job have run and the Job Preparation task ran and completed. If you reimage a compute node after it has run the Job Preparation task, and the job ends without any further tasks of the job running on that compute node (and hence the Job Preparation task does not re-run), then the Job Release task does not run on that node. If a compute node reboots while the Job Release task is still running, the Job Release task runs again when the compute node starts up. The job is not marked as complete until all Job Release tasks have completed. The Job Release task runs in the background. It does not occupy a scheduling slot; that is, it does not count towards the maxTasksPerNode limit specified on the pool.
    """ # noqa: E501
    command_line: StrictStr = Field(description="The command line does not run under a shell, and therefore cannot take advantage of shell features such as environment variable expansion. If you want to take advantage of such features, you should invoke the shell in the command line, for example using \"cmd /c MyCommand\" in Windows or \"/bin/sh -c MyCommand\" in Linux. If the command line refers to file paths, it should use a relative path (relative to the task working directory), or use the Batch provided environment variable (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).", alias="commandLine")
    container_settings: Optional[TaskContainerSettings] = Field(default=None, alias="containerSettings")
    environment_settings: Optional[List[EnvironmentSetting]] = Field(default=None, alias="environmentSettings")
    id: Optional[StrictStr] = Field(default=None, description="The ID can contain any combination of alphanumeric characters including hyphens and underscores and cannot contain more than 64 characters. If you do not specify this property, the Batch service assigns a default value of 'jobrelease'. No other task in the job can have the same ID as the Job Release task. If you try to submit a task with the same id, the Batch service rejects the request with error code TaskIdSameAsJobReleaseTask; if you are calling the REST API directly, the HTTP status code is 409 (Conflict).")
    max_wall_clock_time: Optional[StrictStr] = Field(default=None, alias="maxWallClockTime")
    resource_files: Optional[List[ResourceFile]] = Field(default=None, description="Files listed under this element are located in the task's working directory.", alias="resourceFiles")
    retention_time: Optional[StrictStr] = Field(default=None, description="The default is 7 days, i.e. the task directory will be retained for 7 days unless the compute node is removed or the job is deleted.", alias="retentionTime")
    user_identity: Optional[UserIdentity] = Field(default=None, alias="userIdentity")
    __properties: ClassVar[List[str]] = ["commandLine", "containerSettings", "environmentSettings", "id", "maxWallClockTime", "resourceFiles", "retentionTime", "userIdentity"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of JobReleaseTask from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of container_settings
        if self.container_settings:
            _dict['containerSettings'] = self.container_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in environment_settings (list)
        _items = []
        if self.environment_settings:
            for _item_environment_settings in self.environment_settings:
                if _item_environment_settings:
                    _items.append(_item_environment_settings.to_dict())
            _dict['environmentSettings'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in resource_files (list)
        _items = []
        if self.resource_files:
            for _item_resource_files in self.resource_files:
                if _item_resource_files:
                    _items.append(_item_resource_files.to_dict())
            _dict['resourceFiles'] = _items
        # override the default output from pydantic by calling `to_dict()` of user_identity
        if self.user_identity:
            _dict['userIdentity'] = self.user_identity.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of JobReleaseTask from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "commandLine": obj.get("commandLine"),
            "containerSettings": TaskContainerSettings.from_dict(obj["containerSettings"]) if obj.get("containerSettings") is not None else None,
            "environmentSettings": [EnvironmentSetting.from_dict(_item) for _item in obj["environmentSettings"]] if obj.get("environmentSettings") is not None else None,
            "id": obj.get("id"),
            "maxWallClockTime": obj.get("maxWallClockTime"),
            "resourceFiles": [ResourceFile.from_dict(_item) for _item in obj["resourceFiles"]] if obj.get("resourceFiles") is not None else None,
            "retentionTime": obj.get("retentionTime"),
            "userIdentity": UserIdentity.from_dict(obj["userIdentity"]) if obj.get("userIdentity") is not None else None
        })
        return _obj


