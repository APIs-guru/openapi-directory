# coding: utf-8

"""
    BatchService

    A client for issuing REST requests to the Azure Batch service.

    The version of the OpenAPI document: 2018-12-01.8.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from datetime import datetime
from pydantic import BaseModel, ConfigDict, Field, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.affinity_information import AffinityInformation
from openapi_client.models.application_package_reference import ApplicationPackageReference
from openapi_client.models.authentication_token_settings import AuthenticationTokenSettings
from openapi_client.models.compute_node_information import ComputeNodeInformation
from openapi_client.models.environment_setting import EnvironmentSetting
from openapi_client.models.exit_conditions import ExitConditions
from openapi_client.models.multi_instance_settings import MultiInstanceSettings
from openapi_client.models.output_file import OutputFile
from openapi_client.models.resource_file import ResourceFile
from openapi_client.models.task_constraints import TaskConstraints
from openapi_client.models.task_container_settings import TaskContainerSettings
from openapi_client.models.task_dependencies import TaskDependencies
from openapi_client.models.task_execution_information import TaskExecutionInformation
from openapi_client.models.task_state import TaskState
from openapi_client.models.task_statistics import TaskStatistics
from openapi_client.models.user_identity import UserIdentity
from typing import Optional, Set
from typing_extensions import Self

class CloudTask(BaseModel):
    """
    Batch will retry tasks when a recovery operation is triggered on a compute node. Examples of recovery operations include (but are not limited to) when an unhealthy compute node is rebooted or a compute node disappeared due to host failure. Retries due to recovery operations are independent of and are not counted against the maxTaskRetryCount. Even if the maxTaskRetryCount is 0, an internal retry due to a recovery operation may occur. Because of this, all tasks should be idempotent. This means tasks need to tolerate being interrupted and restarted without causing any corruption or duplicate data. The best practice for long running tasks is to use some form of checkpointing.
    """ # noqa: E501
    affinity_info: Optional[AffinityInformation] = Field(default=None, alias="affinityInfo")
    application_package_references: Optional[List[ApplicationPackageReference]] = Field(default=None, description="Application packages are downloaded and deployed to a shared directory, not the task working directory. Therefore, if a referenced package is already on the compute node, and is up to date, then it is not re-downloaded; the existing copy on the compute node is used. If a referenced application package cannot be installed, for example because the package has been deleted or because download failed, the task fails.", alias="applicationPackageReferences")
    authentication_token_settings: Optional[AuthenticationTokenSettings] = Field(default=None, alias="authenticationTokenSettings")
    command_line: Optional[StrictStr] = Field(default=None, description="For multi-instance tasks, the command line is executed as the primary task, after the primary task and all subtasks have finished executing the coordination command line. The command line does not run under a shell, and therefore cannot take advantage of shell features such as environment variable expansion. If you want to take advantage of such features, you should invoke the shell in the command line, for example using \"cmd /c MyCommand\" in Windows or \"/bin/sh -c MyCommand\" in Linux. If the command line refers to file paths, it should use a relative path (relative to the task working directory), or use the Batch provided environment variable (https://docs.microsoft.com/en-us/azure/batch/batch-compute-node-environment-variables).", alias="commandLine")
    constraints: Optional[TaskConstraints] = None
    container_settings: Optional[TaskContainerSettings] = Field(default=None, alias="containerSettings")
    creation_time: Optional[datetime] = Field(default=None, alias="creationTime")
    depends_on: Optional[TaskDependencies] = Field(default=None, alias="dependsOn")
    display_name: Optional[StrictStr] = Field(default=None, description="The display name need not be unique and can contain any Unicode characters up to a maximum length of 1024.", alias="displayName")
    e_tag: Optional[StrictStr] = Field(default=None, description="This is an opaque string. You can use it to detect whether the task has changed between requests. In particular, you can be pass the ETag when updating a task to specify that your changes should take effect only if nobody else has modified the task in the meantime.", alias="eTag")
    environment_settings: Optional[List[EnvironmentSetting]] = Field(default=None, alias="environmentSettings")
    execution_info: Optional[TaskExecutionInformation] = Field(default=None, alias="executionInfo")
    exit_conditions: Optional[ExitConditions] = Field(default=None, alias="exitConditions")
    id: Optional[StrictStr] = Field(default=None, description="The ID can contain any combination of alphanumeric characters including hyphens and underscores, and cannot contain more than 64 characters.")
    last_modified: Optional[datetime] = Field(default=None, alias="lastModified")
    multi_instance_settings: Optional[MultiInstanceSettings] = Field(default=None, alias="multiInstanceSettings")
    node_info: Optional[ComputeNodeInformation] = Field(default=None, alias="nodeInfo")
    output_files: Optional[List[OutputFile]] = Field(default=None, description="For multi-instance tasks, the files will only be uploaded from the compute node on which the primary task is executed.", alias="outputFiles")
    previous_state: Optional[TaskState] = Field(default=None, alias="previousState")
    previous_state_transition_time: Optional[datetime] = Field(default=None, description="This property is not set if the task is in its initial Active state.", alias="previousStateTransitionTime")
    resource_files: Optional[List[ResourceFile]] = Field(default=None, description="For multi-instance tasks, the resource files will only be downloaded to the compute node on which the primary task is executed. There is a maximum size for the list of resource files.  When the max size is exceeded, the request will fail and the response error code will be RequestEntityTooLarge. If this occurs, the collection of ResourceFiles must be reduced in size. This can be achieved using .zip files, Application Packages, or Docker Containers.", alias="resourceFiles")
    state: Optional[TaskState] = None
    state_transition_time: Optional[datetime] = Field(default=None, alias="stateTransitionTime")
    stats: Optional[TaskStatistics] = None
    url: Optional[StrictStr] = None
    user_identity: Optional[UserIdentity] = Field(default=None, alias="userIdentity")
    __properties: ClassVar[List[str]] = ["affinityInfo", "applicationPackageReferences", "authenticationTokenSettings", "commandLine", "constraints", "containerSettings", "creationTime", "dependsOn", "displayName", "eTag", "environmentSettings", "executionInfo", "exitConditions", "id", "lastModified", "multiInstanceSettings", "nodeInfo", "outputFiles", "previousState", "previousStateTransitionTime", "resourceFiles", "state", "stateTransitionTime", "stats", "url", "userIdentity"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of CloudTask from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of affinity_info
        if self.affinity_info:
            _dict['affinityInfo'] = self.affinity_info.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in application_package_references (list)
        _items = []
        if self.application_package_references:
            for _item_application_package_references in self.application_package_references:
                if _item_application_package_references:
                    _items.append(_item_application_package_references.to_dict())
            _dict['applicationPackageReferences'] = _items
        # override the default output from pydantic by calling `to_dict()` of authentication_token_settings
        if self.authentication_token_settings:
            _dict['authenticationTokenSettings'] = self.authentication_token_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of constraints
        if self.constraints:
            _dict['constraints'] = self.constraints.to_dict()
        # override the default output from pydantic by calling `to_dict()` of container_settings
        if self.container_settings:
            _dict['containerSettings'] = self.container_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of depends_on
        if self.depends_on:
            _dict['dependsOn'] = self.depends_on.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in environment_settings (list)
        _items = []
        if self.environment_settings:
            for _item_environment_settings in self.environment_settings:
                if _item_environment_settings:
                    _items.append(_item_environment_settings.to_dict())
            _dict['environmentSettings'] = _items
        # override the default output from pydantic by calling `to_dict()` of execution_info
        if self.execution_info:
            _dict['executionInfo'] = self.execution_info.to_dict()
        # override the default output from pydantic by calling `to_dict()` of exit_conditions
        if self.exit_conditions:
            _dict['exitConditions'] = self.exit_conditions.to_dict()
        # override the default output from pydantic by calling `to_dict()` of multi_instance_settings
        if self.multi_instance_settings:
            _dict['multiInstanceSettings'] = self.multi_instance_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of node_info
        if self.node_info:
            _dict['nodeInfo'] = self.node_info.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in output_files (list)
        _items = []
        if self.output_files:
            for _item_output_files in self.output_files:
                if _item_output_files:
                    _items.append(_item_output_files.to_dict())
            _dict['outputFiles'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in resource_files (list)
        _items = []
        if self.resource_files:
            for _item_resource_files in self.resource_files:
                if _item_resource_files:
                    _items.append(_item_resource_files.to_dict())
            _dict['resourceFiles'] = _items
        # override the default output from pydantic by calling `to_dict()` of stats
        if self.stats:
            _dict['stats'] = self.stats.to_dict()
        # override the default output from pydantic by calling `to_dict()` of user_identity
        if self.user_identity:
            _dict['userIdentity'] = self.user_identity.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of CloudTask from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "affinityInfo": AffinityInformation.from_dict(obj["affinityInfo"]) if obj.get("affinityInfo") is not None else None,
            "applicationPackageReferences": [ApplicationPackageReference.from_dict(_item) for _item in obj["applicationPackageReferences"]] if obj.get("applicationPackageReferences") is not None else None,
            "authenticationTokenSettings": AuthenticationTokenSettings.from_dict(obj["authenticationTokenSettings"]) if obj.get("authenticationTokenSettings") is not None else None,
            "commandLine": obj.get("commandLine"),
            "constraints": TaskConstraints.from_dict(obj["constraints"]) if obj.get("constraints") is not None else None,
            "containerSettings": TaskContainerSettings.from_dict(obj["containerSettings"]) if obj.get("containerSettings") is not None else None,
            "creationTime": obj.get("creationTime"),
            "dependsOn": TaskDependencies.from_dict(obj["dependsOn"]) if obj.get("dependsOn") is not None else None,
            "displayName": obj.get("displayName"),
            "eTag": obj.get("eTag"),
            "environmentSettings": [EnvironmentSetting.from_dict(_item) for _item in obj["environmentSettings"]] if obj.get("environmentSettings") is not None else None,
            "executionInfo": TaskExecutionInformation.from_dict(obj["executionInfo"]) if obj.get("executionInfo") is not None else None,
            "exitConditions": ExitConditions.from_dict(obj["exitConditions"]) if obj.get("exitConditions") is not None else None,
            "id": obj.get("id"),
            "lastModified": obj.get("lastModified"),
            "multiInstanceSettings": MultiInstanceSettings.from_dict(obj["multiInstanceSettings"]) if obj.get("multiInstanceSettings") is not None else None,
            "nodeInfo": ComputeNodeInformation.from_dict(obj["nodeInfo"]) if obj.get("nodeInfo") is not None else None,
            "outputFiles": [OutputFile.from_dict(_item) for _item in obj["outputFiles"]] if obj.get("outputFiles") is not None else None,
            "previousState": obj.get("previousState"),
            "previousStateTransitionTime": obj.get("previousStateTransitionTime"),
            "resourceFiles": [ResourceFile.from_dict(_item) for _item in obj["resourceFiles"]] if obj.get("resourceFiles") is not None else None,
            "state": obj.get("state"),
            "stateTransitionTime": obj.get("stateTransitionTime"),
            "stats": TaskStatistics.from_dict(obj["stats"]) if obj.get("stats") is not None else None,
            "url": obj.get("url"),
            "userIdentity": UserIdentity.from_dict(obj["userIdentity"]) if obj.get("userIdentity") is not None else None
        })
        return _obj


