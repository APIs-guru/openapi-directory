# coding: utf-8

"""
    StreamAnalyticsManagementClient

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)

    The version of the OpenAPI document: 2016-03-01
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from typing import Optional, Set
from typing_extensions import Self

class AzureDataLakeStoreOutputDataSourceProperties(BaseModel):
    """
    The properties that are associated with an Azure Data Lake Store.
    """ # noqa: E501
    account_name: Optional[StrictStr] = Field(default=None, description="The name of the Azure Data Lake Store account. Required on PUT (CreateOrReplace) requests.", alias="accountName")
    date_format: Optional[StrictStr] = Field(default=None, description="The date format. Wherever {date} appears in filePathPrefix, the value of this property is used as the date format instead.", alias="dateFormat")
    file_path_prefix: Optional[StrictStr] = Field(default=None, description="The location of the file to which the output should be written to. Required on PUT (CreateOrReplace) requests.", alias="filePathPrefix")
    tenant_id: Optional[StrictStr] = Field(default=None, description="The tenant id of the user used to obtain the refresh token. Required on PUT (CreateOrReplace) requests.", alias="tenantId")
    time_format: Optional[StrictStr] = Field(default=None, description="The time format. Wherever {time} appears in filePathPrefix, the value of this property is used as the time format instead.", alias="timeFormat")
    refresh_token: Optional[StrictStr] = Field(default=None, description="A refresh token that can be used to obtain a valid access token that can then be used to authenticate with the data source. A valid refresh token is currently only obtainable via the Azure Portal. It is recommended to put a dummy string value here when creating the data source and then going to the Azure Portal to authenticate the data source which will update this property with a valid refresh token. Required on PUT (CreateOrReplace) requests.", alias="refreshToken")
    token_user_display_name: Optional[StrictStr] = Field(default=None, description="The user display name of the user that was used to obtain the refresh token. Use this property to help remember which user was used to obtain the refresh token.", alias="tokenUserDisplayName")
    token_user_principal_name: Optional[StrictStr] = Field(default=None, description="The user principal name (UPN) of the user that was used to obtain the refresh token. Use this property to help remember which user was used to obtain the refresh token.", alias="tokenUserPrincipalName")
    __properties: ClassVar[List[str]] = ["refreshToken", "tokenUserDisplayName", "tokenUserPrincipalName"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of AzureDataLakeStoreOutputDataSourceProperties from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of AzureDataLakeStoreOutputDataSourceProperties from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "refreshToken": obj.get("refreshToken"),
            "tokenUserDisplayName": obj.get("tokenUserDisplayName"),
            "tokenUserPrincipalName": obj.get("tokenUserPrincipalName")
        })
        return _obj


