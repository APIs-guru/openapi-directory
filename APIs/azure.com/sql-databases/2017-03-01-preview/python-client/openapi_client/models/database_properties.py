# coding: utf-8

"""
    SqlManagementClient

    The Azure SQL Database management API provides a RESTful set of web APIs that interact with Azure SQL Database services to manage your databases. The API enables users to create, retrieve, update, and delete databases, servers, and other entities.

    The version of the OpenAPI document: 2017-03-01-preview
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from datetime import datetime
from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictInt, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from typing import Optional, Set
from typing_extensions import Self

class DatabaseProperties(BaseModel):
    """
    The database's properties.
    """ # noqa: E501
    catalog_collation: Optional[StrictStr] = Field(default=None, description="Collation of the metadata catalog.", alias="catalogCollation")
    collation: Optional[StrictStr] = Field(default=None, description="The collation of the database.")
    create_mode: Optional[StrictStr] = Field(default=None, description="Specifies the mode of database creation.    Default: regular database creation.    Copy: creates a database as a copy of an existing database. sourceDatabaseId must be specified as the resource ID of the source database.    Secondary: creates a database as a secondary replica of an existing database. sourceDatabaseId must be specified as the resource ID of the existing primary database.    PointInTimeRestore: Creates a database by restoring a point in time backup of an existing database. sourceDatabaseId must be specified as the resource ID of the existing database, and restorePointInTime must be specified.    Recovery: Creates a database by restoring a geo-replicated backup. sourceDatabaseId must be specified as the recoverable database resource ID to restore.    Restore: Creates a database by restoring a backup of a deleted database. sourceDatabaseId must be specified. If sourceDatabaseId is the database's original resource ID, then sourceDatabaseDeletionDate must be specified. Otherwise sourceDatabaseId must be the restorable dropped database resource ID and sourceDatabaseDeletionDate is ignored. restorePointInTime may also be specified to restore from an earlier point in time.    RestoreLongTermRetentionBackup: Creates a database by restoring from a long term retention vault. recoveryServicesRecoveryPointResourceId must be specified as the recovery point resource ID.    Copy, Secondary, and RestoreLongTermRetentionBackup are not supported for DataWarehouse edition.", alias="createMode")
    creation_date: Optional[datetime] = Field(default=None, description="The creation date of the database (ISO8601 format).", alias="creationDate")
    current_service_objective_name: Optional[StrictStr] = Field(default=None, description="The current service level objective name of the database.", alias="currentServiceObjectiveName")
    database_id: Optional[StrictStr] = Field(default=None, description="The ID of the database.", alias="databaseId")
    default_secondary_location: Optional[StrictStr] = Field(default=None, description="The default secondary region for this database.", alias="defaultSecondaryLocation")
    elastic_pool_id: Optional[StrictStr] = Field(default=None, description="The resource identifier of the elastic pool containing this database.", alias="elasticPoolId")
    failover_group_id: Optional[StrictStr] = Field(default=None, description="Failover Group resource identifier that this database belongs to.", alias="failoverGroupId")
    long_term_retention_backup_resource_id: Optional[StrictStr] = Field(default=None, description="The resource identifier of the long term retention backup associated with create operation of this database.", alias="longTermRetentionBackupResourceId")
    max_size_bytes: Optional[StrictInt] = Field(default=None, description="The max size of the database expressed in bytes.", alias="maxSizeBytes")
    recoverable_database_id: Optional[StrictStr] = Field(default=None, description="The resource identifier of the recoverable database associated with create operation of this database.", alias="recoverableDatabaseId")
    recovery_services_recovery_point_id: Optional[StrictStr] = Field(default=None, description="The resource identifier of the recovery point associated with create operation of this database.", alias="recoveryServicesRecoveryPointId")
    restorable_dropped_database_id: Optional[StrictStr] = Field(default=None, description="The resource identifier of the restorable dropped database associated with create operation of this database.", alias="restorableDroppedDatabaseId")
    restore_point_in_time: Optional[datetime] = Field(default=None, description="Specifies the point in time (ISO8601 format) of the source database that will be restored to create the new database.", alias="restorePointInTime")
    sample_name: Optional[StrictStr] = Field(default=None, description="The name of the sample schema to apply when creating this database.", alias="sampleName")
    source_database_deletion_date: Optional[datetime] = Field(default=None, description="Specifies the time that the database was deleted.", alias="sourceDatabaseDeletionDate")
    source_database_id: Optional[StrictStr] = Field(default=None, description="The resource identifier of the source database associated with create operation of this database.", alias="sourceDatabaseId")
    status: Optional[StrictStr] = Field(default=None, description="The status of the database.")
    zone_redundant: Optional[StrictBool] = Field(default=None, description="Whether or not this database is zone redundant, which means the replicas of this database will be spread across multiple availability zones.", alias="zoneRedundant")
    __properties: ClassVar[List[str]] = ["catalogCollation", "collation", "createMode", "creationDate", "currentServiceObjectiveName", "databaseId", "defaultSecondaryLocation", "elasticPoolId", "failoverGroupId", "longTermRetentionBackupResourceId", "maxSizeBytes", "recoverableDatabaseId", "recoveryServicesRecoveryPointId", "restorableDroppedDatabaseId", "restorePointInTime", "sampleName", "sourceDatabaseDeletionDate", "sourceDatabaseId", "status", "zoneRedundant"]

    @field_validator('catalog_collation')
    def catalog_collation_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['DATABASE_DEFAULT', 'SQL_Latin1_General_CP1_CI_AS']):
            raise ValueError("must be one of enum values ('DATABASE_DEFAULT', 'SQL_Latin1_General_CP1_CI_AS')")
        return value

    @field_validator('create_mode')
    def create_mode_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['Default', 'Copy', 'Secondary', 'OnlineSecondary', 'PointInTimeRestore', 'Restore', 'Recovery', 'RestoreExternalBackup', 'RestoreExternalBackupSecondary', 'RestoreLongTermRetentionBackup']):
            raise ValueError("must be one of enum values ('Default', 'Copy', 'Secondary', 'OnlineSecondary', 'PointInTimeRestore', 'Restore', 'Recovery', 'RestoreExternalBackup', 'RestoreExternalBackupSecondary', 'RestoreLongTermRetentionBackup')")
        return value

    @field_validator('sample_name')
    def sample_name_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['AdventureWorksLT', 'WideWorldImportersStd', 'WideWorldImportersFull']):
            raise ValueError("must be one of enum values ('AdventureWorksLT', 'WideWorldImportersStd', 'WideWorldImportersFull')")
        return value

    @field_validator('status')
    def status_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['Online', 'Restoring', 'RecoveryPending', 'Recovering', 'Suspect', 'Offline', 'Standby', 'Shutdown', 'EmergencyMode', 'AutoClosed', 'Copying', 'Creating', 'Inaccessible', 'OfflineSecondary', 'Pausing', 'Paused', 'Resuming', 'Scaling']):
            raise ValueError("must be one of enum values ('Online', 'Restoring', 'RecoveryPending', 'Recovering', 'Suspect', 'Offline', 'Standby', 'Shutdown', 'EmergencyMode', 'AutoClosed', 'Copying', 'Creating', 'Inaccessible', 'OfflineSecondary', 'Pausing', 'Paused', 'Resuming', 'Scaling')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of DatabaseProperties from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        """
        excluded_fields: Set[str] = set([
            "creation_date",
            "current_service_objective_name",
            "database_id",
            "default_secondary_location",
            "failover_group_id",
            "status",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of DatabaseProperties from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "catalogCollation": obj.get("catalogCollation"),
            "collation": obj.get("collation"),
            "createMode": obj.get("createMode"),
            "creationDate": obj.get("creationDate"),
            "currentServiceObjectiveName": obj.get("currentServiceObjectiveName"),
            "databaseId": obj.get("databaseId"),
            "defaultSecondaryLocation": obj.get("defaultSecondaryLocation"),
            "elasticPoolId": obj.get("elasticPoolId"),
            "failoverGroupId": obj.get("failoverGroupId"),
            "longTermRetentionBackupResourceId": obj.get("longTermRetentionBackupResourceId"),
            "maxSizeBytes": obj.get("maxSizeBytes"),
            "recoverableDatabaseId": obj.get("recoverableDatabaseId"),
            "recoveryServicesRecoveryPointId": obj.get("recoveryServicesRecoveryPointId"),
            "restorableDroppedDatabaseId": obj.get("restorableDroppedDatabaseId"),
            "restorePointInTime": obj.get("restorePointInTime"),
            "sampleName": obj.get("sampleName"),
            "sourceDatabaseDeletionDate": obj.get("sourceDatabaseDeletionDate"),
            "sourceDatabaseId": obj.get("sourceDatabaseId"),
            "status": obj.get("status"),
            "zoneRedundant": obj.get("zoneRedundant")
        })
        return _obj


