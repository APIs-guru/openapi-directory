# coding: utf-8

"""
    Azure Media Services

    This Swagger was generated by the API Framework.

    The version of the OpenAPI document: 2018-07-01
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from importlib import import_module
from pydantic import BaseModel, ConfigDict, Field, StrictFloat, StrictInt, StrictStr
from typing import Any, ClassVar, Dict, List, Optional, Union
from typing import Optional, Set
from typing_extensions import Self

from typing import TYPE_CHECKING
if TYPE_CHECKING:
    from openapi_client.models.audio_overlay import AudioOverlay
    from openapi_client.models.video_overlay import VideoOverlay

class Overlay(BaseModel):
    """
    Base type for all overlays - image, audio or video.
    """ # noqa: E501
    odata_type: StrictStr = Field(description="The discriminator for derived types.", alias="@odata.type")
    audio_gain_level: Optional[Union[StrictFloat, StrictInt]] = Field(default=None, description="The gain level of audio in the overlay. The value should be in the range [0, 1.0]. The default is 1.0.", alias="audioGainLevel")
    end: Optional[StrictStr] = Field(default=None, description="The position in the input video at which the overlay ends. The value should be in ISO 8601 duration format. For example, PT30S to end the overlay at 30 seconds in to the input video. If not specified the overlay will be applied until the end of the input video if inputLoop is true. Else, if inputLoop is false, then overlay will last as long as the duration of the overlay media.")
    fade_in_duration: Optional[StrictStr] = Field(default=None, description="The duration over which the overlay fades in onto the input video. The value should be in ISO 8601 duration format. If not specified the default behavior is to have no fade in (same as PT0S).", alias="fadeInDuration")
    fade_out_duration: Optional[StrictStr] = Field(default=None, description="The duration over which the overlay fades out of the input video. The value should be in ISO 8601 duration format. If not specified the default behavior is to have no fade out (same as PT0S).", alias="fadeOutDuration")
    input_label: StrictStr = Field(description="The label of the job input which is to be used as an overlay. The Input must specify exactly one file. You can specify an image file in JPG or PNG formats, or an audio file (such as a WAV, MP3, WMA or M4A file), or a video file. See https://aka.ms/mesformats for the complete list of supported audio and video file formats.", alias="inputLabel")
    start: Optional[StrictStr] = Field(default=None, description="The start position, with reference to the input video, at which the overlay starts. The value should be in ISO 8601 format. For example, PT05S to start the overlay at 5 seconds in to the input video. If not specified the overlay starts from the beginning of the input video.")
    __properties: ClassVar[List[str]] = ["@odata.type", "audioGainLevel", "end", "fadeInDuration", "fadeOutDuration", "inputLabel", "start"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    # JSON field name that stores the object type
    __discriminator_property_name: ClassVar[str] = '@odata.type'

    # discriminator mappings
    __discriminator_value_class_map: ClassVar[Dict[str, str]] = {
        'AudioOverlay': 'AudioOverlay','VideoOverlay': 'VideoOverlay'
    }

    @classmethod
    def get_discriminator_value(cls, obj: Dict[str, Any]) -> Optional[str]:
        """Returns the discriminator value (object type) of the data"""
        discriminator_value = obj[cls.__discriminator_property_name]
        if discriminator_value:
            return cls.__discriminator_value_class_map.get(discriminator_value)
        else:
            return None

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Union[AudioOverlay, VideoOverlay]]:
        """Create an instance of Overlay from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Dict[str, Any]) -> Optional[Union[AudioOverlay, VideoOverlay]]:
        """Create an instance of Overlay from a dict"""
        # look up the object type based on discriminator mapping
        object_type = cls.get_discriminator_value(obj)
        if object_type ==  'AudioOverlay':
            return import_module("openapi_client.models.audio_overlay").AudioOverlay.from_dict(obj)
        if object_type ==  'VideoOverlay':
            return import_module("openapi_client.models.video_overlay").VideoOverlay.from_dict(obj)

        raise ValueError("Overlay failed to lookup discriminator value from " +
                            json.dumps(obj) + ". Discriminator property name: " + cls.__discriminator_property_name +
                            ", mapping: " + json.dumps(cls.__discriminator_value_class_map))


