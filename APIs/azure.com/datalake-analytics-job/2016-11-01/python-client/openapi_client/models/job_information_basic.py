# coding: utf-8

"""
    DataLakeAnalyticsJobManagementClient

    Creates an Azure Data Lake Analytics job client.

    The version of the OpenAPI document: 2016-11-01
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from datetime import datetime
from pydantic import BaseModel, ConfigDict, Field, StrictFloat, StrictInt, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional, Union
from openapi_client.models.job_relationship_properties import JobRelationshipProperties
from typing import Optional, Set
from typing_extensions import Self

class JobInformationBasic(BaseModel):
    """
    The common Data Lake Analytics job information properties.
    """ # noqa: E501
    degree_of_parallelism: Optional[StrictInt] = Field(default=1, description="the degree of parallelism used for this job.", alias="degreeOfParallelism")
    degree_of_parallelism_percent: Optional[Union[StrictFloat, StrictInt]] = Field(default=None, description="the degree of parallelism in percentage used for this job.", alias="degreeOfParallelismPercent")
    end_time: Optional[datetime] = Field(default=None, description="the completion time of the job.", alias="endTime")
    hierarchy_queue_node: Optional[StrictStr] = Field(default=None, description="the name of hierarchy queue node this job is assigned to, null if job has not been assigned yet or the account doesn't have hierarchy queue.", alias="hierarchyQueueNode")
    job_id: Optional[StrictStr] = Field(default=None, description="the job's unique identifier (a GUID).", alias="jobId")
    log_file_patterns: Optional[List[StrictStr]] = Field(default=None, description="the list of log file name patterns to find in the logFolder. '*' is the only matching character allowed. Example format: jobExecution*.log or *mylog*.txt", alias="logFilePatterns")
    log_folder: Optional[StrictStr] = Field(default=None, description="the log folder path to use in the following format: adl://<accountName>.azuredatalakestore.net/system/jobservice/jobs/Usql/2016/03/13/17/18/5fe51957-93bc-4de0-8ddc-c5a4753b068b/logs/.", alias="logFolder")
    name: StrictStr = Field(description="the friendly name of the job.")
    priority: Optional[StrictInt] = Field(default=None, description="the priority value for the current job. Lower numbers have a higher priority. By default, a job has a priority of 1000. This must be greater than 0.")
    related: Optional[JobRelationshipProperties] = None
    result: Optional[StrictStr] = Field(default=None, description="the result of job execution or the current result of the running job.")
    start_time: Optional[datetime] = Field(default=None, description="the start time of the job.", alias="startTime")
    state: Optional[StrictStr] = Field(default=None, description="the job state. When the job is in the Ended state, refer to Result and ErrorMessage for details.")
    submit_time: Optional[datetime] = Field(default=None, description="the time the job was submitted to the service.", alias="submitTime")
    submitter: Optional[StrictStr] = Field(default=None, description="the user or account that submitted the job.")
    type: StrictStr = Field(description="the job type of the current job (Hive or USql).")
    __properties: ClassVar[List[str]] = ["degreeOfParallelism", "degreeOfParallelismPercent", "endTime", "hierarchyQueueNode", "jobId", "logFilePatterns", "logFolder", "name", "priority", "related", "result", "startTime", "state", "submitTime", "submitter", "type"]

    @field_validator('result')
    def result_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['None', 'Succeeded', 'Cancelled', 'Failed']):
            raise ValueError("must be one of enum values ('None', 'Succeeded', 'Cancelled', 'Failed')")
        return value

    @field_validator('state')
    def state_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['Accepted', 'Compiling', 'Ended', 'New', 'Queued', 'Running', 'Scheduling', 'Starting', 'Paused', 'WaitingForCapacity']):
            raise ValueError("must be one of enum values ('Accepted', 'Compiling', 'Ended', 'New', 'Queued', 'Running', 'Scheduling', 'Starting', 'Paused', 'WaitingForCapacity')")
        return value

    @field_validator('type')
    def type_validate_enum(cls, value):
        """Validates the enum"""
        if value not in set(['USql', 'Hive']):
            raise ValueError("must be one of enum values ('USql', 'Hive')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of JobInformationBasic from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        """
        excluded_fields: Set[str] = set([
            "degree_of_parallelism",
            "degree_of_parallelism_percent",
            "end_time",
            "hierarchy_queue_node",
            "job_id",
            "log_file_patterns",
            "log_folder",
            "priority",
            "result",
            "start_time",
            "state",
            "submit_time",
            "submitter",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of related
        if self.related:
            _dict['related'] = self.related.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of JobInformationBasic from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "degreeOfParallelism": obj.get("degreeOfParallelism") if obj.get("degreeOfParallelism") is not None else 1,
            "degreeOfParallelismPercent": obj.get("degreeOfParallelismPercent"),
            "endTime": obj.get("endTime"),
            "hierarchyQueueNode": obj.get("hierarchyQueueNode"),
            "jobId": obj.get("jobId"),
            "logFilePatterns": obj.get("logFilePatterns"),
            "logFolder": obj.get("logFolder"),
            "name": obj.get("name"),
            "priority": obj.get("priority"),
            "related": JobRelationshipProperties.from_dict(obj["related"]) if obj.get("related") is not None else None,
            "result": obj.get("result"),
            "startTime": obj.get("startTime"),
            "state": obj.get("state"),
            "submitTime": obj.get("submitTime"),
            "submitter": obj.get("submitter"),
            "type": obj.get("type")
        })
        return _obj


