# coding: utf-8

"""
    BatchManagement

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)

    The version of the OpenAPI document: 2018-12-01
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from datetime import datetime
from pydantic import BaseModel, ConfigDict, Field, StrictInt, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.application_package_reference import ApplicationPackageReference
from openapi_client.models.auto_scale_run import AutoScaleRun
from openapi_client.models.certificate_reference import CertificateReference
from openapi_client.models.deployment_configuration import DeploymentConfiguration
from openapi_client.models.metadata_item import MetadataItem
from openapi_client.models.network_configuration import NetworkConfiguration
from openapi_client.models.resize_operation_status import ResizeOperationStatus
from openapi_client.models.scale_settings import ScaleSettings
from openapi_client.models.start_task import StartTask
from openapi_client.models.task_scheduling_policy import TaskSchedulingPolicy
from openapi_client.models.user_account import UserAccount
from typing import Optional, Set
from typing_extensions import Self

class PoolProperties(BaseModel):
    """
    Pool properties.
    """ # noqa: E501
    allocation_state: Optional[StrictStr] = Field(default=None, alias="allocationState")
    allocation_state_transition_time: Optional[datetime] = Field(default=None, alias="allocationStateTransitionTime")
    application_licenses: Optional[List[StrictStr]] = Field(default=None, description="The list of application licenses must be a subset of available Batch service application licenses. If a license is requested which is not supported, pool creation will fail.", alias="applicationLicenses")
    application_packages: Optional[List[ApplicationPackageReference]] = Field(default=None, description="Changes to application packages affect all new compute nodes joining the pool, but do not affect compute nodes that are already in the pool until they are rebooted or reimaged.", alias="applicationPackages")
    auto_scale_run: Optional[AutoScaleRun] = Field(default=None, alias="autoScaleRun")
    certificates: Optional[List[CertificateReference]] = Field(default=None, description="For Windows compute nodes, the Batch service installs the certificates to the specified certificate store and location. For Linux compute nodes, the certificates are stored in a directory inside the task working directory and an environment variable AZ_BATCH_CERTIFICATES_DIR is supplied to the task to query for this location. For certificates with visibility of 'remoteUser', a 'certs' directory is created in the user's home directory (e.g., /home/{user-name}/certs) and certificates are placed in that directory.")
    creation_time: Optional[datetime] = Field(default=None, alias="creationTime")
    current_dedicated_nodes: Optional[StrictInt] = Field(default=None, alias="currentDedicatedNodes")
    current_low_priority_nodes: Optional[StrictInt] = Field(default=None, alias="currentLowPriorityNodes")
    deployment_configuration: Optional[DeploymentConfiguration] = Field(default=None, alias="deploymentConfiguration")
    display_name: Optional[StrictStr] = Field(default=None, description="The display name need not be unique and can contain any Unicode characters up to a maximum length of 1024.", alias="displayName")
    inter_node_communication: Optional[StrictStr] = Field(default=None, description="This imposes restrictions on which nodes can be assigned to the pool. Enabling this value can reduce the chance of the requested number of nodes to be allocated in the pool. If not specified, this value defaults to 'Disabled'.", alias="interNodeCommunication")
    last_modified: Optional[datetime] = Field(default=None, description="This is the last time at which the pool level data, such as the targetDedicatedNodes or autoScaleSettings, changed. It does not factor in node-level changes such as a compute node changing state.", alias="lastModified")
    max_tasks_per_node: Optional[StrictInt] = Field(default=None, alias="maxTasksPerNode")
    metadata: Optional[List[MetadataItem]] = Field(default=None, description="The Batch service does not assign any meaning to metadata; it is solely for the use of user code.")
    network_configuration: Optional[NetworkConfiguration] = Field(default=None, alias="networkConfiguration")
    provisioning_state: Optional[StrictStr] = Field(default=None, alias="provisioningState")
    provisioning_state_transition_time: Optional[datetime] = Field(default=None, alias="provisioningStateTransitionTime")
    resize_operation_status: Optional[ResizeOperationStatus] = Field(default=None, alias="resizeOperationStatus")
    scale_settings: Optional[ScaleSettings] = Field(default=None, alias="scaleSettings")
    start_task: Optional[StartTask] = Field(default=None, alias="startTask")
    task_scheduling_policy: Optional[TaskSchedulingPolicy] = Field(default=None, alias="taskSchedulingPolicy")
    user_accounts: Optional[List[UserAccount]] = Field(default=None, alias="userAccounts")
    vm_size: Optional[StrictStr] = Field(default=None, description="For information about available sizes of virtual machines for Cloud Services pools (pools created with cloudServiceConfiguration), see Sizes for Cloud Services (https://azure.microsoft.com/documentation/articles/cloud-services-sizes-specs/). Batch supports all Cloud Services VM sizes except ExtraSmall. For information about available VM sizes for pools using images from the Virtual Machines Marketplace (pools created with virtualMachineConfiguration) see Sizes for Virtual Machines (Linux) (https://azure.microsoft.com/documentation/articles/virtual-machines-linux-sizes/) or Sizes for Virtual Machines (Windows) (https://azure.microsoft.com/documentation/articles/virtual-machines-windows-sizes/). Batch supports all Azure VM sizes except STANDARD_A0 and those with premium storage (STANDARD_GS, STANDARD_DS, and STANDARD_DSV2 series).", alias="vmSize")
    __properties: ClassVar[List[str]] = ["allocationState", "allocationStateTransitionTime", "applicationLicenses", "applicationPackages", "autoScaleRun", "certificates", "creationTime", "currentDedicatedNodes", "currentLowPriorityNodes", "deploymentConfiguration", "displayName", "interNodeCommunication", "lastModified", "maxTasksPerNode", "metadata", "networkConfiguration", "provisioningState", "provisioningStateTransitionTime", "resizeOperationStatus", "scaleSettings", "startTask", "taskSchedulingPolicy", "userAccounts", "vmSize"]

    @field_validator('allocation_state')
    def allocation_state_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['Steady', 'Resizing', 'Stopping']):
            raise ValueError("must be one of enum values ('Steady', 'Resizing', 'Stopping')")
        return value

    @field_validator('inter_node_communication')
    def inter_node_communication_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['Enabled', 'Disabled']):
            raise ValueError("must be one of enum values ('Enabled', 'Disabled')")
        return value

    @field_validator('provisioning_state')
    def provisioning_state_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['Succeeded', 'Deleting']):
            raise ValueError("must be one of enum values ('Succeeded', 'Deleting')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of PoolProperties from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        """
        excluded_fields: Set[str] = set([
            "allocation_state",
            "allocation_state_transition_time",
            "creation_time",
            "current_dedicated_nodes",
            "current_low_priority_nodes",
            "last_modified",
            "provisioning_state",
            "provisioning_state_transition_time",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in application_packages (list)
        _items = []
        if self.application_packages:
            for _item_application_packages in self.application_packages:
                if _item_application_packages:
                    _items.append(_item_application_packages.to_dict())
            _dict['applicationPackages'] = _items
        # override the default output from pydantic by calling `to_dict()` of auto_scale_run
        if self.auto_scale_run:
            _dict['autoScaleRun'] = self.auto_scale_run.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in certificates (list)
        _items = []
        if self.certificates:
            for _item_certificates in self.certificates:
                if _item_certificates:
                    _items.append(_item_certificates.to_dict())
            _dict['certificates'] = _items
        # override the default output from pydantic by calling `to_dict()` of deployment_configuration
        if self.deployment_configuration:
            _dict['deploymentConfiguration'] = self.deployment_configuration.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in metadata (list)
        _items = []
        if self.metadata:
            for _item_metadata in self.metadata:
                if _item_metadata:
                    _items.append(_item_metadata.to_dict())
            _dict['metadata'] = _items
        # override the default output from pydantic by calling `to_dict()` of network_configuration
        if self.network_configuration:
            _dict['networkConfiguration'] = self.network_configuration.to_dict()
        # override the default output from pydantic by calling `to_dict()` of resize_operation_status
        if self.resize_operation_status:
            _dict['resizeOperationStatus'] = self.resize_operation_status.to_dict()
        # override the default output from pydantic by calling `to_dict()` of scale_settings
        if self.scale_settings:
            _dict['scaleSettings'] = self.scale_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of start_task
        if self.start_task:
            _dict['startTask'] = self.start_task.to_dict()
        # override the default output from pydantic by calling `to_dict()` of task_scheduling_policy
        if self.task_scheduling_policy:
            _dict['taskSchedulingPolicy'] = self.task_scheduling_policy.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in user_accounts (list)
        _items = []
        if self.user_accounts:
            for _item_user_accounts in self.user_accounts:
                if _item_user_accounts:
                    _items.append(_item_user_accounts.to_dict())
            _dict['userAccounts'] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of PoolProperties from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "allocationState": obj.get("allocationState"),
            "allocationStateTransitionTime": obj.get("allocationStateTransitionTime"),
            "applicationLicenses": obj.get("applicationLicenses"),
            "applicationPackages": [ApplicationPackageReference.from_dict(_item) for _item in obj["applicationPackages"]] if obj.get("applicationPackages") is not None else None,
            "autoScaleRun": AutoScaleRun.from_dict(obj["autoScaleRun"]) if obj.get("autoScaleRun") is not None else None,
            "certificates": [CertificateReference.from_dict(_item) for _item in obj["certificates"]] if obj.get("certificates") is not None else None,
            "creationTime": obj.get("creationTime"),
            "currentDedicatedNodes": obj.get("currentDedicatedNodes"),
            "currentLowPriorityNodes": obj.get("currentLowPriorityNodes"),
            "deploymentConfiguration": DeploymentConfiguration.from_dict(obj["deploymentConfiguration"]) if obj.get("deploymentConfiguration") is not None else None,
            "displayName": obj.get("displayName"),
            "interNodeCommunication": obj.get("interNodeCommunication"),
            "lastModified": obj.get("lastModified"),
            "maxTasksPerNode": obj.get("maxTasksPerNode"),
            "metadata": [MetadataItem.from_dict(_item) for _item in obj["metadata"]] if obj.get("metadata") is not None else None,
            "networkConfiguration": NetworkConfiguration.from_dict(obj["networkConfiguration"]) if obj.get("networkConfiguration") is not None else None,
            "provisioningState": obj.get("provisioningState"),
            "provisioningStateTransitionTime": obj.get("provisioningStateTransitionTime"),
            "resizeOperationStatus": ResizeOperationStatus.from_dict(obj["resizeOperationStatus"]) if obj.get("resizeOperationStatus") is not None else None,
            "scaleSettings": ScaleSettings.from_dict(obj["scaleSettings"]) if obj.get("scaleSettings") is not None else None,
            "startTask": StartTask.from_dict(obj["startTask"]) if obj.get("startTask") is not None else None,
            "taskSchedulingPolicy": TaskSchedulingPolicy.from_dict(obj["taskSchedulingPolicy"]) if obj.get("taskSchedulingPolicy") is not None else None,
            "userAccounts": [UserAccount.from_dict(_item) for _item in obj["userAccounts"]] if obj.get("userAccounts") is not None else None,
            "vmSize": obj.get("vmSize")
        })
        return _obj


