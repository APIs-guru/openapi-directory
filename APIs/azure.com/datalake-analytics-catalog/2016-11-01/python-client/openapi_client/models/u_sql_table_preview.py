# coding: utf-8

"""
    DataLakeAnalyticsCatalogManagementClient

    Creates an Azure Data Lake Analytics catalog client.

    The version of the OpenAPI document: 2016-11-01
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictInt, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.u_sql_table_column import USqlTableColumn
from typing import Optional, Set
from typing_extensions import Self

class USqlTablePreview(BaseModel):
    """
    A Data Lake Analytics catalog table or partition preview rows item.
    """ # noqa: E501
    rows: Optional[List[List[StrictStr]]] = Field(default=None, description="the rows of the table or partition preview, where each row is an array of string representations the row's values. Note: Byte arrays will appear as base-64 encoded values, SqlMap and SqlArray objects will appear as escaped JSON objects, and DateTime objects will appear as ISO formatted UTC date-times.")
    var_schema: Optional[List[USqlTableColumn]] = Field(default=None, description="the schema of the table or partition.", alias="schema")
    total_column_count: Optional[StrictInt] = Field(default=None, description="the total number of columns in the table or partition.", alias="totalColumnCount")
    total_row_count: Optional[StrictInt] = Field(default=None, description="the total number of rows in the table or partition.", alias="totalRowCount")
    truncated: Optional[StrictBool] = Field(default=None, description="true if the amount of data in the response is less than expected due to the preview operation's size limitations. This can occur if the requested rows or row counts are too large.")
    __properties: ClassVar[List[str]] = ["rows", "schema", "totalColumnCount", "totalRowCount", "truncated"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of USqlTablePreview from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in var_schema (list)
        _items = []
        if self.var_schema:
            for _item_var_schema in self.var_schema:
                if _item_var_schema:
                    _items.append(_item_var_schema.to_dict())
            _dict['schema'] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of USqlTablePreview from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "rows": obj.get("rows"),
            "schema": [USqlTableColumn.from_dict(_item) for _item in obj["schema"]] if obj.get("schema") is not None else None,
            "totalColumnCount": obj.get("totalColumnCount"),
            "totalRowCount": obj.get("totalRowCount"),
            "truncated": obj.get("truncated")
        })
        return _obj


