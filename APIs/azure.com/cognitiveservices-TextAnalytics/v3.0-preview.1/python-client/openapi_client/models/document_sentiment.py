# coding: utf-8

"""
    Text Analytics Client

    The Text Analytics API is a suite of text analytics web services built with best-in-class Microsoft machine learning algorithms. The API can be used to analyze unstructured text for tasks such as sentiment analysis, key phrase extraction and language detection. No training data is needed to use this API; just bring your text data. This API uses advanced natural language processing techniques to deliver best in class predictions. Further documentation can be found in https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/overview

    The version of the OpenAPI document: v3.0-preview.1
    Contact: mlapi@microsoft.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.document_statistics import DocumentStatistics
from openapi_client.models.sentence_sentiment import SentenceSentiment
from openapi_client.models.sentiment_confidence_score_per_label import SentimentConfidenceScorePerLabel
from typing import Optional, Set
from typing_extensions import Self

class DocumentSentiment(BaseModel):
    """
    DocumentSentiment
    """ # noqa: E501
    document_scores: SentimentConfidenceScorePerLabel = Field(alias="documentScores")
    id: StrictStr = Field(description="Unique, non-empty document identifier.")
    sentences: List[SentenceSentiment] = Field(description="Sentence level sentiment analysis.")
    sentiment: StrictStr = Field(description="Predicted sentiment for document (Negative, Neutral, Positive, or Mixed).")
    statistics: Optional[DocumentStatistics] = None
    __properties: ClassVar[List[str]] = ["documentScores", "id", "sentences", "sentiment", "statistics"]

    @field_validator('sentiment')
    def sentiment_validate_enum(cls, value):
        """Validates the enum"""
        if value not in set(['positive', 'neutral', 'negative', 'mixed']):
            raise ValueError("must be one of enum values ('positive', 'neutral', 'negative', 'mixed')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of DocumentSentiment from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of document_scores
        if self.document_scores:
            _dict['documentScores'] = self.document_scores.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in sentences (list)
        _items = []
        if self.sentences:
            for _item_sentences in self.sentences:
                if _item_sentences:
                    _items.append(_item_sentences.to_dict())
            _dict['sentences'] = _items
        # override the default output from pydantic by calling `to_dict()` of statistics
        if self.statistics:
            _dict['statistics'] = self.statistics.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of DocumentSentiment from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "documentScores": SentimentConfidenceScorePerLabel.from_dict(obj["documentScores"]) if obj.get("documentScores") is not None else None,
            "id": obj.get("id"),
            "sentences": [SentenceSentiment.from_dict(_item) for _item in obj["sentences"]] if obj.get("sentences") is not None else None,
            "sentiment": obj.get("sentiment"),
            "statistics": DocumentStatistics.from_dict(obj["statistics"]) if obj.get("statistics") is not None else None
        })
        return _obj


