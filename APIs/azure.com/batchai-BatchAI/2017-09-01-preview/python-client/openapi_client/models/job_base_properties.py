# coding: utf-8

"""
    BatchAI

    The Azure BatchAI Management API.

    The version of the OpenAPI document: 2017-09-01-preview
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictInt, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.caffe2_settings import Caffe2Settings
from openapi_client.models.caffe_settings import CaffeSettings
from openapi_client.models.chainer_settings import ChainerSettings
from openapi_client.models.cnt_ksettings import CNTKsettings
from openapi_client.models.container_settings import ContainerSettings
from openapi_client.models.custom_toolkit_settings import CustomToolkitSettings
from openapi_client.models.environment_setting import EnvironmentSetting
from openapi_client.models.input_directory import InputDirectory
from openapi_client.models.job_base_properties_constraints import JobBasePropertiesConstraints
from openapi_client.models.job_preparation import JobPreparation
from openapi_client.models.output_directory import OutputDirectory
from openapi_client.models.resource_id import ResourceId
from openapi_client.models.tensor_flow_settings import TensorFlowSettings
from typing import Optional, Set
from typing_extensions import Self

class JobBaseProperties(BaseModel):
    """
    The properties of a Batch AI job.
    """ # noqa: E501
    caffe2_settings: Optional[Caffe2Settings] = Field(default=None, alias="caffe2Settings")
    caffe_settings: Optional[CaffeSettings] = Field(default=None, alias="caffeSettings")
    chainer_settings: Optional[ChainerSettings] = Field(default=None, alias="chainerSettings")
    cluster: ResourceId
    cntk_settings: Optional[CNTKsettings] = Field(default=None, alias="cntkSettings")
    constraints: Optional[JobBasePropertiesConstraints] = None
    container_settings: Optional[ContainerSettings] = Field(default=None, alias="containerSettings")
    custom_toolkit_settings: Optional[CustomToolkitSettings] = Field(default=None, alias="customToolkitSettings")
    environment_variables: Optional[List[EnvironmentSetting]] = Field(default=None, description="Batch AI service sets the following environment variables for all jobs: AZ_BATCHAI_INPUT_id, AZ_BATCHAI_OUTPUT_id, AZ_BATCHAI_NUM_GPUS_PER_NODE. For distributed TensorFlow jobs, following additional environment variables are set by the Batch AI Service: AZ_BATCHAI_PS_HOSTS, AZ_BATCHAI_WORKER_HOSTS", alias="environmentVariables")
    experiment_name: Optional[StrictStr] = Field(default=None, description="Describe the experiment information of the job", alias="experimentName")
    input_directories: Optional[List[InputDirectory]] = Field(default=None, alias="inputDirectories")
    job_preparation: Optional[JobPreparation] = Field(default=None, alias="jobPreparation")
    node_count: StrictInt = Field(description="The job will be gang scheduled on that many compute nodes", alias="nodeCount")
    output_directories: Optional[List[OutputDirectory]] = Field(default=None, alias="outputDirectories")
    priority: Optional[StrictInt] = Field(default=0, description="Priority associated with the job. Priority values can range from -1000 to 1000, with -1000 being the lowest priority and 1000 being the highest priority. The default value is 0.")
    std_out_err_path_prefix: StrictStr = Field(description="The path where the Batch AI service will upload stdout and stderror of the job.", alias="stdOutErrPathPrefix")
    tensor_flow_settings: Optional[TensorFlowSettings] = Field(default=None, alias="tensorFlowSettings")
    __properties: ClassVar[List[str]] = ["caffe2Settings", "caffeSettings", "chainerSettings", "cluster", "cntkSettings", "constraints", "containerSettings", "customToolkitSettings", "environmentVariables", "experimentName", "inputDirectories", "jobPreparation", "nodeCount", "outputDirectories", "priority", "stdOutErrPathPrefix", "tensorFlowSettings"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of JobBaseProperties from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of caffe2_settings
        if self.caffe2_settings:
            _dict['caffe2Settings'] = self.caffe2_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of caffe_settings
        if self.caffe_settings:
            _dict['caffeSettings'] = self.caffe_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of chainer_settings
        if self.chainer_settings:
            _dict['chainerSettings'] = self.chainer_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of cluster
        if self.cluster:
            _dict['cluster'] = self.cluster.to_dict()
        # override the default output from pydantic by calling `to_dict()` of cntk_settings
        if self.cntk_settings:
            _dict['cntkSettings'] = self.cntk_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of constraints
        if self.constraints:
            _dict['constraints'] = self.constraints.to_dict()
        # override the default output from pydantic by calling `to_dict()` of container_settings
        if self.container_settings:
            _dict['containerSettings'] = self.container_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of custom_toolkit_settings
        if self.custom_toolkit_settings:
            _dict['customToolkitSettings'] = self.custom_toolkit_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in environment_variables (list)
        _items = []
        if self.environment_variables:
            for _item_environment_variables in self.environment_variables:
                if _item_environment_variables:
                    _items.append(_item_environment_variables.to_dict())
            _dict['environmentVariables'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in input_directories (list)
        _items = []
        if self.input_directories:
            for _item_input_directories in self.input_directories:
                if _item_input_directories:
                    _items.append(_item_input_directories.to_dict())
            _dict['inputDirectories'] = _items
        # override the default output from pydantic by calling `to_dict()` of job_preparation
        if self.job_preparation:
            _dict['jobPreparation'] = self.job_preparation.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in output_directories (list)
        _items = []
        if self.output_directories:
            for _item_output_directories in self.output_directories:
                if _item_output_directories:
                    _items.append(_item_output_directories.to_dict())
            _dict['outputDirectories'] = _items
        # override the default output from pydantic by calling `to_dict()` of tensor_flow_settings
        if self.tensor_flow_settings:
            _dict['tensorFlowSettings'] = self.tensor_flow_settings.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of JobBaseProperties from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "caffe2Settings": Caffe2Settings.from_dict(obj["caffe2Settings"]) if obj.get("caffe2Settings") is not None else None,
            "caffeSettings": CaffeSettings.from_dict(obj["caffeSettings"]) if obj.get("caffeSettings") is not None else None,
            "chainerSettings": ChainerSettings.from_dict(obj["chainerSettings"]) if obj.get("chainerSettings") is not None else None,
            "cluster": ResourceId.from_dict(obj["cluster"]) if obj.get("cluster") is not None else None,
            "cntkSettings": CNTKsettings.from_dict(obj["cntkSettings"]) if obj.get("cntkSettings") is not None else None,
            "constraints": JobBasePropertiesConstraints.from_dict(obj["constraints"]) if obj.get("constraints") is not None else None,
            "containerSettings": ContainerSettings.from_dict(obj["containerSettings"]) if obj.get("containerSettings") is not None else None,
            "customToolkitSettings": CustomToolkitSettings.from_dict(obj["customToolkitSettings"]) if obj.get("customToolkitSettings") is not None else None,
            "environmentVariables": [EnvironmentSetting.from_dict(_item) for _item in obj["environmentVariables"]] if obj.get("environmentVariables") is not None else None,
            "experimentName": obj.get("experimentName"),
            "inputDirectories": [InputDirectory.from_dict(_item) for _item in obj["inputDirectories"]] if obj.get("inputDirectories") is not None else None,
            "jobPreparation": JobPreparation.from_dict(obj["jobPreparation"]) if obj.get("jobPreparation") is not None else None,
            "nodeCount": obj.get("nodeCount"),
            "outputDirectories": [OutputDirectory.from_dict(_item) for _item in obj["outputDirectories"]] if obj.get("outputDirectories") is not None else None,
            "priority": obj.get("priority") if obj.get("priority") is not None else 0,
            "stdOutErrPathPrefix": obj.get("stdOutErrPathPrefix"),
            "tensorFlowSettings": TensorFlowSettings.from_dict(obj["tensorFlowSettings"]) if obj.get("tensorFlowSettings") is not None else None
        })
        return _obj


