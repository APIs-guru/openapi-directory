# coding: utf-8

"""
    BatchAI

    The Azure BatchAI Management API.

    The version of the OpenAPI document: 2017-09-01-preview
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from datetime import datetime
from pydantic import BaseModel, ConfigDict, Field, StrictInt, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.caffe_settings import CaffeSettings
from openapi_client.models.chainer_settings import ChainerSettings
from openapi_client.models.cnt_ksettings import CNTKsettings
from openapi_client.models.container_settings import ContainerSettings
from openapi_client.models.custom_toolkit_settings import CustomToolkitSettings
from openapi_client.models.environment_setting import EnvironmentSetting
from openapi_client.models.input_directory import InputDirectory
from openapi_client.models.job_base_properties_constraints import JobBasePropertiesConstraints
from openapi_client.models.job_preparation import JobPreparation
from openapi_client.models.job_properties_execution_info import JobPropertiesExecutionInfo
from openapi_client.models.output_directory import OutputDirectory
from openapi_client.models.resource_id import ResourceId
from openapi_client.models.tensor_flow_settings import TensorFlowSettings
from openapi_client.models.tool_type import ToolType
from typing import Optional, Set
from typing_extensions import Self

class JobProperties(BaseModel):
    """
    Job specific properties.
    """ # noqa: E501
    caffe_settings: Optional[CaffeSettings] = Field(default=None, alias="caffeSettings")
    chainer_settings: Optional[ChainerSettings] = Field(default=None, alias="chainerSettings")
    cluster: Optional[ResourceId] = None
    cntk_settings: Optional[CNTKsettings] = Field(default=None, alias="cntkSettings")
    constraints: Optional[JobBasePropertiesConstraints] = None
    container_settings: Optional[ContainerSettings] = Field(default=None, alias="containerSettings")
    creation_time: Optional[datetime] = Field(default=None, description="The creation time of the job.", alias="creationTime")
    custom_toolkit_settings: Optional[CustomToolkitSettings] = Field(default=None, alias="customToolkitSettings")
    environment_variables: Optional[List[EnvironmentSetting]] = Field(default=None, description="Batch AI services sets the following environment variables for all jobs: AZ_BATCHAI_INPUT_id, AZ_BATCHAI_OUTPUT_id, AZ_BATCHAI_NUM_GPUS_PER_NODE, For distributed TensorFlow jobs, following additional environment variables are set by the Batch AI Service: AZ_BATCHAI_PS_HOSTS, AZ_BATCHAI_WORKER_HOSTS.", alias="environmentVariables")
    execution_info: Optional[JobPropertiesExecutionInfo] = Field(default=None, alias="executionInfo")
    execution_state: Optional[StrictStr] = Field(default=None, description="The current state of the job. Possible values are: queued - The job is queued and able to run. A job enters this state when it is created, or when it is awaiting a retry after a failed run. running - The job is running on a compute cluster. This includes job-level preparation such as downloading resource files or set up container specified on the job - it does not necessarily mean that the job command line has started executing. terminating - The job is terminated by the user, the terminate operation is in progress. succeeded - The job has completed running successfully and exited with exit code 0. failed - The job has finished unsuccessfully (failed with a non-zero exit code) and has exhausted its retry limit. A job is also marked as failed if an error occurred launching the job.", alias="executionState")
    execution_state_transition_time: Optional[datetime] = Field(default=None, description="The time at which the job entered its current execution state.", alias="executionStateTransitionTime")
    experiment_name: Optional[StrictStr] = Field(default=None, description="Describe the experiment information of the job", alias="experimentName")
    input_directories: Optional[List[InputDirectory]] = Field(default=None, alias="inputDirectories")
    job_preparation: Optional[JobPreparation] = Field(default=None, alias="jobPreparation")
    node_count: Optional[StrictInt] = Field(default=None, description="The job will be gang scheduled on that many compute nodes", alias="nodeCount")
    output_directories: Optional[List[OutputDirectory]] = Field(default=None, alias="outputDirectories")
    priority: Optional[StrictInt] = Field(default=0, description="Priority associated with the job. Priority values can range from -1000 to 1000, with -1000 being the lowest priority and 1000 being the highest priority. The default value is 0.")
    provisioning_state: Optional[StrictStr] = Field(default=None, description="The provisioned state of the Batch AI job", alias="provisioningState")
    provisioning_state_transition_time: Optional[datetime] = Field(default=None, description="The time at which the job entered its current provisioning state.", alias="provisioningStateTransitionTime")
    std_out_err_path_prefix: Optional[StrictStr] = Field(default=None, description="The path where the Batch AI service will upload stdout and stderror of the job.", alias="stdOutErrPathPrefix")
    tensor_flow_settings: Optional[TensorFlowSettings] = Field(default=None, alias="tensorFlowSettings")
    tool_type: Optional[ToolType] = Field(default=None, alias="toolType")
    __properties: ClassVar[List[str]] = ["caffeSettings", "chainerSettings", "cluster", "cntkSettings", "constraints", "containerSettings", "creationTime", "customToolkitSettings", "environmentVariables", "executionInfo", "executionState", "executionStateTransitionTime", "experimentName", "inputDirectories", "jobPreparation", "nodeCount", "outputDirectories", "priority", "provisioningState", "provisioningStateTransitionTime", "stdOutErrPathPrefix", "tensorFlowSettings", "toolType"]

    @field_validator('execution_state')
    def execution_state_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['queued', 'running', 'terminating', 'succeeded', 'failed']):
            raise ValueError("must be one of enum values ('queued', 'running', 'terminating', 'succeeded', 'failed')")
        return value

    @field_validator('provisioning_state')
    def provisioning_state_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['creating', 'deleting', 'succeeded', 'failed']):
            raise ValueError("must be one of enum values ('creating', 'deleting', 'succeeded', 'failed')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of JobProperties from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        """
        excluded_fields: Set[str] = set([
            "creation_time",
            "execution_state_transition_time",
            "provisioning_state",
            "provisioning_state_transition_time",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of caffe_settings
        if self.caffe_settings:
            _dict['caffeSettings'] = self.caffe_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of chainer_settings
        if self.chainer_settings:
            _dict['chainerSettings'] = self.chainer_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of cluster
        if self.cluster:
            _dict['cluster'] = self.cluster.to_dict()
        # override the default output from pydantic by calling `to_dict()` of cntk_settings
        if self.cntk_settings:
            _dict['cntkSettings'] = self.cntk_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of constraints
        if self.constraints:
            _dict['constraints'] = self.constraints.to_dict()
        # override the default output from pydantic by calling `to_dict()` of container_settings
        if self.container_settings:
            _dict['containerSettings'] = self.container_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of custom_toolkit_settings
        if self.custom_toolkit_settings:
            _dict['customToolkitSettings'] = self.custom_toolkit_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in environment_variables (list)
        _items = []
        if self.environment_variables:
            for _item_environment_variables in self.environment_variables:
                if _item_environment_variables:
                    _items.append(_item_environment_variables.to_dict())
            _dict['environmentVariables'] = _items
        # override the default output from pydantic by calling `to_dict()` of execution_info
        if self.execution_info:
            _dict['executionInfo'] = self.execution_info.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in input_directories (list)
        _items = []
        if self.input_directories:
            for _item_input_directories in self.input_directories:
                if _item_input_directories:
                    _items.append(_item_input_directories.to_dict())
            _dict['inputDirectories'] = _items
        # override the default output from pydantic by calling `to_dict()` of job_preparation
        if self.job_preparation:
            _dict['jobPreparation'] = self.job_preparation.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in output_directories (list)
        _items = []
        if self.output_directories:
            for _item_output_directories in self.output_directories:
                if _item_output_directories:
                    _items.append(_item_output_directories.to_dict())
            _dict['outputDirectories'] = _items
        # override the default output from pydantic by calling `to_dict()` of tensor_flow_settings
        if self.tensor_flow_settings:
            _dict['tensorFlowSettings'] = self.tensor_flow_settings.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of JobProperties from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "caffeSettings": CaffeSettings.from_dict(obj["caffeSettings"]) if obj.get("caffeSettings") is not None else None,
            "chainerSettings": ChainerSettings.from_dict(obj["chainerSettings"]) if obj.get("chainerSettings") is not None else None,
            "cluster": ResourceId.from_dict(obj["cluster"]) if obj.get("cluster") is not None else None,
            "cntkSettings": CNTKsettings.from_dict(obj["cntkSettings"]) if obj.get("cntkSettings") is not None else None,
            "constraints": JobBasePropertiesConstraints.from_dict(obj["constraints"]) if obj.get("constraints") is not None else None,
            "containerSettings": ContainerSettings.from_dict(obj["containerSettings"]) if obj.get("containerSettings") is not None else None,
            "creationTime": obj.get("creationTime"),
            "customToolkitSettings": CustomToolkitSettings.from_dict(obj["customToolkitSettings"]) if obj.get("customToolkitSettings") is not None else None,
            "environmentVariables": [EnvironmentSetting.from_dict(_item) for _item in obj["environmentVariables"]] if obj.get("environmentVariables") is not None else None,
            "executionInfo": JobPropertiesExecutionInfo.from_dict(obj["executionInfo"]) if obj.get("executionInfo") is not None else None,
            "executionState": obj.get("executionState"),
            "executionStateTransitionTime": obj.get("executionStateTransitionTime"),
            "experimentName": obj.get("experimentName"),
            "inputDirectories": [InputDirectory.from_dict(_item) for _item in obj["inputDirectories"]] if obj.get("inputDirectories") is not None else None,
            "jobPreparation": JobPreparation.from_dict(obj["jobPreparation"]) if obj.get("jobPreparation") is not None else None,
            "nodeCount": obj.get("nodeCount"),
            "outputDirectories": [OutputDirectory.from_dict(_item) for _item in obj["outputDirectories"]] if obj.get("outputDirectories") is not None else None,
            "priority": obj.get("priority") if obj.get("priority") is not None else 0,
            "provisioningState": obj.get("provisioningState"),
            "provisioningStateTransitionTime": obj.get("provisioningStateTransitionTime"),
            "stdOutErrPathPrefix": obj.get("stdOutErrPathPrefix"),
            "tensorFlowSettings": TensorFlowSettings.from_dict(obj["tensorFlowSettings"]) if obj.get("tensorFlowSettings") is not None else None,
            "toolType": obj.get("toolType")
        })
        return _obj


