# coding: utf-8

"""
    BatchAI

    The Azure BatchAI Management API.

    The version of the OpenAPI document: 2018-05-01
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from datetime import datetime
from pydantic import BaseModel, ConfigDict, Field, StrictInt, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.caffe2_settings import Caffe2Settings
from openapi_client.models.caffe_settings import CaffeSettings
from openapi_client.models.chainer_settings import ChainerSettings
from openapi_client.models.cnt_ksettings import CNTKsettings
from openapi_client.models.container_settings import ContainerSettings
from openapi_client.models.custom_mpi_settings import CustomMpiSettings
from openapi_client.models.custom_toolkit_settings import CustomToolkitSettings
from openapi_client.models.environment_variable import EnvironmentVariable
from openapi_client.models.environment_variable_with_secret_value import EnvironmentVariableWithSecretValue
from openapi_client.models.horovod_settings import HorovodSettings
from openapi_client.models.input_directory import InputDirectory
from openapi_client.models.job_base_properties_constraints import JobBasePropertiesConstraints
from openapi_client.models.job_preparation import JobPreparation
from openapi_client.models.job_properties_execution_info import JobPropertiesExecutionInfo
from openapi_client.models.mount_volumes import MountVolumes
from openapi_client.models.output_directory import OutputDirectory
from openapi_client.models.py_torch_settings import PyTorchSettings
from openapi_client.models.resource_id import ResourceId
from openapi_client.models.tensor_flow_settings import TensorFlowSettings
from openapi_client.models.tool_type import ToolType
from typing import Optional, Set
from typing_extensions import Self

class JobProperties(BaseModel):
    """
    Job properties.
    """ # noqa: E501
    caffe2_settings: Optional[Caffe2Settings] = Field(default=None, alias="caffe2Settings")
    caffe_settings: Optional[CaffeSettings] = Field(default=None, alias="caffeSettings")
    chainer_settings: Optional[ChainerSettings] = Field(default=None, alias="chainerSettings")
    cluster: Optional[ResourceId] = None
    cntk_settings: Optional[CNTKsettings] = Field(default=None, alias="cntkSettings")
    constraints: Optional[JobBasePropertiesConstraints] = None
    container_settings: Optional[ContainerSettings] = Field(default=None, alias="containerSettings")
    creation_time: Optional[datetime] = Field(default=None, description="The creation time of the job.", alias="creationTime")
    custom_mpi_settings: Optional[CustomMpiSettings] = Field(default=None, alias="customMpiSettings")
    custom_toolkit_settings: Optional[CustomToolkitSettings] = Field(default=None, alias="customToolkitSettings")
    environment_variables: Optional[List[EnvironmentVariable]] = Field(default=None, description="A collection of user defined environment variables to be setup for the job.", alias="environmentVariables")
    execution_info: Optional[JobPropertiesExecutionInfo] = Field(default=None, alias="executionInfo")
    execution_state: Optional[StrictStr] = Field(default=None, description="The current state of the job. Possible values are: queued - The job is queued and able to run. A job enters this state when it is created, or when it is awaiting a retry after a failed run. running - The job is running on a compute cluster. This includes job-level preparation such as downloading resource files or set up container specified on the job - it does not necessarily mean that the job command line has started executing. terminating - The job is terminated by the user, the terminate operation is in progress. succeeded - The job has completed running successfully and exited with exit code 0. failed - The job has finished unsuccessfully (failed with a non-zero exit code) and has exhausted its retry limit. A job is also marked as failed if an error occurred launching the job.", alias="executionState")
    execution_state_transition_time: Optional[datetime] = Field(default=None, description="The time at which the job entered its current execution state.", alias="executionStateTransitionTime")
    horovod_settings: Optional[HorovodSettings] = Field(default=None, alias="horovodSettings")
    input_directories: Optional[List[InputDirectory]] = Field(default=None, description="A list of input directories for the job.", alias="inputDirectories")
    job_output_directory_path_segment: Optional[StrictStr] = Field(default=None, description="A segment of job's output directories path created by Batch AI. Batch AI creates job's output directories under an unique path to avoid conflicts between jobs. This value contains a path segment generated by Batch AI to make the path unique and can be used to find the output directory on the node or mounted filesystem.", alias="jobOutputDirectoryPathSegment")
    job_preparation: Optional[JobPreparation] = Field(default=None, alias="jobPreparation")
    mount_volumes: Optional[MountVolumes] = Field(default=None, alias="mountVolumes")
    node_count: Optional[StrictInt] = Field(default=None, description="The job will be gang scheduled on that many compute nodes", alias="nodeCount")
    output_directories: Optional[List[OutputDirectory]] = Field(default=None, description="A list of output directories for the job.", alias="outputDirectories")
    provisioning_state: Optional[StrictStr] = Field(default=None, description="The provisioned state of the Batch AI job", alias="provisioningState")
    provisioning_state_transition_time: Optional[datetime] = Field(default=None, description="The time at which the job entered its current provisioning state.", alias="provisioningStateTransitionTime")
    py_torch_settings: Optional[PyTorchSettings] = Field(default=None, alias="pyTorchSettings")
    scheduling_priority: Optional[StrictStr] = Field(default='normal', description="Scheduling priority associated with the job.", alias="schedulingPriority")
    secrets: Optional[List[EnvironmentVariableWithSecretValue]] = Field(default=None, description="A collection of user defined environment variables with secret values to be setup for the job. Server will never report values of these variables back.")
    std_out_err_path_prefix: Optional[StrictStr] = Field(default=None, description="The path where the Batch AI service stores stdout, stderror and execution log of the job.", alias="stdOutErrPathPrefix")
    tensor_flow_settings: Optional[TensorFlowSettings] = Field(default=None, alias="tensorFlowSettings")
    tool_type: Optional[ToolType] = Field(default=None, alias="toolType")
    __properties: ClassVar[List[str]] = ["caffe2Settings", "caffeSettings", "chainerSettings", "cluster", "cntkSettings", "constraints", "containerSettings", "creationTime", "customMpiSettings", "customToolkitSettings", "environmentVariables", "executionInfo", "executionState", "executionStateTransitionTime", "horovodSettings", "inputDirectories", "jobOutputDirectoryPathSegment", "jobPreparation", "mountVolumes", "nodeCount", "outputDirectories", "provisioningState", "provisioningStateTransitionTime", "pyTorchSettings", "schedulingPriority", "secrets", "stdOutErrPathPrefix", "tensorFlowSettings", "toolType"]

    @field_validator('execution_state')
    def execution_state_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['queued', 'running', 'terminating', 'succeeded', 'failed']):
            raise ValueError("must be one of enum values ('queued', 'running', 'terminating', 'succeeded', 'failed')")
        return value

    @field_validator('provisioning_state')
    def provisioning_state_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['creating', 'deleting', 'succeeded', 'failed']):
            raise ValueError("must be one of enum values ('creating', 'deleting', 'succeeded', 'failed')")
        return value

    @field_validator('scheduling_priority')
    def scheduling_priority_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['low', 'normal', 'high']):
            raise ValueError("must be one of enum values ('low', 'normal', 'high')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of JobProperties from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        """
        excluded_fields: Set[str] = set([
            "creation_time",
            "execution_state",
            "execution_state_transition_time",
            "job_output_directory_path_segment",
            "provisioning_state",
            "provisioning_state_transition_time",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of caffe2_settings
        if self.caffe2_settings:
            _dict['caffe2Settings'] = self.caffe2_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of caffe_settings
        if self.caffe_settings:
            _dict['caffeSettings'] = self.caffe_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of chainer_settings
        if self.chainer_settings:
            _dict['chainerSettings'] = self.chainer_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of cluster
        if self.cluster:
            _dict['cluster'] = self.cluster.to_dict()
        # override the default output from pydantic by calling `to_dict()` of cntk_settings
        if self.cntk_settings:
            _dict['cntkSettings'] = self.cntk_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of constraints
        if self.constraints:
            _dict['constraints'] = self.constraints.to_dict()
        # override the default output from pydantic by calling `to_dict()` of container_settings
        if self.container_settings:
            _dict['containerSettings'] = self.container_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of custom_mpi_settings
        if self.custom_mpi_settings:
            _dict['customMpiSettings'] = self.custom_mpi_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of custom_toolkit_settings
        if self.custom_toolkit_settings:
            _dict['customToolkitSettings'] = self.custom_toolkit_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in environment_variables (list)
        _items = []
        if self.environment_variables:
            for _item_environment_variables in self.environment_variables:
                if _item_environment_variables:
                    _items.append(_item_environment_variables.to_dict())
            _dict['environmentVariables'] = _items
        # override the default output from pydantic by calling `to_dict()` of execution_info
        if self.execution_info:
            _dict['executionInfo'] = self.execution_info.to_dict()
        # override the default output from pydantic by calling `to_dict()` of horovod_settings
        if self.horovod_settings:
            _dict['horovodSettings'] = self.horovod_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in input_directories (list)
        _items = []
        if self.input_directories:
            for _item_input_directories in self.input_directories:
                if _item_input_directories:
                    _items.append(_item_input_directories.to_dict())
            _dict['inputDirectories'] = _items
        # override the default output from pydantic by calling `to_dict()` of job_preparation
        if self.job_preparation:
            _dict['jobPreparation'] = self.job_preparation.to_dict()
        # override the default output from pydantic by calling `to_dict()` of mount_volumes
        if self.mount_volumes:
            _dict['mountVolumes'] = self.mount_volumes.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in output_directories (list)
        _items = []
        if self.output_directories:
            for _item_output_directories in self.output_directories:
                if _item_output_directories:
                    _items.append(_item_output_directories.to_dict())
            _dict['outputDirectories'] = _items
        # override the default output from pydantic by calling `to_dict()` of py_torch_settings
        if self.py_torch_settings:
            _dict['pyTorchSettings'] = self.py_torch_settings.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in secrets (list)
        _items = []
        if self.secrets:
            for _item_secrets in self.secrets:
                if _item_secrets:
                    _items.append(_item_secrets.to_dict())
            _dict['secrets'] = _items
        # override the default output from pydantic by calling `to_dict()` of tensor_flow_settings
        if self.tensor_flow_settings:
            _dict['tensorFlowSettings'] = self.tensor_flow_settings.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of JobProperties from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "caffe2Settings": Caffe2Settings.from_dict(obj["caffe2Settings"]) if obj.get("caffe2Settings") is not None else None,
            "caffeSettings": CaffeSettings.from_dict(obj["caffeSettings"]) if obj.get("caffeSettings") is not None else None,
            "chainerSettings": ChainerSettings.from_dict(obj["chainerSettings"]) if obj.get("chainerSettings") is not None else None,
            "cluster": ResourceId.from_dict(obj["cluster"]) if obj.get("cluster") is not None else None,
            "cntkSettings": CNTKsettings.from_dict(obj["cntkSettings"]) if obj.get("cntkSettings") is not None else None,
            "constraints": JobBasePropertiesConstraints.from_dict(obj["constraints"]) if obj.get("constraints") is not None else None,
            "containerSettings": ContainerSettings.from_dict(obj["containerSettings"]) if obj.get("containerSettings") is not None else None,
            "creationTime": obj.get("creationTime"),
            "customMpiSettings": CustomMpiSettings.from_dict(obj["customMpiSettings"]) if obj.get("customMpiSettings") is not None else None,
            "customToolkitSettings": CustomToolkitSettings.from_dict(obj["customToolkitSettings"]) if obj.get("customToolkitSettings") is not None else None,
            "environmentVariables": [EnvironmentVariable.from_dict(_item) for _item in obj["environmentVariables"]] if obj.get("environmentVariables") is not None else None,
            "executionInfo": JobPropertiesExecutionInfo.from_dict(obj["executionInfo"]) if obj.get("executionInfo") is not None else None,
            "executionState": obj.get("executionState"),
            "executionStateTransitionTime": obj.get("executionStateTransitionTime"),
            "horovodSettings": HorovodSettings.from_dict(obj["horovodSettings"]) if obj.get("horovodSettings") is not None else None,
            "inputDirectories": [InputDirectory.from_dict(_item) for _item in obj["inputDirectories"]] if obj.get("inputDirectories") is not None else None,
            "jobOutputDirectoryPathSegment": obj.get("jobOutputDirectoryPathSegment"),
            "jobPreparation": JobPreparation.from_dict(obj["jobPreparation"]) if obj.get("jobPreparation") is not None else None,
            "mountVolumes": MountVolumes.from_dict(obj["mountVolumes"]) if obj.get("mountVolumes") is not None else None,
            "nodeCount": obj.get("nodeCount"),
            "outputDirectories": [OutputDirectory.from_dict(_item) for _item in obj["outputDirectories"]] if obj.get("outputDirectories") is not None else None,
            "provisioningState": obj.get("provisioningState"),
            "provisioningStateTransitionTime": obj.get("provisioningStateTransitionTime"),
            "pyTorchSettings": PyTorchSettings.from_dict(obj["pyTorchSettings"]) if obj.get("pyTorchSettings") is not None else None,
            "schedulingPriority": obj.get("schedulingPriority") if obj.get("schedulingPriority") is not None else 'normal',
            "secrets": [EnvironmentVariableWithSecretValue.from_dict(_item) for _item in obj["secrets"]] if obj.get("secrets") is not None else None,
            "stdOutErrPathPrefix": obj.get("stdOutErrPathPrefix"),
            "tensorFlowSettings": TensorFlowSettings.from_dict(obj["tensorFlowSettings"]) if obj.get("tensorFlowSettings") is not None else None,
            "toolType": obj.get("toolType")
        })
        return _obj


