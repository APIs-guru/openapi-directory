# coding: utf-8

"""
    Cloud Speech-to-Text API

    Converts audio to text by applying powerful neural network models.

    The version of the OpenAPI document: v1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


import unittest

from openapi_client.models.recognition_config import RecognitionConfig

class TestRecognitionConfig(unittest.TestCase):
    """RecognitionConfig unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> RecognitionConfig:
        """Test RecognitionConfig
            include_optional is a boolean, when False only required
            params are included, when True both required and
            optional params are included """
        # uncomment below to create an instance of `RecognitionConfig`
        """
        model = RecognitionConfig()
        if include_optional:
            return RecognitionConfig(
                adaptation = openapi_client.models.speech_adaptation.SpeechAdaptation(
                    abnf_grammar = openapi_client.models.abnf_grammar.ABNFGrammar(
                        abnf_strings = [
                            ''
                            ], ), 
                    custom_classes = [
                        openapi_client.models.custom_class.CustomClass(
                            annotations = {
                                'key' : ''
                                }, 
                            custom_class_id = '', 
                            delete_time = '', 
                            display_name = '', 
                            etag = '', 
                            expire_time = '', 
                            items = [
                                openapi_client.models.class_item.ClassItem(
                                    value = '', )
                                ], 
                            kms_key_name = '', 
                            kms_key_version_name = '', 
                            name = '', 
                            reconciling = True, 
                            state = 'STATE_UNSPECIFIED', 
                            uid = '', )
                        ], 
                    phrase_set_references = [
                        ''
                        ], 
                    phrase_sets = [
                        openapi_client.models.phrase_set.PhraseSet(
                            boost = 1.337, 
                            delete_time = '', 
                            display_name = '', 
                            etag = '', 
                            expire_time = '', 
                            kms_key_name = '', 
                            kms_key_version_name = '', 
                            name = '', 
                            phrases = [
                                openapi_client.models.phrase.Phrase(
                                    boost = 1.337, 
                                    value = '', )
                                ], 
                            reconciling = True, 
                            state = 'STATE_UNSPECIFIED', 
                            uid = '', )
                        ], ),
                alternative_language_codes = [
                    ''
                    ],
                audio_channel_count = 56,
                diarization_config = openapi_client.models.speaker_diarization_config.SpeakerDiarizationConfig(
                    enable_speaker_diarization = True, 
                    max_speaker_count = 56, 
                    min_speaker_count = 56, 
                    speaker_tag = 56, ),
                enable_automatic_punctuation = True,
                enable_separate_recognition_per_channel = True,
                enable_spoken_emojis = True,
                enable_spoken_punctuation = True,
                enable_word_confidence = True,
                enable_word_time_offsets = True,
                encoding = 'ENCODING_UNSPECIFIED',
                language_code = '',
                max_alternatives = 56,
                metadata = openapi_client.models.recognition_metadata.RecognitionMetadata(
                    audio_topic = '', 
                    industry_naics_code_of_audio = 56, 
                    interaction_type = 'INTERACTION_TYPE_UNSPECIFIED', 
                    microphone_distance = 'MICROPHONE_DISTANCE_UNSPECIFIED', 
                    original_media_type = 'ORIGINAL_MEDIA_TYPE_UNSPECIFIED', 
                    original_mime_type = '', 
                    recording_device_name = '', 
                    recording_device_type = 'RECORDING_DEVICE_TYPE_UNSPECIFIED', ),
                model = '',
                profanity_filter = True,
                sample_rate_hertz = 56,
                speech_contexts = [
                    openapi_client.models.speech_context.SpeechContext(
                        boost = 1.337, 
                        phrases = [
                            ''
                            ], )
                    ],
                transcript_normalization = openapi_client.models.transcript_normalization.TranscriptNormalization(
                    entries = [
                        openapi_client.models.entry.Entry(
                            case_sensitive = True, 
                            replace = '', 
                            search = '', )
                        ], ),
                use_enhanced = True
            )
        else:
            return RecognitionConfig(
        )
        """

    def testRecognitionConfig(self):
        """Test RecognitionConfig"""
        # inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)

if __name__ == '__main__':
    unittest.main()
