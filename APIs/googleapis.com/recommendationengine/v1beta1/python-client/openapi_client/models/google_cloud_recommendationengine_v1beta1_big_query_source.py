# coding: utf-8

"""
    Recommendations AI (Beta)

    Note that we now highly recommend new customers to use Retail API, which incorporates the GA version of the Recommendations AI funtionalities. To enable Retail API, please visit https://console.cloud.google.com/apis/library/retail.googleapis.com. The Recommendations AI service enables customers to build end-to-end personalized recommendation systems without requiring a high level of expertise in machine learning, recommendation system, or Google Cloud.

    The version of the OpenAPI document: v1beta1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from typing import Optional, Set
from typing_extensions import Self

class GoogleCloudRecommendationengineV1beta1BigQuerySource(BaseModel):
    """
    BigQuery source import data from.
    """ # noqa: E501
    data_schema: Optional[StrictStr] = Field(default=None, description="Optional. The schema to use when parsing the data from the source. Supported values for catalog imports: 1: \"catalog_recommendations_ai\" using https://cloud.google.com/recommendations-ai/docs/upload-catalog#json (Default for catalogItems.import) 2: \"catalog_merchant_center\" using https://cloud.google.com/recommendations-ai/docs/upload-catalog#mc Supported values for user event imports: 1: \"user_events_recommendations_ai\" using https://cloud.google.com/recommendations-ai/docs/manage-user-events#import (Default for userEvents.import) 2. \"user_events_ga360\" using https://support.google.com/analytics/answer/3437719?hl=en", alias="dataSchema")
    dataset_id: Optional[StrictStr] = Field(default=None, description="Required. The BigQuery data set to copy the data from.", alias="datasetId")
    gcs_staging_dir: Optional[StrictStr] = Field(default=None, description="Optional. Intermediate Cloud Storage directory used for the import. Can be specified if one wants to have the BigQuery export to a specific Cloud Storage directory.", alias="gcsStagingDir")
    project_id: Optional[StrictStr] = Field(default=None, description="Optional. The project id (can be project # or id) that the BigQuery source is in. If not specified, inherits the project id from the parent request.", alias="projectId")
    table_id: Optional[StrictStr] = Field(default=None, description="Required. The BigQuery table to copy the data from.", alias="tableId")
    __properties: ClassVar[List[str]] = ["dataSchema", "datasetId", "gcsStagingDir", "projectId", "tableId"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of GoogleCloudRecommendationengineV1beta1BigQuerySource from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of GoogleCloudRecommendationengineV1beta1BigQuerySource from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "dataSchema": obj.get("dataSchema"),
            "datasetId": obj.get("datasetId"),
            "gcsStagingDir": obj.get("gcsStagingDir"),
            "projectId": obj.get("projectId"),
            "tableId": obj.get("tableId")
        })
        return _obj


