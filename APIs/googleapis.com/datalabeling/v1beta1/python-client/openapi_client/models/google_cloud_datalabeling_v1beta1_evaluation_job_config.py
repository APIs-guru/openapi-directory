# coding: utf-8

"""
    Data Labeling API

    Public API for Google Cloud AI Data Labeling Service.

    The version of the OpenAPI document: v1beta1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictFloat, StrictInt, StrictStr
from typing import Any, ClassVar, Dict, List, Optional, Union
from openapi_client.models.google_cloud_datalabeling_v1beta1_bounding_poly_config import GoogleCloudDatalabelingV1beta1BoundingPolyConfig
from openapi_client.models.google_cloud_datalabeling_v1beta1_evaluation_config import GoogleCloudDatalabelingV1beta1EvaluationConfig
from openapi_client.models.google_cloud_datalabeling_v1beta1_evaluation_job_alert_config import GoogleCloudDatalabelingV1beta1EvaluationJobAlertConfig
from openapi_client.models.google_cloud_datalabeling_v1beta1_human_annotation_config import GoogleCloudDatalabelingV1beta1HumanAnnotationConfig
from openapi_client.models.google_cloud_datalabeling_v1beta1_image_classification_config import GoogleCloudDatalabelingV1beta1ImageClassificationConfig
from openapi_client.models.google_cloud_datalabeling_v1beta1_input_config import GoogleCloudDatalabelingV1beta1InputConfig
from openapi_client.models.google_cloud_datalabeling_v1beta1_text_classification_config import GoogleCloudDatalabelingV1beta1TextClassificationConfig
from typing import Optional, Set
from typing_extensions import Self

class GoogleCloudDatalabelingV1beta1EvaluationJobConfig(BaseModel):
    """
    Configures specific details of how a continuous evaluation job works. Provide this configuration when you create an EvaluationJob.
    """ # noqa: E501
    bigquery_import_keys: Optional[Dict[str, StrictStr]] = Field(default=None, description="Required. Prediction keys that tell Data Labeling Service where to find the data for evaluation in your BigQuery table. When the service samples prediction input and output from your model version and saves it to BigQuery, the data gets stored as JSON strings in the BigQuery table. These keys tell Data Labeling Service how to parse the JSON. You can provide the following entries in this field: * `data_json_key`: the data key for prediction input. You must provide either this key or `reference_json_key`. * `reference_json_key`: the data reference key for prediction input. You must provide either this key or `data_json_key`. * `label_json_key`: the label key for prediction output. Required. * `label_score_json_key`: the score key for prediction output. Required. * `bounding_box_json_key`: the bounding box key for prediction output. Required if your model version perform image object detection. Learn [how to configure prediction keys](/ml-engine/docs/continuous-evaluation/create-job#prediction-keys).", alias="bigqueryImportKeys")
    bounding_poly_config: Optional[GoogleCloudDatalabelingV1beta1BoundingPolyConfig] = Field(default=None, alias="boundingPolyConfig")
    evaluation_config: Optional[GoogleCloudDatalabelingV1beta1EvaluationConfig] = Field(default=None, alias="evaluationConfig")
    evaluation_job_alert_config: Optional[GoogleCloudDatalabelingV1beta1EvaluationJobAlertConfig] = Field(default=None, alias="evaluationJobAlertConfig")
    example_count: Optional[StrictInt] = Field(default=None, description="Required. The maximum number of predictions to sample and save to BigQuery during each evaluation interval. This limit overrides `example_sample_percentage`: even if the service has not sampled enough predictions to fulfill `example_sample_perecentage` during an interval, it stops sampling predictions when it meets this limit.", alias="exampleCount")
    example_sample_percentage: Optional[Union[StrictFloat, StrictInt]] = Field(default=None, description="Required. Fraction of predictions to sample and save to BigQuery during each evaluation interval. For example, 0.1 means 10% of predictions served by your model version get saved to BigQuery.", alias="exampleSamplePercentage")
    human_annotation_config: Optional[GoogleCloudDatalabelingV1beta1HumanAnnotationConfig] = Field(default=None, alias="humanAnnotationConfig")
    image_classification_config: Optional[GoogleCloudDatalabelingV1beta1ImageClassificationConfig] = Field(default=None, alias="imageClassificationConfig")
    input_config: Optional[GoogleCloudDatalabelingV1beta1InputConfig] = Field(default=None, alias="inputConfig")
    text_classification_config: Optional[GoogleCloudDatalabelingV1beta1TextClassificationConfig] = Field(default=None, alias="textClassificationConfig")
    __properties: ClassVar[List[str]] = ["bigqueryImportKeys", "boundingPolyConfig", "evaluationConfig", "evaluationJobAlertConfig", "exampleCount", "exampleSamplePercentage", "humanAnnotationConfig", "imageClassificationConfig", "inputConfig", "textClassificationConfig"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of GoogleCloudDatalabelingV1beta1EvaluationJobConfig from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of bounding_poly_config
        if self.bounding_poly_config:
            _dict['boundingPolyConfig'] = self.bounding_poly_config.to_dict()
        # override the default output from pydantic by calling `to_dict()` of evaluation_config
        if self.evaluation_config:
            _dict['evaluationConfig'] = self.evaluation_config.to_dict()
        # override the default output from pydantic by calling `to_dict()` of evaluation_job_alert_config
        if self.evaluation_job_alert_config:
            _dict['evaluationJobAlertConfig'] = self.evaluation_job_alert_config.to_dict()
        # override the default output from pydantic by calling `to_dict()` of human_annotation_config
        if self.human_annotation_config:
            _dict['humanAnnotationConfig'] = self.human_annotation_config.to_dict()
        # override the default output from pydantic by calling `to_dict()` of image_classification_config
        if self.image_classification_config:
            _dict['imageClassificationConfig'] = self.image_classification_config.to_dict()
        # override the default output from pydantic by calling `to_dict()` of input_config
        if self.input_config:
            _dict['inputConfig'] = self.input_config.to_dict()
        # override the default output from pydantic by calling `to_dict()` of text_classification_config
        if self.text_classification_config:
            _dict['textClassificationConfig'] = self.text_classification_config.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of GoogleCloudDatalabelingV1beta1EvaluationJobConfig from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "bigqueryImportKeys": obj.get("bigqueryImportKeys"),
            "boundingPolyConfig": GoogleCloudDatalabelingV1beta1BoundingPolyConfig.from_dict(obj["boundingPolyConfig"]) if obj.get("boundingPolyConfig") is not None else None,
            "evaluationConfig": GoogleCloudDatalabelingV1beta1EvaluationConfig.from_dict(obj["evaluationConfig"]) if obj.get("evaluationConfig") is not None else None,
            "evaluationJobAlertConfig": GoogleCloudDatalabelingV1beta1EvaluationJobAlertConfig.from_dict(obj["evaluationJobAlertConfig"]) if obj.get("evaluationJobAlertConfig") is not None else None,
            "exampleCount": obj.get("exampleCount"),
            "exampleSamplePercentage": obj.get("exampleSamplePercentage"),
            "humanAnnotationConfig": GoogleCloudDatalabelingV1beta1HumanAnnotationConfig.from_dict(obj["humanAnnotationConfig"]) if obj.get("humanAnnotationConfig") is not None else None,
            "imageClassificationConfig": GoogleCloudDatalabelingV1beta1ImageClassificationConfig.from_dict(obj["imageClassificationConfig"]) if obj.get("imageClassificationConfig") is not None else None,
            "inputConfig": GoogleCloudDatalabelingV1beta1InputConfig.from_dict(obj["inputConfig"]) if obj.get("inputConfig") is not None else None,
            "textClassificationConfig": GoogleCloudDatalabelingV1beta1TextClassificationConfig.from_dict(obj["textClassificationConfig"]) if obj.get("textClassificationConfig") is not None else None
        })
        return _obj


