# coding: utf-8

"""
    Cloud Dataproc API

    Manages Hadoop-based clusters and jobs on Google Cloud Platform.

    The version of the OpenAPI document: v1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


import unittest

from openapi_client.models.submit_job_request import SubmitJobRequest

class TestSubmitJobRequest(unittest.TestCase):
    """SubmitJobRequest unit test stubs"""

    def setUp(self):
        pass

    def tearDown(self):
        pass

    def make_instance(self, include_optional) -> SubmitJobRequest:
        """Test SubmitJobRequest
            include_optional is a boolean, when False only required
            params are included, when True both required and
            optional params are included """
        # uncomment below to create an instance of `SubmitJobRequest`
        """
        model = SubmitJobRequest()
        if include_optional:
            return SubmitJobRequest(
                job = openapi_client.models.job.Job(
                    done = True, 
                    driver_control_files_uri = '', 
                    driver_output_resource_uri = '', 
                    driver_scheduling_config = openapi_client.models.driver_scheduling_config.DriverSchedulingConfig(
                        memory_mb = 56, 
                        vcores = 56, ), 
                    flink_job = openapi_client.models.flink_job.FlinkJob(
                        args = [
                            ''
                            ], 
                        jar_file_uris = [
                            ''
                            ], 
                        logging_config = openapi_client.models.logging_config.LoggingConfig(
                            driver_log_levels = {
                                'LEVEL_UNSPECIFIED' : 'LEVEL_UNSPECIFIED'
                                }, ), 
                        main_class = '', 
                        main_jar_file_uri = '', 
                        properties = {
                            'key' : ''
                            }, 
                        savepoint_uri = '', ), 
                    hadoop_job = openapi_client.models.hadoop_job.HadoopJob(
                        archive_uris = [
                            ''
                            ], 
                        file_uris = [
                            ''
                            ], 
                        main_class = '', 
                        main_jar_file_uri = '', ), 
                    hive_job = openapi_client.models.hive_job.HiveJob(
                        continue_on_failure = True, 
                        query_file_uri = '', 
                        query_list = openapi_client.models.query_list.QueryList(
                            queries = [
                                ''
                                ], ), 
                        script_variables = {
                            'key' : ''
                            }, ), 
                    job_uuid = '', 
                    labels = {
                        'key' : ''
                        }, 
                    pig_job = openapi_client.models.pig_job.PigJob(
                        continue_on_failure = True, 
                        query_file_uri = '', ), 
                    placement = openapi_client.models.job_placement.JobPlacement(
                        cluster_labels = {
                            'key' : ''
                            }, 
                        cluster_name = '', 
                        cluster_uuid = '', ), 
                    presto_job = openapi_client.models.presto_job.PrestoJob(
                        client_tags = [
                            ''
                            ], 
                        continue_on_failure = True, 
                        output_format = '', 
                        query_file_uri = '', ), 
                    pyspark_job = openapi_client.models.py_spark_job.PySparkJob(
                        main_python_file_uri = '', 
                        python_file_uris = [
                            ''
                            ], ), 
                    reference = openapi_client.models.job_reference.JobReference(
                        job_id = '', 
                        project_id = '', ), 
                    scheduling = openapi_client.models.job_scheduling.JobScheduling(
                        max_failures_per_hour = 56, 
                        max_failures_total = 56, ), 
                    spark_job = openapi_client.models.spark_job.SparkJob(
                        main_class = '', 
                        main_jar_file_uri = '', ), 
                    spark_r_job = openapi_client.models.spark_r_job.SparkRJob(
                        main_r_file_uri = '', ), 
                    spark_sql_job = openapi_client.models.spark_sql_job.SparkSqlJob(
                        query_file_uri = '', ), 
                    status = openapi_client.models.job_status.JobStatus(
                        details = '', 
                        state = 'STATE_UNSPECIFIED', 
                        state_start_time = '', 
                        substate = 'UNSPECIFIED', ), 
                    status_history = [
                        openapi_client.models.job_status.JobStatus(
                            details = '', 
                            state = 'STATE_UNSPECIFIED', 
                            state_start_time = '', 
                            substate = 'UNSPECIFIED', )
                        ], 
                    trino_job = openapi_client.models.trino_job.TrinoJob(
                        continue_on_failure = True, 
                        output_format = '', 
                        query_file_uri = '', ), 
                    yarn_applications = [
                        openapi_client.models.yarn_application.YarnApplication(
                            name = '', 
                            progress = 1.337, 
                            state = 'STATE_UNSPECIFIED', 
                            tracking_url = '', )
                        ], ),
                request_id = ''
            )
        else:
            return SubmitJobRequest(
        )
        """

    def testSubmitJobRequest(self):
        """Test SubmitJobRequest"""
        # inst_req_only = self.make_instance(include_optional=False)
        # inst_req_and_optional = self.make_instance(include_optional=True)

if __name__ == '__main__':
    unittest.main()
