# coding: utf-8

"""
    Cloud Video Intelligence API

    Detects objects, explicit content, and scene changes in videos. It also specifies the region for annotation and transcribes speech to text. Supports both asynchronous API and streaming API.

    The version of the OpenAPI document: v1p3beta1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictFloat, StrictInt, StrictStr
from typing import Any, ClassVar, Dict, List, Optional, Union
from openapi_client.models.google_cloud_videointelligence_v1p3beta1_entity import GoogleCloudVideointelligenceV1p3beta1Entity
from openapi_client.models.google_cloud_videointelligence_v1p3beta1_object_tracking_frame import GoogleCloudVideointelligenceV1p3beta1ObjectTrackingFrame
from openapi_client.models.google_cloud_videointelligence_v1p3beta1_video_segment import GoogleCloudVideointelligenceV1p3beta1VideoSegment
from typing import Optional, Set
from typing_extensions import Self

class GoogleCloudVideointelligenceV1p3beta1ObjectTrackingAnnotation(BaseModel):
    """
    Annotations corresponding to one tracked object.
    """ # noqa: E501
    confidence: Optional[Union[StrictFloat, StrictInt]] = Field(default=None, description="Object category's labeling confidence of this track.")
    entity: Optional[GoogleCloudVideointelligenceV1p3beta1Entity] = None
    frames: Optional[List[GoogleCloudVideointelligenceV1p3beta1ObjectTrackingFrame]] = Field(default=None, description="Information corresponding to all frames where this object track appears. Non-streaming batch mode: it may be one or multiple ObjectTrackingFrame messages in frames. Streaming mode: it can only be one ObjectTrackingFrame message in frames.")
    segment: Optional[GoogleCloudVideointelligenceV1p3beta1VideoSegment] = None
    track_id: Optional[StrictStr] = Field(default=None, description="Streaming mode ONLY. In streaming mode, we do not know the end time of a tracked object before it is completed. Hence, there is no VideoSegment info returned. Instead, we provide a unique identifiable integer track_id so that the customers can correlate the results of the ongoing ObjectTrackAnnotation of the same track_id over time.", alias="trackId")
    version: Optional[StrictStr] = Field(default=None, description="Feature version.")
    __properties: ClassVar[List[str]] = ["confidence", "entity", "frames", "segment", "trackId", "version"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of GoogleCloudVideointelligenceV1p3beta1ObjectTrackingAnnotation from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of entity
        if self.entity:
            _dict['entity'] = self.entity.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in frames (list)
        _items = []
        if self.frames:
            for _item_frames in self.frames:
                if _item_frames:
                    _items.append(_item_frames.to_dict())
            _dict['frames'] = _items
        # override the default output from pydantic by calling `to_dict()` of segment
        if self.segment:
            _dict['segment'] = self.segment.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of GoogleCloudVideointelligenceV1p3beta1ObjectTrackingAnnotation from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "confidence": obj.get("confidence"),
            "entity": GoogleCloudVideointelligenceV1p3beta1Entity.from_dict(obj["entity"]) if obj.get("entity") is not None else None,
            "frames": [GoogleCloudVideointelligenceV1p3beta1ObjectTrackingFrame.from_dict(_item) for _item in obj["frames"]] if obj.get("frames") is not None else None,
            "segment": GoogleCloudVideointelligenceV1p3beta1VideoSegment.from_dict(obj["segment"]) if obj.get("segment") is not None else None,
            "trackId": obj.get("trackId"),
            "version": obj.get("version")
        })
        return _obj


