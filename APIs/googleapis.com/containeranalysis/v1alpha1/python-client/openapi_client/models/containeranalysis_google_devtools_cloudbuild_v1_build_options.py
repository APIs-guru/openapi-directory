# coding: utf-8

"""
    Container Analysis API

    This API is a prerequisite for leveraging Artifact Analysis scanning capabilities in both Artifact Registry and with Advanced Vulnerability Insights (runtime scanning) in GKE. In addition, the Container Analysis API is an implementation of the Grafeas API, which enables storing, querying, and retrieval of critical metadata about all of your software artifacts.

    The version of the OpenAPI document: v1alpha1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.containeranalysis_google_devtools_cloudbuild_v1_build_options_pool_option import ContaineranalysisGoogleDevtoolsCloudbuildV1BuildOptionsPoolOption
from openapi_client.models.containeranalysis_google_devtools_cloudbuild_v1_volume import ContaineranalysisGoogleDevtoolsCloudbuildV1Volume
from typing import Optional, Set
from typing_extensions import Self

class ContaineranalysisGoogleDevtoolsCloudbuildV1BuildOptions(BaseModel):
    """
    Optional arguments to enable specific features of builds.
    """ # noqa: E501
    automap_substitutions: Optional[StrictBool] = Field(default=None, description="Option to include built-in and custom substitutions as env variables for all build steps.", alias="automapSubstitutions")
    default_logs_bucket_behavior: Optional[StrictStr] = Field(default=None, description="Optional. Option to specify how default logs buckets are setup.", alias="defaultLogsBucketBehavior")
    disk_size_gb: Optional[StrictStr] = Field(default=None, description="Requested disk size for the VM that runs the build. Note that this is *NOT* \"disk free\"; some of the space will be used by the operating system and build utilities. Also note that this is the minimum disk size that will be allocated for the build -- the build may run with a larger disk than requested. At present, the maximum disk size is 2000GB; builds that request more than the maximum are rejected with an error.", alias="diskSizeGb")
    dynamic_substitutions: Optional[StrictBool] = Field(default=None, description="Option to specify whether or not to apply bash style string operations to the substitutions. NOTE: this is always enabled for triggered builds and cannot be overridden in the build configuration file.", alias="dynamicSubstitutions")
    env: Optional[List[StrictStr]] = Field(default=None, description="A list of global environment variable definitions that will exist for all build steps in this build. If a variable is defined in both globally and in a build step, the variable will use the build step value. The elements are of the form \"KEY=VALUE\" for the environment variable \"KEY\" being given the value \"VALUE\".")
    log_streaming_option: Optional[StrictStr] = Field(default=None, description="Option to define build log streaming behavior to Cloud Storage.", alias="logStreamingOption")
    logging: Optional[StrictStr] = Field(default=None, description="Option to specify the logging mode, which determines if and where build logs are stored.")
    machine_type: Optional[StrictStr] = Field(default=None, description="Compute Engine machine type on which to run the build.", alias="machineType")
    pool: Optional[ContaineranalysisGoogleDevtoolsCloudbuildV1BuildOptionsPoolOption] = None
    requested_verify_option: Optional[StrictStr] = Field(default=None, description="Requested verifiability options.", alias="requestedVerifyOption")
    secret_env: Optional[List[StrictStr]] = Field(default=None, description="A list of global environment variables, which are encrypted using a Cloud Key Management Service crypto key. These values must be specified in the build's `Secret`. These variables will be available to all build steps in this build.", alias="secretEnv")
    source_provenance_hash: Optional[List[StrictStr]] = Field(default=None, description="Requested hash for SourceProvenance.", alias="sourceProvenanceHash")
    substitution_option: Optional[StrictStr] = Field(default=None, description="Option to specify behavior when there is an error in the substitution checks. NOTE: this is always set to ALLOW_LOOSE for triggered builds and cannot be overridden in the build configuration file.", alias="substitutionOption")
    volumes: Optional[List[ContaineranalysisGoogleDevtoolsCloudbuildV1Volume]] = Field(default=None, description="Global list of volumes to mount for ALL build steps Each volume is created as an empty volume prior to starting the build process. Upon completion of the build, volumes and their contents are discarded. Global volume names and paths cannot conflict with the volumes defined a build step. Using a global volume in a build with only one step is not valid as it is indicative of a build request with an incorrect configuration.")
    worker_pool: Optional[StrictStr] = Field(default=None, description="This field deprecated; please use `pool.name` instead.", alias="workerPool")
    __properties: ClassVar[List[str]] = ["automapSubstitutions", "defaultLogsBucketBehavior", "diskSizeGb", "dynamicSubstitutions", "env", "logStreamingOption", "logging", "machineType", "pool", "requestedVerifyOption", "secretEnv", "sourceProvenanceHash", "substitutionOption", "volumes", "workerPool"]

    @field_validator('default_logs_bucket_behavior')
    def default_logs_bucket_behavior_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['DEFAULT_LOGS_BUCKET_BEHAVIOR_UNSPECIFIED', 'REGIONAL_USER_OWNED_BUCKET']):
            raise ValueError("must be one of enum values ('DEFAULT_LOGS_BUCKET_BEHAVIOR_UNSPECIFIED', 'REGIONAL_USER_OWNED_BUCKET')")
        return value

    @field_validator('log_streaming_option')
    def log_streaming_option_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['STREAM_DEFAULT', 'STREAM_ON', 'STREAM_OFF']):
            raise ValueError("must be one of enum values ('STREAM_DEFAULT', 'STREAM_ON', 'STREAM_OFF')")
        return value

    @field_validator('logging')
    def logging_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['LOGGING_UNSPECIFIED', 'LEGACY', 'GCS_ONLY', 'STACKDRIVER_ONLY', 'CLOUD_LOGGING_ONLY', 'NONE']):
            raise ValueError("must be one of enum values ('LOGGING_UNSPECIFIED', 'LEGACY', 'GCS_ONLY', 'STACKDRIVER_ONLY', 'CLOUD_LOGGING_ONLY', 'NONE')")
        return value

    @field_validator('machine_type')
    def machine_type_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['UNSPECIFIED', 'N1_HIGHCPU_8', 'N1_HIGHCPU_32', 'E2_HIGHCPU_8', 'E2_HIGHCPU_32', 'E2_MEDIUM']):
            raise ValueError("must be one of enum values ('UNSPECIFIED', 'N1_HIGHCPU_8', 'N1_HIGHCPU_32', 'E2_HIGHCPU_8', 'E2_HIGHCPU_32', 'E2_MEDIUM')")
        return value

    @field_validator('requested_verify_option')
    def requested_verify_option_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['NOT_VERIFIED', 'VERIFIED']):
            raise ValueError("must be one of enum values ('NOT_VERIFIED', 'VERIFIED')")
        return value

    @field_validator('source_provenance_hash')
    def source_provenance_hash_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        for i in value:
            if i not in set(['NONE', 'SHA256', 'MD5', 'SHA512']):
                raise ValueError("each list item must be one of ('NONE', 'SHA256', 'MD5', 'SHA512')")
        return value

    @field_validator('substitution_option')
    def substitution_option_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['MUST_MATCH', 'ALLOW_LOOSE']):
            raise ValueError("must be one of enum values ('MUST_MATCH', 'ALLOW_LOOSE')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of ContaineranalysisGoogleDevtoolsCloudbuildV1BuildOptions from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of pool
        if self.pool:
            _dict['pool'] = self.pool.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in volumes (list)
        _items = []
        if self.volumes:
            for _item_volumes in self.volumes:
                if _item_volumes:
                    _items.append(_item_volumes.to_dict())
            _dict['volumes'] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of ContaineranalysisGoogleDevtoolsCloudbuildV1BuildOptions from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "automapSubstitutions": obj.get("automapSubstitutions"),
            "defaultLogsBucketBehavior": obj.get("defaultLogsBucketBehavior"),
            "diskSizeGb": obj.get("diskSizeGb"),
            "dynamicSubstitutions": obj.get("dynamicSubstitutions"),
            "env": obj.get("env"),
            "logStreamingOption": obj.get("logStreamingOption"),
            "logging": obj.get("logging"),
            "machineType": obj.get("machineType"),
            "pool": ContaineranalysisGoogleDevtoolsCloudbuildV1BuildOptionsPoolOption.from_dict(obj["pool"]) if obj.get("pool") is not None else None,
            "requestedVerifyOption": obj.get("requestedVerifyOption"),
            "secretEnv": obj.get("secretEnv"),
            "sourceProvenanceHash": obj.get("sourceProvenanceHash"),
            "substitutionOption": obj.get("substitutionOption"),
            "volumes": [ContaineranalysisGoogleDevtoolsCloudbuildV1Volume.from_dict(_item) for _item in obj["volumes"]] if obj.get("volumes") is not None else None,
            "workerPool": obj.get("workerPool")
        })
        return _obj


