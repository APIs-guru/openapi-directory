# coding: utf-8

"""
    Container Analysis API

    This API is a prerequisite for leveraging Artifact Analysis scanning capabilities in both Artifact Registry and with Advanced Vulnerability Insights (runtime scanning) in GKE. In addition, the Container Analysis API is an implementation of the Grafeas API, which enables storing, querying, and retrieval of critical metadata about all of your software artifacts.

    The version of the OpenAPI document: v1alpha1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.containeranalysis_google_devtools_cloudbuild_v1_time_span import ContaineranalysisGoogleDevtoolsCloudbuildV1TimeSpan
from typing import Optional, Set
from typing_extensions import Self

class ContaineranalysisGoogleDevtoolsCloudbuildV1ArtifactsArtifactObjects(BaseModel):
    """
    Files in the workspace to upload to Cloud Storage upon successful completion of all build steps.
    """ # noqa: E501
    location: Optional[StrictStr] = Field(default=None, description="Cloud Storage bucket and optional object path, in the form \"gs://bucket/path/to/somewhere/\". (see [Bucket Name Requirements](https://cloud.google.com/storage/docs/bucket-naming#requirements)). Files in the workspace matching any path pattern will be uploaded to Cloud Storage with this location as a prefix.")
    paths: Optional[List[StrictStr]] = Field(default=None, description="Path globs used to match files in the build's workspace.")
    timing: Optional[ContaineranalysisGoogleDevtoolsCloudbuildV1TimeSpan] = None
    __properties: ClassVar[List[str]] = ["location", "paths", "timing"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of ContaineranalysisGoogleDevtoolsCloudbuildV1ArtifactsArtifactObjects from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of timing
        if self.timing:
            _dict['timing'] = self.timing.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of ContaineranalysisGoogleDevtoolsCloudbuildV1ArtifactsArtifactObjects from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "location": obj.get("location"),
            "paths": obj.get("paths"),
            "timing": ContaineranalysisGoogleDevtoolsCloudbuildV1TimeSpan.from_dict(obj["timing"]) if obj.get("timing") is not None else None
        })
        return _obj


