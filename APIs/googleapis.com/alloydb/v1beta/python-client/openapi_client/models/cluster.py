# coding: utf-8

"""
    AlloyDB API

    AlloyDB for PostgreSQL is an open source-compatible database service that provides a powerful option for migrating, modernizing, or building commercial-grade applications. It offers full compatibility with standard PostgreSQL, and is more than 4x faster for transactional workloads and up to 100x faster for analytical queries than standard PostgreSQL in our performance tests. AlloyDB for PostgreSQL offers a 99.99 percent availability SLA inclusive of maintenance. AlloyDB is optimized for the most demanding use cases, allowing you to build new applications that require high transaction throughput, large database sizes, or multiple read resources; scale existing PostgreSQL workloads with no application changes; and modernize legacy proprietary databases. 

    The version of the OpenAPI document: v1beta
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.automated_backup_policy import AutomatedBackupPolicy
from openapi_client.models.backup_source import BackupSource
from openapi_client.models.continuous_backup_config import ContinuousBackupConfig
from openapi_client.models.continuous_backup_info import ContinuousBackupInfo
from openapi_client.models.encryption_config import EncryptionConfig
from openapi_client.models.encryption_info import EncryptionInfo
from openapi_client.models.migration_source import MigrationSource
from openapi_client.models.network_config import NetworkConfig
from openapi_client.models.primary_config import PrimaryConfig
from openapi_client.models.psc_config import PscConfig
from openapi_client.models.secondary_config import SecondaryConfig
from openapi_client.models.ssl_config import SslConfig
from openapi_client.models.user_password import UserPassword
from typing import Optional, Set
from typing_extensions import Self

class Cluster(BaseModel):
    """
    A cluster is a collection of regional AlloyDB resources. It can include a primary instance and one or more read pool instances. All cluster resources share a storage layer, which scales as needed.
    """ # noqa: E501
    annotations: Optional[Dict[str, StrictStr]] = Field(default=None, description="Annotations to allow client tools to store small amount of arbitrary data. This is distinct from labels. https://google.aip.dev/128")
    automated_backup_policy: Optional[AutomatedBackupPolicy] = Field(default=None, alias="automatedBackupPolicy")
    backup_source: Optional[BackupSource] = Field(default=None, alias="backupSource")
    cluster_type: Optional[StrictStr] = Field(default=None, description="Output only. The type of the cluster. This is an output-only field and it's populated at the Cluster creation time or the Cluster promotion time. The cluster type is determined by which RPC was used to create the cluster (i.e. `CreateCluster` vs. `CreateSecondaryCluster`", alias="clusterType")
    continuous_backup_config: Optional[ContinuousBackupConfig] = Field(default=None, alias="continuousBackupConfig")
    continuous_backup_info: Optional[ContinuousBackupInfo] = Field(default=None, alias="continuousBackupInfo")
    create_time: Optional[StrictStr] = Field(default=None, description="Output only. Create time stamp", alias="createTime")
    database_version: Optional[StrictStr] = Field(default=None, description="Optional. The database engine major version. This is an optional field and it is populated at the Cluster creation time. If a database version is not supplied at cluster creation time, then a default database version will be used.", alias="databaseVersion")
    delete_time: Optional[StrictStr] = Field(default=None, description="Output only. Delete time stamp", alias="deleteTime")
    display_name: Optional[StrictStr] = Field(default=None, description="User-settable and human-readable display name for the Cluster.", alias="displayName")
    encryption_config: Optional[EncryptionConfig] = Field(default=None, alias="encryptionConfig")
    encryption_info: Optional[EncryptionInfo] = Field(default=None, alias="encryptionInfo")
    etag: Optional[StrictStr] = Field(default=None, description="For Resource freshness validation (https://google.aip.dev/154)")
    initial_user: Optional[UserPassword] = Field(default=None, alias="initialUser")
    labels: Optional[Dict[str, StrictStr]] = Field(default=None, description="Labels as key value pairs")
    migration_source: Optional[MigrationSource] = Field(default=None, alias="migrationSource")
    name: Optional[StrictStr] = Field(default=None, description="Output only. The name of the cluster resource with the format: * projects/{project}/locations/{region}/clusters/{cluster_id} where the cluster ID segment should satisfy the regex expression `[a-z0-9-]+`. For more details see https://google.aip.dev/122. The prefix of the cluster resource name is the name of the parent resource: * projects/{project}/locations/{region}")
    network: Optional[StrictStr] = Field(default=None, description="Required. The resource link for the VPC network in which cluster resources are created and from which they are accessible via Private IP. The network must belong to the same project as the cluster. It is specified in the form: `projects/{project}/global/networks/{network_id}`. This is required to create a cluster. Deprecated, use network_config.network instead.")
    network_config: Optional[NetworkConfig] = Field(default=None, alias="networkConfig")
    primary_config: Optional[PrimaryConfig] = Field(default=None, alias="primaryConfig")
    psc_config: Optional[PscConfig] = Field(default=None, alias="pscConfig")
    reconciling: Optional[StrictBool] = Field(default=None, description="Output only. Reconciling (https://google.aip.dev/128#reconciliation). Set to true if the current state of Cluster does not match the user's intended state, and the service is actively updating the resource to reconcile them. This can happen due to user-triggered updates or system actions like failover or maintenance.")
    satisfies_pzs: Optional[StrictBool] = Field(default=None, description="Output only. Reserved for future use.", alias="satisfiesPzs")
    secondary_config: Optional[SecondaryConfig] = Field(default=None, alias="secondaryConfig")
    ssl_config: Optional[SslConfig] = Field(default=None, alias="sslConfig")
    state: Optional[StrictStr] = Field(default=None, description="Output only. The current serving state of the cluster.")
    uid: Optional[StrictStr] = Field(default=None, description="Output only. The system-generated UID of the resource. The UID is assigned when the resource is created, and it is retained until it is deleted.")
    update_time: Optional[StrictStr] = Field(default=None, description="Output only. Update time stamp", alias="updateTime")
    __properties: ClassVar[List[str]] = ["annotations", "automatedBackupPolicy", "backupSource", "clusterType", "continuousBackupConfig", "continuousBackupInfo", "createTime", "databaseVersion", "deleteTime", "displayName", "encryptionConfig", "encryptionInfo", "etag", "initialUser", "labels", "migrationSource", "name", "network", "networkConfig", "primaryConfig", "pscConfig", "reconciling", "satisfiesPzs", "secondaryConfig", "sslConfig", "state", "uid", "updateTime"]

    @field_validator('cluster_type')
    def cluster_type_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['CLUSTER_TYPE_UNSPECIFIED', 'PRIMARY', 'SECONDARY']):
            raise ValueError("must be one of enum values ('CLUSTER_TYPE_UNSPECIFIED', 'PRIMARY', 'SECONDARY')")
        return value

    @field_validator('database_version')
    def database_version_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['DATABASE_VERSION_UNSPECIFIED', 'POSTGRES_13', 'POSTGRES_14', 'POSTGRES_15']):
            raise ValueError("must be one of enum values ('DATABASE_VERSION_UNSPECIFIED', 'POSTGRES_13', 'POSTGRES_14', 'POSTGRES_15')")
        return value

    @field_validator('state')
    def state_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['STATE_UNSPECIFIED', 'READY', 'STOPPED', 'EMPTY', 'CREATING', 'DELETING', 'FAILED', 'BOOTSTRAPPING', 'MAINTENANCE', 'PROMOTING']):
            raise ValueError("must be one of enum values ('STATE_UNSPECIFIED', 'READY', 'STOPPED', 'EMPTY', 'CREATING', 'DELETING', 'FAILED', 'BOOTSTRAPPING', 'MAINTENANCE', 'PROMOTING')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of Cluster from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        """
        excluded_fields: Set[str] = set([
            "cluster_type",
            "create_time",
            "delete_time",
            "name",
            "reconciling",
            "satisfies_pzs",
            "state",
            "uid",
            "update_time",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of automated_backup_policy
        if self.automated_backup_policy:
            _dict['automatedBackupPolicy'] = self.automated_backup_policy.to_dict()
        # override the default output from pydantic by calling `to_dict()` of backup_source
        if self.backup_source:
            _dict['backupSource'] = self.backup_source.to_dict()
        # override the default output from pydantic by calling `to_dict()` of continuous_backup_config
        if self.continuous_backup_config:
            _dict['continuousBackupConfig'] = self.continuous_backup_config.to_dict()
        # override the default output from pydantic by calling `to_dict()` of continuous_backup_info
        if self.continuous_backup_info:
            _dict['continuousBackupInfo'] = self.continuous_backup_info.to_dict()
        # override the default output from pydantic by calling `to_dict()` of encryption_config
        if self.encryption_config:
            _dict['encryptionConfig'] = self.encryption_config.to_dict()
        # override the default output from pydantic by calling `to_dict()` of encryption_info
        if self.encryption_info:
            _dict['encryptionInfo'] = self.encryption_info.to_dict()
        # override the default output from pydantic by calling `to_dict()` of initial_user
        if self.initial_user:
            _dict['initialUser'] = self.initial_user.to_dict()
        # override the default output from pydantic by calling `to_dict()` of migration_source
        if self.migration_source:
            _dict['migrationSource'] = self.migration_source.to_dict()
        # override the default output from pydantic by calling `to_dict()` of network_config
        if self.network_config:
            _dict['networkConfig'] = self.network_config.to_dict()
        # override the default output from pydantic by calling `to_dict()` of primary_config
        if self.primary_config:
            _dict['primaryConfig'] = self.primary_config.to_dict()
        # override the default output from pydantic by calling `to_dict()` of psc_config
        if self.psc_config:
            _dict['pscConfig'] = self.psc_config.to_dict()
        # override the default output from pydantic by calling `to_dict()` of secondary_config
        if self.secondary_config:
            _dict['secondaryConfig'] = self.secondary_config.to_dict()
        # override the default output from pydantic by calling `to_dict()` of ssl_config
        if self.ssl_config:
            _dict['sslConfig'] = self.ssl_config.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of Cluster from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "annotations": obj.get("annotations"),
            "automatedBackupPolicy": AutomatedBackupPolicy.from_dict(obj["automatedBackupPolicy"]) if obj.get("automatedBackupPolicy") is not None else None,
            "backupSource": BackupSource.from_dict(obj["backupSource"]) if obj.get("backupSource") is not None else None,
            "clusterType": obj.get("clusterType"),
            "continuousBackupConfig": ContinuousBackupConfig.from_dict(obj["continuousBackupConfig"]) if obj.get("continuousBackupConfig") is not None else None,
            "continuousBackupInfo": ContinuousBackupInfo.from_dict(obj["continuousBackupInfo"]) if obj.get("continuousBackupInfo") is not None else None,
            "createTime": obj.get("createTime"),
            "databaseVersion": obj.get("databaseVersion"),
            "deleteTime": obj.get("deleteTime"),
            "displayName": obj.get("displayName"),
            "encryptionConfig": EncryptionConfig.from_dict(obj["encryptionConfig"]) if obj.get("encryptionConfig") is not None else None,
            "encryptionInfo": EncryptionInfo.from_dict(obj["encryptionInfo"]) if obj.get("encryptionInfo") is not None else None,
            "etag": obj.get("etag"),
            "initialUser": UserPassword.from_dict(obj["initialUser"]) if obj.get("initialUser") is not None else None,
            "labels": obj.get("labels"),
            "migrationSource": MigrationSource.from_dict(obj["migrationSource"]) if obj.get("migrationSource") is not None else None,
            "name": obj.get("name"),
            "network": obj.get("network"),
            "networkConfig": NetworkConfig.from_dict(obj["networkConfig"]) if obj.get("networkConfig") is not None else None,
            "primaryConfig": PrimaryConfig.from_dict(obj["primaryConfig"]) if obj.get("primaryConfig") is not None else None,
            "pscConfig": PscConfig.from_dict(obj["pscConfig"]) if obj.get("pscConfig") is not None else None,
            "reconciling": obj.get("reconciling"),
            "satisfiesPzs": obj.get("satisfiesPzs"),
            "secondaryConfig": SecondaryConfig.from_dict(obj["secondaryConfig"]) if obj.get("secondaryConfig") is not None else None,
            "sslConfig": SslConfig.from_dict(obj["sslConfig"]) if obj.get("sslConfig") is not None else None,
            "state": obj.get("state"),
            "uid": obj.get("uid"),
            "updateTime": obj.get("updateTime")
        })
        return _obj


