# coding: utf-8

"""
    Google Cloud Data Catalog API

    A fully managed and highly scalable data discovery and metadata management service. 

    The version of the OpenAPI document: v1beta1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.google_cloud_datacatalog_v1beta1_big_query_date_sharded_spec import GoogleCloudDatacatalogV1beta1BigQueryDateShardedSpec
from openapi_client.models.google_cloud_datacatalog_v1beta1_big_query_table_spec import GoogleCloudDatacatalogV1beta1BigQueryTableSpec
from openapi_client.models.google_cloud_datacatalog_v1beta1_gcs_fileset_spec import GoogleCloudDatacatalogV1beta1GcsFilesetSpec
from openapi_client.models.google_cloud_datacatalog_v1beta1_schema import GoogleCloudDatacatalogV1beta1Schema
from openapi_client.models.google_cloud_datacatalog_v1beta1_system_timestamps import GoogleCloudDatacatalogV1beta1SystemTimestamps
from openapi_client.models.google_cloud_datacatalog_v1beta1_usage_signal import GoogleCloudDatacatalogV1beta1UsageSignal
from typing import Optional, Set
from typing_extensions import Self

class GoogleCloudDatacatalogV1beta1Entry(BaseModel):
    """
    Entry Metadata. A Data Catalog Entry resource represents another resource in Google Cloud Platform (such as a BigQuery dataset or a Pub/Sub topic), or outside of Google Cloud Platform. Clients can use the `linked_resource` field in the Entry resource to refer to the original resource ID of the source system. An Entry resource contains resource details, such as its schema. An Entry can also be used to attach flexible metadata, such as a Tag.
    """ # noqa: E501
    bigquery_date_sharded_spec: Optional[GoogleCloudDatacatalogV1beta1BigQueryDateShardedSpec] = Field(default=None, alias="bigqueryDateShardedSpec")
    bigquery_table_spec: Optional[GoogleCloudDatacatalogV1beta1BigQueryTableSpec] = Field(default=None, alias="bigqueryTableSpec")
    description: Optional[StrictStr] = Field(default=None, description="Entry description, which can consist of several sentences or paragraphs that describe entry contents. Default value is an empty string.")
    display_name: Optional[StrictStr] = Field(default=None, description="Display information such as title and description. A short name to identify the entry, for example, \"Analytics Data - Jan 2011\". Default value is an empty string.", alias="displayName")
    gcs_fileset_spec: Optional[GoogleCloudDatacatalogV1beta1GcsFilesetSpec] = Field(default=None, alias="gcsFilesetSpec")
    integrated_system: Optional[StrictStr] = Field(default=None, description="Output only. This field indicates the entry's source system that Data Catalog integrates with, such as BigQuery or Pub/Sub.", alias="integratedSystem")
    linked_resource: Optional[StrictStr] = Field(default=None, description="The resource this metadata entry refers to. For Google Cloud Platform resources, `linked_resource` is the [full name of the resource](https://cloud.google.com/apis/design/resource_names#full_resource_name). For example, the `linked_resource` for a table resource from BigQuery is: * //bigquery.googleapis.com/projects/projectId/datasets/datasetId/tables/tableId Output only when Entry is of type in the EntryType enum. For entries with user_specified_type, this field is optional and defaults to an empty string.", alias="linkedResource")
    name: Optional[StrictStr] = Field(default=None, description="Output only. The Data Catalog resource name of the entry in URL format. Example: * projects/{project_id}/locations/{location}/entryGroups/{entry_group_id}/entries/{entry_id} Note that this Entry and its child resources may not actually be stored in the location in this name.")
    var_schema: Optional[GoogleCloudDatacatalogV1beta1Schema] = Field(default=None, alias="schema")
    source_system_timestamps: Optional[GoogleCloudDatacatalogV1beta1SystemTimestamps] = Field(default=None, alias="sourceSystemTimestamps")
    type: Optional[StrictStr] = Field(default=None, description="The type of the entry. Only used for Entries with types in the EntryType enum.")
    usage_signal: Optional[GoogleCloudDatacatalogV1beta1UsageSignal] = Field(default=None, alias="usageSignal")
    user_specified_system: Optional[StrictStr] = Field(default=None, description="This field indicates the entry's source system that Data Catalog does not integrate with. `user_specified_system` strings must begin with a letter or underscore and can only contain letters, numbers, and underscores; are case insensitive; must be at least 1 character and at most 64 characters long.", alias="userSpecifiedSystem")
    user_specified_type: Optional[StrictStr] = Field(default=None, description="Entry type if it does not fit any of the input-allowed values listed in `EntryType` enum above. When creating an entry, users should check the enum values first, if nothing matches the entry to be created, then provide a custom value, for example \"my_special_type\". `user_specified_type` strings must begin with a letter or underscore and can only contain letters, numbers, and underscores; are case insensitive; must be at least 1 character and at most 64 characters long. Currently, only FILESET enum value is allowed. All other entries created through Data Catalog must use `user_specified_type`.", alias="userSpecifiedType")
    __properties: ClassVar[List[str]] = ["bigqueryDateShardedSpec", "bigqueryTableSpec", "description", "displayName", "gcsFilesetSpec", "integratedSystem", "linkedResource", "name", "schema", "sourceSystemTimestamps", "type", "usageSignal", "userSpecifiedSystem", "userSpecifiedType"]

    @field_validator('integrated_system')
    def integrated_system_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['INTEGRATED_SYSTEM_UNSPECIFIED', 'BIGQUERY', 'CLOUD_PUBSUB']):
            raise ValueError("must be one of enum values ('INTEGRATED_SYSTEM_UNSPECIFIED', 'BIGQUERY', 'CLOUD_PUBSUB')")
        return value

    @field_validator('type')
    def type_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['ENTRY_TYPE_UNSPECIFIED', 'TABLE', 'MODEL', 'DATA_STREAM', 'FILESET']):
            raise ValueError("must be one of enum values ('ENTRY_TYPE_UNSPECIFIED', 'TABLE', 'MODEL', 'DATA_STREAM', 'FILESET')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of GoogleCloudDatacatalogV1beta1Entry from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        """
        excluded_fields: Set[str] = set([
            "integrated_system",
            "name",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of bigquery_date_sharded_spec
        if self.bigquery_date_sharded_spec:
            _dict['bigqueryDateShardedSpec'] = self.bigquery_date_sharded_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of bigquery_table_spec
        if self.bigquery_table_spec:
            _dict['bigqueryTableSpec'] = self.bigquery_table_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of gcs_fileset_spec
        if self.gcs_fileset_spec:
            _dict['gcsFilesetSpec'] = self.gcs_fileset_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of var_schema
        if self.var_schema:
            _dict['schema'] = self.var_schema.to_dict()
        # override the default output from pydantic by calling `to_dict()` of source_system_timestamps
        if self.source_system_timestamps:
            _dict['sourceSystemTimestamps'] = self.source_system_timestamps.to_dict()
        # override the default output from pydantic by calling `to_dict()` of usage_signal
        if self.usage_signal:
            _dict['usageSignal'] = self.usage_signal.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of GoogleCloudDatacatalogV1beta1Entry from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "bigqueryDateShardedSpec": GoogleCloudDatacatalogV1beta1BigQueryDateShardedSpec.from_dict(obj["bigqueryDateShardedSpec"]) if obj.get("bigqueryDateShardedSpec") is not None else None,
            "bigqueryTableSpec": GoogleCloudDatacatalogV1beta1BigQueryTableSpec.from_dict(obj["bigqueryTableSpec"]) if obj.get("bigqueryTableSpec") is not None else None,
            "description": obj.get("description"),
            "displayName": obj.get("displayName"),
            "gcsFilesetSpec": GoogleCloudDatacatalogV1beta1GcsFilesetSpec.from_dict(obj["gcsFilesetSpec"]) if obj.get("gcsFilesetSpec") is not None else None,
            "integratedSystem": obj.get("integratedSystem"),
            "linkedResource": obj.get("linkedResource"),
            "name": obj.get("name"),
            "schema": GoogleCloudDatacatalogV1beta1Schema.from_dict(obj["schema"]) if obj.get("schema") is not None else None,
            "sourceSystemTimestamps": GoogleCloudDatacatalogV1beta1SystemTimestamps.from_dict(obj["sourceSystemTimestamps"]) if obj.get("sourceSystemTimestamps") is not None else None,
            "type": obj.get("type"),
            "usageSignal": GoogleCloudDatacatalogV1beta1UsageSignal.from_dict(obj["usageSignal"]) if obj.get("usageSignal") is not None else None,
            "userSpecifiedSystem": obj.get("userSpecifiedSystem"),
            "userSpecifiedType": obj.get("userSpecifiedType")
        })
        return _obj


