# coding: utf-8

"""
    Google Cloud Data Catalog API

    A fully managed and highly scalable data discovery and metadata management service. 

    The version of the OpenAPI document: v1beta1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.google_cloud_datacatalog_v1_big_query_date_sharded_spec import GoogleCloudDatacatalogV1BigQueryDateShardedSpec
from openapi_client.models.google_cloud_datacatalog_v1_big_query_table_spec import GoogleCloudDatacatalogV1BigQueryTableSpec
from openapi_client.models.google_cloud_datacatalog_v1_business_context import GoogleCloudDatacatalogV1BusinessContext
from openapi_client.models.google_cloud_datacatalog_v1_cloud_bigtable_system_spec import GoogleCloudDatacatalogV1CloudBigtableSystemSpec
from openapi_client.models.google_cloud_datacatalog_v1_data_source import GoogleCloudDatacatalogV1DataSource
from openapi_client.models.google_cloud_datacatalog_v1_data_source_connection_spec import GoogleCloudDatacatalogV1DataSourceConnectionSpec
from openapi_client.models.google_cloud_datacatalog_v1_database_table_spec import GoogleCloudDatacatalogV1DatabaseTableSpec
from openapi_client.models.google_cloud_datacatalog_v1_dataset_spec import GoogleCloudDatacatalogV1DatasetSpec
from openapi_client.models.google_cloud_datacatalog_v1_feature_online_store_spec import GoogleCloudDatacatalogV1FeatureOnlineStoreSpec
from openapi_client.models.google_cloud_datacatalog_v1_fileset_spec import GoogleCloudDatacatalogV1FilesetSpec
from openapi_client.models.google_cloud_datacatalog_v1_gcs_fileset_spec import GoogleCloudDatacatalogV1GcsFilesetSpec
from openapi_client.models.google_cloud_datacatalog_v1_looker_system_spec import GoogleCloudDatacatalogV1LookerSystemSpec
from openapi_client.models.google_cloud_datacatalog_v1_model_spec import GoogleCloudDatacatalogV1ModelSpec
from openapi_client.models.google_cloud_datacatalog_v1_personal_details import GoogleCloudDatacatalogV1PersonalDetails
from openapi_client.models.google_cloud_datacatalog_v1_routine_spec import GoogleCloudDatacatalogV1RoutineSpec
from openapi_client.models.google_cloud_datacatalog_v1_schema import GoogleCloudDatacatalogV1Schema
from openapi_client.models.google_cloud_datacatalog_v1_service_spec import GoogleCloudDatacatalogV1ServiceSpec
from openapi_client.models.google_cloud_datacatalog_v1_sql_database_system_spec import GoogleCloudDatacatalogV1SqlDatabaseSystemSpec
from openapi_client.models.google_cloud_datacatalog_v1_system_timestamps import GoogleCloudDatacatalogV1SystemTimestamps
from openapi_client.models.google_cloud_datacatalog_v1_usage_signal import GoogleCloudDatacatalogV1UsageSignal
from typing import Optional, Set
from typing_extensions import Self

class GoogleCloudDatacatalogV1Entry(BaseModel):
    """
    Entry metadata. A Data Catalog entry represents another resource in Google Cloud Platform (such as a BigQuery dataset or a Pub/Sub topic) or outside of it. You can use the `linked_resource` field in the entry resource to refer to the original resource ID of the source system. An entry resource contains resource details, for example, its schema. Additionally, you can attach flexible metadata to an entry in the form of a Tag.
    """ # noqa: E501
    bigquery_date_sharded_spec: Optional[GoogleCloudDatacatalogV1BigQueryDateShardedSpec] = Field(default=None, alias="bigqueryDateShardedSpec")
    bigquery_table_spec: Optional[GoogleCloudDatacatalogV1BigQueryTableSpec] = Field(default=None, alias="bigqueryTableSpec")
    business_context: Optional[GoogleCloudDatacatalogV1BusinessContext] = Field(default=None, alias="businessContext")
    cloud_bigtable_system_spec: Optional[GoogleCloudDatacatalogV1CloudBigtableSystemSpec] = Field(default=None, alias="cloudBigtableSystemSpec")
    data_source: Optional[GoogleCloudDatacatalogV1DataSource] = Field(default=None, alias="dataSource")
    data_source_connection_spec: Optional[GoogleCloudDatacatalogV1DataSourceConnectionSpec] = Field(default=None, alias="dataSourceConnectionSpec")
    database_table_spec: Optional[GoogleCloudDatacatalogV1DatabaseTableSpec] = Field(default=None, alias="databaseTableSpec")
    dataset_spec: Optional[GoogleCloudDatacatalogV1DatasetSpec] = Field(default=None, alias="datasetSpec")
    description: Optional[StrictStr] = Field(default=None, description="Entry description that can consist of several sentences or paragraphs that describe entry contents. The description must not contain Unicode non-characters as well as C0 and C1 control codes except tabs (HT), new lines (LF), carriage returns (CR), and page breaks (FF). The maximum size is 2000 bytes when encoded in UTF-8. Default value is an empty string.")
    display_name: Optional[StrictStr] = Field(default=None, description="Display name of an entry. The maximum size is 500 bytes when encoded in UTF-8. Default value is an empty string.", alias="displayName")
    feature_online_store_spec: Optional[GoogleCloudDatacatalogV1FeatureOnlineStoreSpec] = Field(default=None, alias="featureOnlineStoreSpec")
    fileset_spec: Optional[GoogleCloudDatacatalogV1FilesetSpec] = Field(default=None, alias="filesetSpec")
    fully_qualified_name: Optional[StrictStr] = Field(default=None, description="[Fully Qualified Name (FQN)](https://cloud.google.com//data-catalog/docs/fully-qualified-names) of the resource. Set automatically for entries representing resources from synced systems. Settable only during creation, and read-only later. Can be used for search and lookup of the entries. ", alias="fullyQualifiedName")
    gcs_fileset_spec: Optional[GoogleCloudDatacatalogV1GcsFilesetSpec] = Field(default=None, alias="gcsFilesetSpec")
    integrated_system: Optional[StrictStr] = Field(default=None, description="Output only. Indicates the entry's source system that Data Catalog integrates with, such as BigQuery, Pub/Sub, or Dataproc Metastore.", alias="integratedSystem")
    labels: Optional[Dict[str, StrictStr]] = Field(default=None, description="Cloud labels attached to the entry. In Data Catalog, you can create and modify labels attached only to custom entries. Synced entries have unmodifiable labels that come from the source system.")
    linked_resource: Optional[StrictStr] = Field(default=None, description="The resource this metadata entry refers to. For Google Cloud Platform resources, `linked_resource` is the [Full Resource Name] (https://cloud.google.com/apis/design/resource_names#full_resource_name). For example, the `linked_resource` for a table resource from BigQuery is: `//bigquery.googleapis.com/projects/{PROJECT_ID}/datasets/{DATASET_ID}/tables/{TABLE_ID}` Output only when the entry is one of the types in the `EntryType` enum. For entries with a `user_specified_type`, this field is optional and defaults to an empty string. The resource string must contain only letters (a-z, A-Z), numbers (0-9), underscores (_), periods (.), colons (:), slashes (/), dashes (-), and hashes (#). The maximum size is 200 bytes when encoded in UTF-8.", alias="linkedResource")
    looker_system_spec: Optional[GoogleCloudDatacatalogV1LookerSystemSpec] = Field(default=None, alias="lookerSystemSpec")
    model_spec: Optional[GoogleCloudDatacatalogV1ModelSpec] = Field(default=None, alias="modelSpec")
    name: Optional[StrictStr] = Field(default=None, description="Output only. The resource name of an entry in URL format. Note: The entry itself and its child resources might not be stored in the location specified in its name.")
    personal_details: Optional[GoogleCloudDatacatalogV1PersonalDetails] = Field(default=None, alias="personalDetails")
    routine_spec: Optional[GoogleCloudDatacatalogV1RoutineSpec] = Field(default=None, alias="routineSpec")
    var_schema: Optional[GoogleCloudDatacatalogV1Schema] = Field(default=None, alias="schema")
    service_spec: Optional[GoogleCloudDatacatalogV1ServiceSpec] = Field(default=None, alias="serviceSpec")
    source_system_timestamps: Optional[GoogleCloudDatacatalogV1SystemTimestamps] = Field(default=None, alias="sourceSystemTimestamps")
    sql_database_system_spec: Optional[GoogleCloudDatacatalogV1SqlDatabaseSystemSpec] = Field(default=None, alias="sqlDatabaseSystemSpec")
    type: Optional[StrictStr] = Field(default=None, description="The type of the entry. For details, see [`EntryType`](#entrytype).")
    usage_signal: Optional[GoogleCloudDatacatalogV1UsageSignal] = Field(default=None, alias="usageSignal")
    user_specified_system: Optional[StrictStr] = Field(default=None, description="Indicates the entry's source system that Data Catalog doesn't automatically integrate with. The `user_specified_system` string has the following limitations: * Is case insensitive. * Must begin with a letter or underscore. * Can only contain letters, numbers, and underscores. * Must be at least 1 character and at most 64 characters long.", alias="userSpecifiedSystem")
    user_specified_type: Optional[StrictStr] = Field(default=None, description="Custom entry type that doesn't match any of the values allowed for input and listed in the `EntryType` enum. When creating an entry, first check the type values in the enum. If there are no appropriate types for the new entry, provide a custom value, for example, `my_special_type`. The `user_specified_type` string has the following limitations: * Is case insensitive. * Must begin with a letter or underscore. * Can only contain letters, numbers, and underscores. * Must be at least 1 character and at most 64 characters long.", alias="userSpecifiedType")
    __properties: ClassVar[List[str]] = ["bigqueryDateShardedSpec", "bigqueryTableSpec", "businessContext", "cloudBigtableSystemSpec", "dataSource", "dataSourceConnectionSpec", "databaseTableSpec", "datasetSpec", "description", "displayName", "featureOnlineStoreSpec", "filesetSpec", "fullyQualifiedName", "gcsFilesetSpec", "integratedSystem", "labels", "linkedResource", "lookerSystemSpec", "modelSpec", "name", "personalDetails", "routineSpec", "schema", "serviceSpec", "sourceSystemTimestamps", "sqlDatabaseSystemSpec", "type", "usageSignal", "userSpecifiedSystem", "userSpecifiedType"]

    @field_validator('integrated_system')
    def integrated_system_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['INTEGRATED_SYSTEM_UNSPECIFIED', 'BIGQUERY', 'CLOUD_PUBSUB', 'DATAPROC_METASTORE', 'DATAPLEX', 'CLOUD_SPANNER', 'CLOUD_BIGTABLE', 'CLOUD_SQL', 'LOOKER', 'VERTEX_AI']):
            raise ValueError("must be one of enum values ('INTEGRATED_SYSTEM_UNSPECIFIED', 'BIGQUERY', 'CLOUD_PUBSUB', 'DATAPROC_METASTORE', 'DATAPLEX', 'CLOUD_SPANNER', 'CLOUD_BIGTABLE', 'CLOUD_SQL', 'LOOKER', 'VERTEX_AI')")
        return value

    @field_validator('type')
    def type_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['ENTRY_TYPE_UNSPECIFIED', 'TABLE', 'MODEL', 'DATA_STREAM', 'FILESET', 'CLUSTER', 'DATABASE', 'DATA_SOURCE_CONNECTION', 'ROUTINE', 'LAKE', 'ZONE', 'SERVICE', 'DATABASE_SCHEMA', 'DASHBOARD', 'EXPLORE', 'LOOK', 'FEATURE_ONLINE_STORE', 'FEATURE_VIEW', 'FEATURE_GROUP']):
            raise ValueError("must be one of enum values ('ENTRY_TYPE_UNSPECIFIED', 'TABLE', 'MODEL', 'DATA_STREAM', 'FILESET', 'CLUSTER', 'DATABASE', 'DATA_SOURCE_CONNECTION', 'ROUTINE', 'LAKE', 'ZONE', 'SERVICE', 'DATABASE_SCHEMA', 'DASHBOARD', 'EXPLORE', 'LOOK', 'FEATURE_ONLINE_STORE', 'FEATURE_VIEW', 'FEATURE_GROUP')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of GoogleCloudDatacatalogV1Entry from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        """
        excluded_fields: Set[str] = set([
            "integrated_system",
            "name",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of bigquery_date_sharded_spec
        if self.bigquery_date_sharded_spec:
            _dict['bigqueryDateShardedSpec'] = self.bigquery_date_sharded_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of bigquery_table_spec
        if self.bigquery_table_spec:
            _dict['bigqueryTableSpec'] = self.bigquery_table_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of business_context
        if self.business_context:
            _dict['businessContext'] = self.business_context.to_dict()
        # override the default output from pydantic by calling `to_dict()` of cloud_bigtable_system_spec
        if self.cloud_bigtable_system_spec:
            _dict['cloudBigtableSystemSpec'] = self.cloud_bigtable_system_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of data_source
        if self.data_source:
            _dict['dataSource'] = self.data_source.to_dict()
        # override the default output from pydantic by calling `to_dict()` of data_source_connection_spec
        if self.data_source_connection_spec:
            _dict['dataSourceConnectionSpec'] = self.data_source_connection_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of database_table_spec
        if self.database_table_spec:
            _dict['databaseTableSpec'] = self.database_table_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of dataset_spec
        if self.dataset_spec:
            _dict['datasetSpec'] = self.dataset_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of feature_online_store_spec
        if self.feature_online_store_spec:
            _dict['featureOnlineStoreSpec'] = self.feature_online_store_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of fileset_spec
        if self.fileset_spec:
            _dict['filesetSpec'] = self.fileset_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of gcs_fileset_spec
        if self.gcs_fileset_spec:
            _dict['gcsFilesetSpec'] = self.gcs_fileset_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of looker_system_spec
        if self.looker_system_spec:
            _dict['lookerSystemSpec'] = self.looker_system_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of model_spec
        if self.model_spec:
            _dict['modelSpec'] = self.model_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of personal_details
        if self.personal_details:
            _dict['personalDetails'] = self.personal_details.to_dict()
        # override the default output from pydantic by calling `to_dict()` of routine_spec
        if self.routine_spec:
            _dict['routineSpec'] = self.routine_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of var_schema
        if self.var_schema:
            _dict['schema'] = self.var_schema.to_dict()
        # override the default output from pydantic by calling `to_dict()` of service_spec
        if self.service_spec:
            _dict['serviceSpec'] = self.service_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of source_system_timestamps
        if self.source_system_timestamps:
            _dict['sourceSystemTimestamps'] = self.source_system_timestamps.to_dict()
        # override the default output from pydantic by calling `to_dict()` of sql_database_system_spec
        if self.sql_database_system_spec:
            _dict['sqlDatabaseSystemSpec'] = self.sql_database_system_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of usage_signal
        if self.usage_signal:
            _dict['usageSignal'] = self.usage_signal.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of GoogleCloudDatacatalogV1Entry from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "bigqueryDateShardedSpec": GoogleCloudDatacatalogV1BigQueryDateShardedSpec.from_dict(obj["bigqueryDateShardedSpec"]) if obj.get("bigqueryDateShardedSpec") is not None else None,
            "bigqueryTableSpec": GoogleCloudDatacatalogV1BigQueryTableSpec.from_dict(obj["bigqueryTableSpec"]) if obj.get("bigqueryTableSpec") is not None else None,
            "businessContext": GoogleCloudDatacatalogV1BusinessContext.from_dict(obj["businessContext"]) if obj.get("businessContext") is not None else None,
            "cloudBigtableSystemSpec": GoogleCloudDatacatalogV1CloudBigtableSystemSpec.from_dict(obj["cloudBigtableSystemSpec"]) if obj.get("cloudBigtableSystemSpec") is not None else None,
            "dataSource": GoogleCloudDatacatalogV1DataSource.from_dict(obj["dataSource"]) if obj.get("dataSource") is not None else None,
            "dataSourceConnectionSpec": GoogleCloudDatacatalogV1DataSourceConnectionSpec.from_dict(obj["dataSourceConnectionSpec"]) if obj.get("dataSourceConnectionSpec") is not None else None,
            "databaseTableSpec": GoogleCloudDatacatalogV1DatabaseTableSpec.from_dict(obj["databaseTableSpec"]) if obj.get("databaseTableSpec") is not None else None,
            "datasetSpec": GoogleCloudDatacatalogV1DatasetSpec.from_dict(obj["datasetSpec"]) if obj.get("datasetSpec") is not None else None,
            "description": obj.get("description"),
            "displayName": obj.get("displayName"),
            "featureOnlineStoreSpec": GoogleCloudDatacatalogV1FeatureOnlineStoreSpec.from_dict(obj["featureOnlineStoreSpec"]) if obj.get("featureOnlineStoreSpec") is not None else None,
            "filesetSpec": GoogleCloudDatacatalogV1FilesetSpec.from_dict(obj["filesetSpec"]) if obj.get("filesetSpec") is not None else None,
            "fullyQualifiedName": obj.get("fullyQualifiedName"),
            "gcsFilesetSpec": GoogleCloudDatacatalogV1GcsFilesetSpec.from_dict(obj["gcsFilesetSpec"]) if obj.get("gcsFilesetSpec") is not None else None,
            "integratedSystem": obj.get("integratedSystem"),
            "labels": obj.get("labels"),
            "linkedResource": obj.get("linkedResource"),
            "lookerSystemSpec": GoogleCloudDatacatalogV1LookerSystemSpec.from_dict(obj["lookerSystemSpec"]) if obj.get("lookerSystemSpec") is not None else None,
            "modelSpec": GoogleCloudDatacatalogV1ModelSpec.from_dict(obj["modelSpec"]) if obj.get("modelSpec") is not None else None,
            "name": obj.get("name"),
            "personalDetails": GoogleCloudDatacatalogV1PersonalDetails.from_dict(obj["personalDetails"]) if obj.get("personalDetails") is not None else None,
            "routineSpec": GoogleCloudDatacatalogV1RoutineSpec.from_dict(obj["routineSpec"]) if obj.get("routineSpec") is not None else None,
            "schema": GoogleCloudDatacatalogV1Schema.from_dict(obj["schema"]) if obj.get("schema") is not None else None,
            "serviceSpec": GoogleCloudDatacatalogV1ServiceSpec.from_dict(obj["serviceSpec"]) if obj.get("serviceSpec") is not None else None,
            "sourceSystemTimestamps": GoogleCloudDatacatalogV1SystemTimestamps.from_dict(obj["sourceSystemTimestamps"]) if obj.get("sourceSystemTimestamps") is not None else None,
            "sqlDatabaseSystemSpec": GoogleCloudDatacatalogV1SqlDatabaseSystemSpec.from_dict(obj["sqlDatabaseSystemSpec"]) if obj.get("sqlDatabaseSystemSpec") is not None else None,
            "type": obj.get("type"),
            "usageSignal": GoogleCloudDatacatalogV1UsageSignal.from_dict(obj["usageSignal"]) if obj.get("usageSignal") is not None else None,
            "userSpecifiedSystem": obj.get("userSpecifiedSystem"),
            "userSpecifiedType": obj.get("userSpecifiedType")
        })
        return _obj


