# coding: utf-8

"""
    Fitness API

    The Fitness API for managing users' fitness tracking data.

    The version of the OpenAPI document: v1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.aggregate_by import AggregateBy
from openapi_client.models.bucket_by_activity import BucketByActivity
from openapi_client.models.bucket_by_session import BucketBySession
from openapi_client.models.bucket_by_time import BucketByTime
from typing import Optional, Set
from typing_extensions import Self

class AggregateRequest(BaseModel):
    """
    Next id: 10
    """ # noqa: E501
    aggregate_by: Optional[List[AggregateBy]] = Field(default=None, description="The specification of data to be aggregated. At least one aggregateBy spec must be provided. All data that is specified will be aggregated using the same bucketing criteria. There will be one dataset in the response for every aggregateBy spec.", alias="aggregateBy")
    bucket_by_activity_segment: Optional[BucketByActivity] = Field(default=None, alias="bucketByActivitySegment")
    bucket_by_activity_type: Optional[BucketByActivity] = Field(default=None, alias="bucketByActivityType")
    bucket_by_session: Optional[BucketBySession] = Field(default=None, alias="bucketBySession")
    bucket_by_time: Optional[BucketByTime] = Field(default=None, alias="bucketByTime")
    end_time_millis: Optional[StrictStr] = Field(default=None, description="The end of a window of time. Data that intersects with this time window will be aggregated. The time is in milliseconds since epoch, inclusive. The maximum allowed difference between start_time_millis // and end_time_millis is 7776000000 (roughly 90 days).", alias="endTimeMillis")
    filtered_data_quality_standard: Optional[List[StrictStr]] = Field(default=None, description="DO NOT POPULATE THIS FIELD. It is ignored.", alias="filteredDataQualityStandard")
    start_time_millis: Optional[StrictStr] = Field(default=None, description="The start of a window of time. Data that intersects with this time window will be aggregated. The time is in milliseconds since epoch, inclusive.", alias="startTimeMillis")
    __properties: ClassVar[List[str]] = ["aggregateBy", "bucketByActivitySegment", "bucketByActivityType", "bucketBySession", "bucketByTime", "endTimeMillis", "filteredDataQualityStandard", "startTimeMillis"]

    @field_validator('filtered_data_quality_standard')
    def filtered_data_quality_standard_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        for i in value:
            if i not in set(['dataQualityUnknown', 'dataQualityBloodPressureEsh2002', 'dataQualityBloodPressureEsh2010', 'dataQualityBloodPressureAami', 'dataQualityBloodPressureBhsAA', 'dataQualityBloodPressureBhsAB', 'dataQualityBloodPressureBhsBA', 'dataQualityBloodPressureBhsBB', 'dataQualityBloodGlucoseIso151972003', 'dataQualityBloodGlucoseIso151972013']):
                raise ValueError("each list item must be one of ('dataQualityUnknown', 'dataQualityBloodPressureEsh2002', 'dataQualityBloodPressureEsh2010', 'dataQualityBloodPressureAami', 'dataQualityBloodPressureBhsAA', 'dataQualityBloodPressureBhsAB', 'dataQualityBloodPressureBhsBA', 'dataQualityBloodPressureBhsBB', 'dataQualityBloodGlucoseIso151972003', 'dataQualityBloodGlucoseIso151972013')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of AggregateRequest from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in aggregate_by (list)
        _items = []
        if self.aggregate_by:
            for _item_aggregate_by in self.aggregate_by:
                if _item_aggregate_by:
                    _items.append(_item_aggregate_by.to_dict())
            _dict['aggregateBy'] = _items
        # override the default output from pydantic by calling `to_dict()` of bucket_by_activity_segment
        if self.bucket_by_activity_segment:
            _dict['bucketByActivitySegment'] = self.bucket_by_activity_segment.to_dict()
        # override the default output from pydantic by calling `to_dict()` of bucket_by_activity_type
        if self.bucket_by_activity_type:
            _dict['bucketByActivityType'] = self.bucket_by_activity_type.to_dict()
        # override the default output from pydantic by calling `to_dict()` of bucket_by_session
        if self.bucket_by_session:
            _dict['bucketBySession'] = self.bucket_by_session.to_dict()
        # override the default output from pydantic by calling `to_dict()` of bucket_by_time
        if self.bucket_by_time:
            _dict['bucketByTime'] = self.bucket_by_time.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of AggregateRequest from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "aggregateBy": [AggregateBy.from_dict(_item) for _item in obj["aggregateBy"]] if obj.get("aggregateBy") is not None else None,
            "bucketByActivitySegment": BucketByActivity.from_dict(obj["bucketByActivitySegment"]) if obj.get("bucketByActivitySegment") is not None else None,
            "bucketByActivityType": BucketByActivity.from_dict(obj["bucketByActivityType"]) if obj.get("bucketByActivityType") is not None else None,
            "bucketBySession": BucketBySession.from_dict(obj["bucketBySession"]) if obj.get("bucketBySession") is not None else None,
            "bucketByTime": BucketByTime.from_dict(obj["bucketByTime"]) if obj.get("bucketByTime") is not None else None,
            "endTimeMillis": obj.get("endTimeMillis"),
            "filteredDataQualityStandard": obj.get("filteredDataQualityStandard"),
            "startTimeMillis": obj.get("startTimeMillis")
        })
        return _obj


