# coding: utf-8

"""
    Perspective Comment Analyzer API

    The Perspective Comment Analyzer API provides information about the potential impact of a comment on a conversation (e.g. it can provide a score for the \"toxicity\" of a comment). Users can leverage the \"SuggestCommentScore\" method to submit corrections to improve Perspective over time. Users can set the \"doNotStore\" flag to ensure that all submitted comments are automatically deleted after scores are returned.

    The version of the OpenAPI document: v1alpha1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.attribute_scores import AttributeScores
from typing import Optional, Set
from typing_extensions import Self

class AnalyzeCommentResponse(BaseModel):
    """
    The comment analysis response message.
    """ # noqa: E501
    attribute_scores: Optional[Dict[str, AttributeScores]] = Field(default=None, description="Scores for the requested attributes. The map keys are attribute names (same as the requested_attribute field in AnalyzeCommentRequest, for example \"ATTACK_ON_AUTHOR\", \"INFLAMMATORY\", etc).", alias="attributeScores")
    client_token: Optional[StrictStr] = Field(default=None, description="Same token from the original AnalyzeCommentRequest.", alias="clientToken")
    detected_languages: Optional[List[StrictStr]] = Field(default=None, description="Contains the languages detected from the text content, sorted in order of likelihood.", alias="detectedLanguages")
    languages: Optional[List[StrictStr]] = Field(default=None, description="The language(s) used by CommentAnalyzer service to choose which Model to use when analyzing the comment. Might better be called \"effective_languages\". The logic used to make the choice is as follows: if !Request.languages.empty() effective_languages = Request.languages else effective_languages = detected_languages[0]")
    __properties: ClassVar[List[str]] = ["attributeScores", "clientToken", "detectedLanguages", "languages"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of AnalyzeCommentResponse from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each value in attribute_scores (dict)
        _field_dict = {}
        if self.attribute_scores:
            for _key_attribute_scores in self.attribute_scores:
                if self.attribute_scores[_key_attribute_scores]:
                    _field_dict[_key_attribute_scores] = self.attribute_scores[_key_attribute_scores].to_dict()
            _dict['attributeScores'] = _field_dict
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of AnalyzeCommentResponse from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "attributeScores": dict(
                (_k, AttributeScores.from_dict(_v))
                for _k, _v in obj["attributeScores"].items()
            )
            if obj.get("attributeScores") is not None
            else None,
            "clientToken": obj.get("clientToken"),
            "detectedLanguages": obj.get("detectedLanguages"),
            "languages": obj.get("languages")
        })
        return _obj


