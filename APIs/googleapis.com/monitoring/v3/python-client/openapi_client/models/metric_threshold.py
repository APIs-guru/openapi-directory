# coding: utf-8

"""
    Cloud Monitoring API

    Manages your Cloud Monitoring data and configurations.

    The version of the OpenAPI document: v3
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictFloat, StrictInt, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional, Union
from openapi_client.models.aggregation import Aggregation
from openapi_client.models.forecast_options import ForecastOptions
from openapi_client.models.trigger import Trigger
from typing import Optional, Set
from typing_extensions import Self

class MetricThreshold(BaseModel):
    """
    A condition type that compares a collection of time series against a threshold.
    """ # noqa: E501
    aggregations: Optional[List[Aggregation]] = Field(default=None, description="Specifies the alignment of data points in individual time series as well as how to combine the retrieved time series together (such as when aggregating multiple streams on each resource to a single stream for each resource or when aggregating streams across all members of a group of resources). Multiple aggregations are applied in the order specified.This field is similar to the one in the ListTimeSeries request (https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.timeSeries/list). It is advisable to use the ListTimeSeries method when debugging this field.")
    comparison: Optional[StrictStr] = Field(default=None, description="The comparison to apply between the time series (indicated by filter and aggregation) and the threshold (indicated by threshold_value). The comparison is applied on each time series, with the time series on the left-hand side and the threshold on the right-hand side.Only COMPARISON_LT and COMPARISON_GT are supported currently.")
    denominator_aggregations: Optional[List[Aggregation]] = Field(default=None, description="Specifies the alignment of data points in individual time series selected by denominatorFilter as well as how to combine the retrieved time series together (such as when aggregating multiple streams on each resource to a single stream for each resource or when aggregating streams across all members of a group of resources).When computing ratios, the aggregations and denominator_aggregations fields must use the same alignment period and produce time series that have the same periodicity and labels.", alias="denominatorAggregations")
    denominator_filter: Optional[StrictStr] = Field(default=None, description="A filter (https://cloud.google.com/monitoring/api/v3/filters) that identifies a time series that should be used as the denominator of a ratio that will be compared with the threshold. If a denominator_filter is specified, the time series specified by the filter field will be used as the numerator.The filter must specify the metric type and optionally may contain restrictions on resource type, resource labels, and metric labels. This field may not exceed 2048 Unicode characters in length.", alias="denominatorFilter")
    duration: Optional[StrictStr] = Field(default=None, description="The amount of time that a time series must violate the threshold to be considered failing. Currently, only values that are a multiple of a minute--e.g., 0, 60, 120, or 300 seconds--are supported. If an invalid value is given, an error will be returned. When choosing a duration, it is useful to keep in mind the frequency of the underlying time series data (which may also be affected by any alignments specified in the aggregations field); a good duration is long enough so that a single outlier does not generate spurious alerts, but short enough that unhealthy states are detected and alerted on quickly.")
    evaluation_missing_data: Optional[StrictStr] = Field(default=None, description="A condition control that determines how metric-threshold conditions are evaluated when data stops arriving. To use this control, the value of the duration field must be greater than or equal to 60 seconds.", alias="evaluationMissingData")
    filter: Optional[StrictStr] = Field(default=None, description="Required. A filter (https://cloud.google.com/monitoring/api/v3/filters) that identifies which time series should be compared with the threshold.The filter is similar to the one that is specified in the ListTimeSeries request (https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.timeSeries/list) (that call is useful to verify the time series that will be retrieved / processed). The filter must specify the metric type and the resource type. Optionally, it can specify resource labels and metric labels. This field must not exceed 2048 Unicode characters in length.")
    forecast_options: Optional[ForecastOptions] = Field(default=None, alias="forecastOptions")
    threshold_value: Optional[Union[StrictFloat, StrictInt]] = Field(default=None, description="A value against which to compare the time series.", alias="thresholdValue")
    trigger: Optional[Trigger] = None
    __properties: ClassVar[List[str]] = ["aggregations", "comparison", "denominatorAggregations", "denominatorFilter", "duration", "evaluationMissingData", "filter", "forecastOptions", "thresholdValue", "trigger"]

    @field_validator('comparison')
    def comparison_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['COMPARISON_UNSPECIFIED', 'COMPARISON_GT', 'COMPARISON_GE', 'COMPARISON_LT', 'COMPARISON_LE', 'COMPARISON_EQ', 'COMPARISON_NE']):
            raise ValueError("must be one of enum values ('COMPARISON_UNSPECIFIED', 'COMPARISON_GT', 'COMPARISON_GE', 'COMPARISON_LT', 'COMPARISON_LE', 'COMPARISON_EQ', 'COMPARISON_NE')")
        return value

    @field_validator('evaluation_missing_data')
    def evaluation_missing_data_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['EVALUATION_MISSING_DATA_UNSPECIFIED', 'EVALUATION_MISSING_DATA_INACTIVE', 'EVALUATION_MISSING_DATA_ACTIVE', 'EVALUATION_MISSING_DATA_NO_OP']):
            raise ValueError("must be one of enum values ('EVALUATION_MISSING_DATA_UNSPECIFIED', 'EVALUATION_MISSING_DATA_INACTIVE', 'EVALUATION_MISSING_DATA_ACTIVE', 'EVALUATION_MISSING_DATA_NO_OP')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of MetricThreshold from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in aggregations (list)
        _items = []
        if self.aggregations:
            for _item_aggregations in self.aggregations:
                if _item_aggregations:
                    _items.append(_item_aggregations.to_dict())
            _dict['aggregations'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in denominator_aggregations (list)
        _items = []
        if self.denominator_aggregations:
            for _item_denominator_aggregations in self.denominator_aggregations:
                if _item_denominator_aggregations:
                    _items.append(_item_denominator_aggregations.to_dict())
            _dict['denominatorAggregations'] = _items
        # override the default output from pydantic by calling `to_dict()` of forecast_options
        if self.forecast_options:
            _dict['forecastOptions'] = self.forecast_options.to_dict()
        # override the default output from pydantic by calling `to_dict()` of trigger
        if self.trigger:
            _dict['trigger'] = self.trigger.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of MetricThreshold from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "aggregations": [Aggregation.from_dict(_item) for _item in obj["aggregations"]] if obj.get("aggregations") is not None else None,
            "comparison": obj.get("comparison"),
            "denominatorAggregations": [Aggregation.from_dict(_item) for _item in obj["denominatorAggregations"]] if obj.get("denominatorAggregations") is not None else None,
            "denominatorFilter": obj.get("denominatorFilter"),
            "duration": obj.get("duration"),
            "evaluationMissingData": obj.get("evaluationMissingData"),
            "filter": obj.get("filter"),
            "forecastOptions": ForecastOptions.from_dict(obj["forecastOptions"]) if obj.get("forecastOptions") is not None else None,
            "thresholdValue": obj.get("thresholdValue"),
            "trigger": Trigger.from_dict(obj["trigger"]) if obj.get("trigger") is not None else None
        })
        return _obj


