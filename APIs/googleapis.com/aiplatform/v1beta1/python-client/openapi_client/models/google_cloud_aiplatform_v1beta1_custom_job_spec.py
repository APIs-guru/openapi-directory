# coding: utf-8

"""
    Vertex AI API

    Train high-quality custom machine learning models with minimal machine learning expertise and effort.

    The version of the OpenAPI document: v1beta1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.google_cloud_aiplatform_v1beta1_gcs_destination import GoogleCloudAiplatformV1beta1GcsDestination
from openapi_client.models.google_cloud_aiplatform_v1beta1_scheduling import GoogleCloudAiplatformV1beta1Scheduling
from openapi_client.models.google_cloud_aiplatform_v1beta1_worker_pool_spec import GoogleCloudAiplatformV1beta1WorkerPoolSpec
from typing import Optional, Set
from typing_extensions import Self

class GoogleCloudAiplatformV1beta1CustomJobSpec(BaseModel):
    """
    Represents the spec of a CustomJob.
    """ # noqa: E501
    base_output_directory: Optional[GoogleCloudAiplatformV1beta1GcsDestination] = Field(default=None, alias="baseOutputDirectory")
    enable_dashboard_access: Optional[StrictBool] = Field(default=None, description="Optional. Whether you want Vertex AI to enable access to the customized dashboard in training chief container. If set to `true`, you can access the dashboard at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).", alias="enableDashboardAccess")
    enable_web_access: Optional[StrictBool] = Field(default=None, description="Optional. Whether you want Vertex AI to enable [interactive shell access](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell) to training containers. If set to `true`, you can access interactive shells at the URIs given by CustomJob.web_access_uris or Trial.web_access_uris (within HyperparameterTuningJob.trials).", alias="enableWebAccess")
    experiment: Optional[StrictStr] = Field(default=None, description="Optional. The Experiment associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}`")
    experiment_run: Optional[StrictStr] = Field(default=None, description="Optional. The Experiment Run associated with this job. Format: `projects/{project}/locations/{location}/metadataStores/{metadataStores}/contexts/{experiment-name}-{experiment-run-name}`", alias="experimentRun")
    models: Optional[List[StrictStr]] = Field(default=None, description="Optional. The name of the Model resources for which to generate a mapping to artifact URIs. Applicable only to some of the Google-provided custom jobs. Format: `projects/{project}/locations/{location}/models/{model}` In order to retrieve a specific version of the model, also provide the version ID or version alias. Example: `projects/{project}/locations/{location}/models/{model}@2` or `projects/{project}/locations/{location}/models/{model}@golden` If no version ID or alias is specified, the \"default\" version will be returned. The \"default\" version alias is created for the first version of the model, and can be moved to other versions later on. There will be exactly one default version.")
    network: Optional[StrictStr] = Field(default=None, description="Optional. The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Job should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. To specify this field, you must have already [configured VPC Network Peering for Vertex AI](https://cloud.google.com/vertex-ai/docs/general/vpc-peering). If this field is left unspecified, the job is not peered with any network.")
    persistent_resource_id: Optional[StrictStr] = Field(default=None, description="Optional. The ID of the PersistentResource in the same Project and Location which to run If this is specified, the job will be run on existing machines held by the PersistentResource instead of on-demand short-live machines. The network and CMEK configs on the job should be consistent with those on the PersistentResource, otherwise, the job will be rejected.", alias="persistentResourceId")
    protected_artifact_location_id: Optional[StrictStr] = Field(default=None, description="The ID of the location to store protected artifacts. e.g. us-central1. Populate only when the location is different than CustomJob location. List of supported locations: https://cloud.google.com/vertex-ai/docs/general/locations", alias="protectedArtifactLocationId")
    reserved_ip_ranges: Optional[List[StrictStr]] = Field(default=None, description="Optional. A list of names for the reserved ip ranges under the VPC network that can be used for this job. If set, we will deploy the job within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].", alias="reservedIpRanges")
    scheduling: Optional[GoogleCloudAiplatformV1beta1Scheduling] = None
    service_account: Optional[StrictStr] = Field(default=None, description="Specifies the service account for workload run-as account. Users submitting jobs must have act-as permission on this run-as account. If unspecified, the [Vertex AI Custom Code Service Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents) for the CustomJob's project is used.", alias="serviceAccount")
    tensorboard: Optional[StrictStr] = Field(default=None, description="Optional. The name of a Vertex AI Tensorboard resource to which this CustomJob will upload Tensorboard logs. Format: `projects/{project}/locations/{location}/tensorboards/{tensorboard}`")
    worker_pool_specs: Optional[List[GoogleCloudAiplatformV1beta1WorkerPoolSpec]] = Field(default=None, description="Required. The spec of the worker pools including machine type and Docker image. All worker pools except the first one are optional and can be skipped by providing an empty value.", alias="workerPoolSpecs")
    __properties: ClassVar[List[str]] = ["baseOutputDirectory", "enableDashboardAccess", "enableWebAccess", "experiment", "experimentRun", "models", "network", "persistentResourceId", "protectedArtifactLocationId", "reservedIpRanges", "scheduling", "serviceAccount", "tensorboard", "workerPoolSpecs"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of GoogleCloudAiplatformV1beta1CustomJobSpec from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of base_output_directory
        if self.base_output_directory:
            _dict['baseOutputDirectory'] = self.base_output_directory.to_dict()
        # override the default output from pydantic by calling `to_dict()` of scheduling
        if self.scheduling:
            _dict['scheduling'] = self.scheduling.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in worker_pool_specs (list)
        _items = []
        if self.worker_pool_specs:
            for _item_worker_pool_specs in self.worker_pool_specs:
                if _item_worker_pool_specs:
                    _items.append(_item_worker_pool_specs.to_dict())
            _dict['workerPoolSpecs'] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of GoogleCloudAiplatformV1beta1CustomJobSpec from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "baseOutputDirectory": GoogleCloudAiplatformV1beta1GcsDestination.from_dict(obj["baseOutputDirectory"]) if obj.get("baseOutputDirectory") is not None else None,
            "enableDashboardAccess": obj.get("enableDashboardAccess"),
            "enableWebAccess": obj.get("enableWebAccess"),
            "experiment": obj.get("experiment"),
            "experimentRun": obj.get("experimentRun"),
            "models": obj.get("models"),
            "network": obj.get("network"),
            "persistentResourceId": obj.get("persistentResourceId"),
            "protectedArtifactLocationId": obj.get("protectedArtifactLocationId"),
            "reservedIpRanges": obj.get("reservedIpRanges"),
            "scheduling": GoogleCloudAiplatformV1beta1Scheduling.from_dict(obj["scheduling"]) if obj.get("scheduling") is not None else None,
            "serviceAccount": obj.get("serviceAccount"),
            "tensorboard": obj.get("tensorboard"),
            "workerPoolSpecs": [GoogleCloudAiplatformV1beta1WorkerPoolSpec.from_dict(_item) for _item in obj["workerPoolSpecs"]] if obj.get("workerPoolSpecs") is not None else None
        })
        return _obj


