# coding: utf-8

"""
    Vertex AI API

    Train high-quality custom machine learning models with minimal machine learning expertise and effort.

    The version of the OpenAPI document: v1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.google_cloud_aiplatform_v1_batch_dedicated_resources import GoogleCloudAiplatformV1BatchDedicatedResources
from openapi_client.models.google_cloud_aiplatform_v1_batch_prediction_job_input_config import GoogleCloudAiplatformV1BatchPredictionJobInputConfig
from openapi_client.models.google_cloud_aiplatform_v1_batch_prediction_job_instance_config import GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig
from openapi_client.models.google_cloud_aiplatform_v1_batch_prediction_job_output_config import GoogleCloudAiplatformV1BatchPredictionJobOutputConfig
from openapi_client.models.google_cloud_aiplatform_v1_batch_prediction_job_output_info import GoogleCloudAiplatformV1BatchPredictionJobOutputInfo
from openapi_client.models.google_cloud_aiplatform_v1_completion_stats import GoogleCloudAiplatformV1CompletionStats
from openapi_client.models.google_cloud_aiplatform_v1_encryption_spec import GoogleCloudAiplatformV1EncryptionSpec
from openapi_client.models.google_cloud_aiplatform_v1_explanation_spec import GoogleCloudAiplatformV1ExplanationSpec
from openapi_client.models.google_cloud_aiplatform_v1_manual_batch_tuning_parameters import GoogleCloudAiplatformV1ManualBatchTuningParameters
from openapi_client.models.google_cloud_aiplatform_v1_resources_consumed import GoogleCloudAiplatformV1ResourcesConsumed
from openapi_client.models.google_cloud_aiplatform_v1_unmanaged_container_model import GoogleCloudAiplatformV1UnmanagedContainerModel
from openapi_client.models.google_rpc_status import GoogleRpcStatus
from typing import Optional, Set
from typing_extensions import Self

class GoogleCloudAiplatformV1BatchPredictionJob(BaseModel):
    """
    A job that uses a Model to produce predictions on multiple input instances. If predictions for significant portion of the instances fail, the job may finish without attempting predictions for all remaining instances.
    """ # noqa: E501
    completion_stats: Optional[GoogleCloudAiplatformV1CompletionStats] = Field(default=None, alias="completionStats")
    create_time: Optional[StrictStr] = Field(default=None, description="Output only. Time when the BatchPredictionJob was created.", alias="createTime")
    dedicated_resources: Optional[GoogleCloudAiplatformV1BatchDedicatedResources] = Field(default=None, alias="dedicatedResources")
    disable_container_logging: Optional[StrictBool] = Field(default=None, description="For custom-trained Models and AutoML Tabular Models, the container of the DeployedModel instances will send `stderr` and `stdout` streams to Cloud Logging by default. Please note that the logs incur cost, which are subject to [Cloud Logging pricing](https://cloud.google.com/logging/pricing). User can disable container logging by setting this flag to true.", alias="disableContainerLogging")
    display_name: Optional[StrictStr] = Field(default=None, description="Required. The user-defined name of this BatchPredictionJob.", alias="displayName")
    encryption_spec: Optional[GoogleCloudAiplatformV1EncryptionSpec] = Field(default=None, alias="encryptionSpec")
    end_time: Optional[StrictStr] = Field(default=None, description="Output only. Time when the BatchPredictionJob entered any of the following states: `JOB_STATE_SUCCEEDED`, `JOB_STATE_FAILED`, `JOB_STATE_CANCELLED`.", alias="endTime")
    error: Optional[GoogleRpcStatus] = None
    explanation_spec: Optional[GoogleCloudAiplatformV1ExplanationSpec] = Field(default=None, alias="explanationSpec")
    generate_explanation: Optional[StrictBool] = Field(default=None, description="Generate explanation with the batch prediction results. When set to `true`, the batch prediction output changes based on the `predictions_format` field of the BatchPredictionJob.output_config object: * `bigquery`: output includes a column named `explanation`. The value is a struct that conforms to the Explanation object. * `jsonl`: The JSON objects on each line include an additional entry keyed `explanation`. The value of the entry is a JSON object that conforms to the Explanation object. * `csv`: Generating explanations for CSV format is not supported. If this field is set to true, either the Model.explanation_spec or explanation_spec must be populated.", alias="generateExplanation")
    input_config: Optional[GoogleCloudAiplatformV1BatchPredictionJobInputConfig] = Field(default=None, alias="inputConfig")
    instance_config: Optional[GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig] = Field(default=None, alias="instanceConfig")
    labels: Optional[Dict[str, StrictStr]] = Field(default=None, description="The labels with user-defined metadata to organize BatchPredictionJobs. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.")
    manual_batch_tuning_parameters: Optional[GoogleCloudAiplatformV1ManualBatchTuningParameters] = Field(default=None, alias="manualBatchTuningParameters")
    model: Optional[StrictStr] = Field(default=None, description="The name of the Model resource that produces the predictions via this job, must share the same ancestor Location. Starting this job has no impact on any existing deployments of the Model and their resources. Exactly one of model and unmanaged_container_model must be set. The model resource name may contain version id or version alias to specify the version. Example: `projects/{project}/locations/{location}/models/{model}@2` or `projects/{project}/locations/{location}/models/{model}@golden` if no version is specified, the default version will be deployed. The model resource could also be a publisher model. Example: `publishers/{publisher}/models/{model}` or `projects/{project}/locations/{location}/publishers/{publisher}/models/{model}`")
    model_parameters: Optional[Any] = Field(default=None, description="The parameters that govern the predictions. The schema of the parameters may be specified via the Model's PredictSchemata's parameters_schema_uri.", alias="modelParameters")
    model_version_id: Optional[StrictStr] = Field(default=None, description="Output only. The version ID of the Model that produces the predictions via this job.", alias="modelVersionId")
    name: Optional[StrictStr] = Field(default=None, description="Output only. Resource name of the BatchPredictionJob.")
    output_config: Optional[GoogleCloudAiplatformV1BatchPredictionJobOutputConfig] = Field(default=None, alias="outputConfig")
    output_info: Optional[GoogleCloudAiplatformV1BatchPredictionJobOutputInfo] = Field(default=None, alias="outputInfo")
    partial_failures: Optional[List[GoogleRpcStatus]] = Field(default=None, description="Output only. Partial failures encountered. For example, single files that can't be read. This field never exceeds 20 entries. Status details fields contain standard Google Cloud error details.", alias="partialFailures")
    resources_consumed: Optional[GoogleCloudAiplatformV1ResourcesConsumed] = Field(default=None, alias="resourcesConsumed")
    service_account: Optional[StrictStr] = Field(default=None, description="The service account that the DeployedModel's container runs as. If not specified, a system generated one will be used, which has minimal permissions and the custom container, if used, may not have enough permission to access other Google Cloud resources. Users deploying the Model must have the `iam.serviceAccounts.actAs` permission on this service account.", alias="serviceAccount")
    start_time: Optional[StrictStr] = Field(default=None, description="Output only. Time when the BatchPredictionJob for the first time entered the `JOB_STATE_RUNNING` state.", alias="startTime")
    state: Optional[StrictStr] = Field(default=None, description="Output only. The detailed state of the job.")
    unmanaged_container_model: Optional[GoogleCloudAiplatformV1UnmanagedContainerModel] = Field(default=None, alias="unmanagedContainerModel")
    update_time: Optional[StrictStr] = Field(default=None, description="Output only. Time when the BatchPredictionJob was most recently updated.", alias="updateTime")
    __properties: ClassVar[List[str]] = ["completionStats", "createTime", "dedicatedResources", "disableContainerLogging", "displayName", "encryptionSpec", "endTime", "error", "explanationSpec", "generateExplanation", "inputConfig", "instanceConfig", "labels", "manualBatchTuningParameters", "model", "modelParameters", "modelVersionId", "name", "outputConfig", "outputInfo", "partialFailures", "resourcesConsumed", "serviceAccount", "startTime", "state", "unmanagedContainerModel", "updateTime"]

    @field_validator('state')
    def state_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['JOB_STATE_UNSPECIFIED', 'JOB_STATE_QUEUED', 'JOB_STATE_PENDING', 'JOB_STATE_RUNNING', 'JOB_STATE_SUCCEEDED', 'JOB_STATE_FAILED', 'JOB_STATE_CANCELLING', 'JOB_STATE_CANCELLED', 'JOB_STATE_PAUSED', 'JOB_STATE_EXPIRED', 'JOB_STATE_UPDATING', 'JOB_STATE_PARTIALLY_SUCCEEDED']):
            raise ValueError("must be one of enum values ('JOB_STATE_UNSPECIFIED', 'JOB_STATE_QUEUED', 'JOB_STATE_PENDING', 'JOB_STATE_RUNNING', 'JOB_STATE_SUCCEEDED', 'JOB_STATE_FAILED', 'JOB_STATE_CANCELLING', 'JOB_STATE_CANCELLED', 'JOB_STATE_PAUSED', 'JOB_STATE_EXPIRED', 'JOB_STATE_UPDATING', 'JOB_STATE_PARTIALLY_SUCCEEDED')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of GoogleCloudAiplatformV1BatchPredictionJob from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        """
        excluded_fields: Set[str] = set([
            "create_time",
            "end_time",
            "model_version_id",
            "name",
            "partial_failures",
            "start_time",
            "state",
            "update_time",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of completion_stats
        if self.completion_stats:
            _dict['completionStats'] = self.completion_stats.to_dict()
        # override the default output from pydantic by calling `to_dict()` of dedicated_resources
        if self.dedicated_resources:
            _dict['dedicatedResources'] = self.dedicated_resources.to_dict()
        # override the default output from pydantic by calling `to_dict()` of encryption_spec
        if self.encryption_spec:
            _dict['encryptionSpec'] = self.encryption_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of error
        if self.error:
            _dict['error'] = self.error.to_dict()
        # override the default output from pydantic by calling `to_dict()` of explanation_spec
        if self.explanation_spec:
            _dict['explanationSpec'] = self.explanation_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of input_config
        if self.input_config:
            _dict['inputConfig'] = self.input_config.to_dict()
        # override the default output from pydantic by calling `to_dict()` of instance_config
        if self.instance_config:
            _dict['instanceConfig'] = self.instance_config.to_dict()
        # override the default output from pydantic by calling `to_dict()` of manual_batch_tuning_parameters
        if self.manual_batch_tuning_parameters:
            _dict['manualBatchTuningParameters'] = self.manual_batch_tuning_parameters.to_dict()
        # override the default output from pydantic by calling `to_dict()` of output_config
        if self.output_config:
            _dict['outputConfig'] = self.output_config.to_dict()
        # override the default output from pydantic by calling `to_dict()` of output_info
        if self.output_info:
            _dict['outputInfo'] = self.output_info.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in partial_failures (list)
        _items = []
        if self.partial_failures:
            for _item_partial_failures in self.partial_failures:
                if _item_partial_failures:
                    _items.append(_item_partial_failures.to_dict())
            _dict['partialFailures'] = _items
        # override the default output from pydantic by calling `to_dict()` of resources_consumed
        if self.resources_consumed:
            _dict['resourcesConsumed'] = self.resources_consumed.to_dict()
        # override the default output from pydantic by calling `to_dict()` of unmanaged_container_model
        if self.unmanaged_container_model:
            _dict['unmanagedContainerModel'] = self.unmanaged_container_model.to_dict()
        # set to None if model_parameters (nullable) is None
        # and model_fields_set contains the field
        if self.model_parameters is None and "model_parameters" in self.model_fields_set:
            _dict['modelParameters'] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of GoogleCloudAiplatformV1BatchPredictionJob from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "completionStats": GoogleCloudAiplatformV1CompletionStats.from_dict(obj["completionStats"]) if obj.get("completionStats") is not None else None,
            "createTime": obj.get("createTime"),
            "dedicatedResources": GoogleCloudAiplatformV1BatchDedicatedResources.from_dict(obj["dedicatedResources"]) if obj.get("dedicatedResources") is not None else None,
            "disableContainerLogging": obj.get("disableContainerLogging"),
            "displayName": obj.get("displayName"),
            "encryptionSpec": GoogleCloudAiplatformV1EncryptionSpec.from_dict(obj["encryptionSpec"]) if obj.get("encryptionSpec") is not None else None,
            "endTime": obj.get("endTime"),
            "error": GoogleRpcStatus.from_dict(obj["error"]) if obj.get("error") is not None else None,
            "explanationSpec": GoogleCloudAiplatformV1ExplanationSpec.from_dict(obj["explanationSpec"]) if obj.get("explanationSpec") is not None else None,
            "generateExplanation": obj.get("generateExplanation"),
            "inputConfig": GoogleCloudAiplatformV1BatchPredictionJobInputConfig.from_dict(obj["inputConfig"]) if obj.get("inputConfig") is not None else None,
            "instanceConfig": GoogleCloudAiplatformV1BatchPredictionJobInstanceConfig.from_dict(obj["instanceConfig"]) if obj.get("instanceConfig") is not None else None,
            "labels": obj.get("labels"),
            "manualBatchTuningParameters": GoogleCloudAiplatformV1ManualBatchTuningParameters.from_dict(obj["manualBatchTuningParameters"]) if obj.get("manualBatchTuningParameters") is not None else None,
            "model": obj.get("model"),
            "modelParameters": obj.get("modelParameters"),
            "modelVersionId": obj.get("modelVersionId"),
            "name": obj.get("name"),
            "outputConfig": GoogleCloudAiplatformV1BatchPredictionJobOutputConfig.from_dict(obj["outputConfig"]) if obj.get("outputConfig") is not None else None,
            "outputInfo": GoogleCloudAiplatformV1BatchPredictionJobOutputInfo.from_dict(obj["outputInfo"]) if obj.get("outputInfo") is not None else None,
            "partialFailures": [GoogleRpcStatus.from_dict(_item) for _item in obj["partialFailures"]] if obj.get("partialFailures") is not None else None,
            "resourcesConsumed": GoogleCloudAiplatformV1ResourcesConsumed.from_dict(obj["resourcesConsumed"]) if obj.get("resourcesConsumed") is not None else None,
            "serviceAccount": obj.get("serviceAccount"),
            "startTime": obj.get("startTime"),
            "state": obj.get("state"),
            "unmanagedContainerModel": GoogleCloudAiplatformV1UnmanagedContainerModel.from_dict(obj["unmanagedContainerModel"]) if obj.get("unmanagedContainerModel") is not None else None,
            "updateTime": obj.get("updateTime")
        })
        return _obj


