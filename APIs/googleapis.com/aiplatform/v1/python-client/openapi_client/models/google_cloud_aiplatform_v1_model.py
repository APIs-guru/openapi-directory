# coding: utf-8

"""
    Vertex AI API

    Train high-quality custom machine learning models with minimal machine learning expertise and effort.

    The version of the OpenAPI document: v1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.google_cloud_aiplatform_v1_deployed_model_ref import GoogleCloudAiplatformV1DeployedModelRef
from openapi_client.models.google_cloud_aiplatform_v1_encryption_spec import GoogleCloudAiplatformV1EncryptionSpec
from openapi_client.models.google_cloud_aiplatform_v1_explanation_spec import GoogleCloudAiplatformV1ExplanationSpec
from openapi_client.models.google_cloud_aiplatform_v1_model_container_spec import GoogleCloudAiplatformV1ModelContainerSpec
from openapi_client.models.google_cloud_aiplatform_v1_model_data_stats import GoogleCloudAiplatformV1ModelDataStats
from openapi_client.models.google_cloud_aiplatform_v1_model_export_format import GoogleCloudAiplatformV1ModelExportFormat
from openapi_client.models.google_cloud_aiplatform_v1_model_original_model_info import GoogleCloudAiplatformV1ModelOriginalModelInfo
from openapi_client.models.google_cloud_aiplatform_v1_model_source_info import GoogleCloudAiplatformV1ModelSourceInfo
from openapi_client.models.google_cloud_aiplatform_v1_predict_schemata import GoogleCloudAiplatformV1PredictSchemata
from typing import Optional, Set
from typing_extensions import Self

class GoogleCloudAiplatformV1Model(BaseModel):
    """
    A trained machine learning Model.
    """ # noqa: E501
    artifact_uri: Optional[StrictStr] = Field(default=None, description="Immutable. The path to the directory containing the Model artifact and any of its supporting files. Not required for AutoML Models.", alias="artifactUri")
    container_spec: Optional[GoogleCloudAiplatformV1ModelContainerSpec] = Field(default=None, alias="containerSpec")
    create_time: Optional[StrictStr] = Field(default=None, description="Output only. Timestamp when this Model was uploaded into Vertex AI.", alias="createTime")
    data_stats: Optional[GoogleCloudAiplatformV1ModelDataStats] = Field(default=None, alias="dataStats")
    deployed_models: Optional[List[GoogleCloudAiplatformV1DeployedModelRef]] = Field(default=None, description="Output only. The pointers to DeployedModels created from this Model. Note that Model could have been deployed to Endpoints in different Locations.", alias="deployedModels")
    description: Optional[StrictStr] = Field(default=None, description="The description of the Model.")
    display_name: Optional[StrictStr] = Field(default=None, description="Required. The display name of the Model. The name can be up to 128 characters long and can consist of any UTF-8 characters.", alias="displayName")
    encryption_spec: Optional[GoogleCloudAiplatformV1EncryptionSpec] = Field(default=None, alias="encryptionSpec")
    etag: Optional[StrictStr] = Field(default=None, description="Used to perform consistent read-modify-write updates. If not set, a blind \"overwrite\" update happens.")
    explanation_spec: Optional[GoogleCloudAiplatformV1ExplanationSpec] = Field(default=None, alias="explanationSpec")
    labels: Optional[Dict[str, StrictStr]] = Field(default=None, description="The labels with user-defined metadata to organize your Models. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels.")
    metadata: Optional[Any] = Field(default=None, description="Immutable. An additional information about the Model; the schema of the metadata can be found in metadata_schema. Unset if the Model does not have any additional information.")
    metadata_artifact: Optional[StrictStr] = Field(default=None, description="Output only. The resource name of the Artifact that was created in MetadataStore when creating the Model. The Artifact resource name pattern is `projects/{project}/locations/{location}/metadataStores/{metadata_store}/artifacts/{artifact}`.", alias="metadataArtifact")
    metadata_schema_uri: Optional[StrictStr] = Field(default=None, description="Immutable. Points to a YAML file stored on Google Cloud Storage describing additional information about the Model, that is specific to it. Unset if the Model does not have any additional information. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). AutoML Models always have this field populated by Vertex AI, if no additional metadata is needed, this field is set to an empty string. Note: The URI given on output will be immutable and probably different, including the URI scheme, than the one given on input. The output URI will point to a location where the user only has a read access.", alias="metadataSchemaUri")
    model_source_info: Optional[GoogleCloudAiplatformV1ModelSourceInfo] = Field(default=None, alias="modelSourceInfo")
    name: Optional[StrictStr] = Field(default=None, description="The resource name of the Model.")
    original_model_info: Optional[GoogleCloudAiplatformV1ModelOriginalModelInfo] = Field(default=None, alias="originalModelInfo")
    pipeline_job: Optional[StrictStr] = Field(default=None, description="Optional. This field is populated if the model is produced by a pipeline job.", alias="pipelineJob")
    predict_schemata: Optional[GoogleCloudAiplatformV1PredictSchemata] = Field(default=None, alias="predictSchemata")
    supported_deployment_resources_types: Optional[List[StrictStr]] = Field(default=None, description="Output only. When this Model is deployed, its prediction resources are described by the `prediction_resources` field of the Endpoint.deployed_models object. Because not all Models support all resource configuration types, the configuration types this Model supports are listed here. If no configuration types are listed, the Model cannot be deployed to an Endpoint and does not support online predictions (PredictionService.Predict or PredictionService.Explain). Such a Model can serve predictions by using a BatchPredictionJob, if it has at least one entry each in supported_input_storage_formats and supported_output_storage_formats.", alias="supportedDeploymentResourcesTypes")
    supported_export_formats: Optional[List[GoogleCloudAiplatformV1ModelExportFormat]] = Field(default=None, description="Output only. The formats in which this Model may be exported. If empty, this Model is not available for export.", alias="supportedExportFormats")
    supported_input_storage_formats: Optional[List[StrictStr]] = Field(default=None, description="Output only. The formats this Model supports in BatchPredictionJob.input_config. If PredictSchemata.instance_schema_uri exists, the instances should be given as per that schema. The possible formats are: * `jsonl` The JSON Lines format, where each instance is a single line. Uses GcsSource. * `csv` The CSV format, where each instance is a single comma-separated line. The first line in the file is the header, containing comma-separated field names. Uses GcsSource. * `tf-record` The TFRecord format, where each instance is a single record in tfrecord syntax. Uses GcsSource. * `tf-record-gzip` Similar to `tf-record`, but the file is gzipped. Uses GcsSource. * `bigquery` Each instance is a single row in BigQuery. Uses BigQuerySource. * `file-list` Each line of the file is the location of an instance to process, uses `gcs_source` field of the InputConfig object. If this Model doesn't support any of these formats it means it cannot be used with a BatchPredictionJob. However, if it has supported_deployment_resources_types, it could serve online predictions by using PredictionService.Predict or PredictionService.Explain.", alias="supportedInputStorageFormats")
    supported_output_storage_formats: Optional[List[StrictStr]] = Field(default=None, description="Output only. The formats this Model supports in BatchPredictionJob.output_config. If both PredictSchemata.instance_schema_uri and PredictSchemata.prediction_schema_uri exist, the predictions are returned together with their instances. In other words, the prediction has the original instance data first, followed by the actual prediction content (as per the schema). The possible formats are: * `jsonl` The JSON Lines format, where each prediction is a single line. Uses GcsDestination. * `csv` The CSV format, where each prediction is a single comma-separated line. The first line in the file is the header, containing comma-separated field names. Uses GcsDestination. * `bigquery` Each prediction is a single row in a BigQuery table, uses BigQueryDestination . If this Model doesn't support any of these formats it means it cannot be used with a BatchPredictionJob. However, if it has supported_deployment_resources_types, it could serve online predictions by using PredictionService.Predict or PredictionService.Explain.", alias="supportedOutputStorageFormats")
    training_pipeline: Optional[StrictStr] = Field(default=None, description="Output only. The resource name of the TrainingPipeline that uploaded this Model, if any.", alias="trainingPipeline")
    update_time: Optional[StrictStr] = Field(default=None, description="Output only. Timestamp when this Model was most recently updated.", alias="updateTime")
    version_aliases: Optional[List[StrictStr]] = Field(default=None, description="User provided version aliases so that a model version can be referenced via alias (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_alias}` instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{model_id}@{version_id})`. The format is a-z{0,126}[a-z0-9] to distinguish from version_id. A default version alias will be created for the first version of the model, and there must be exactly one default version alias for a model.", alias="versionAliases")
    version_create_time: Optional[StrictStr] = Field(default=None, description="Output only. Timestamp when this version was created.", alias="versionCreateTime")
    version_description: Optional[StrictStr] = Field(default=None, description="The description of this version.", alias="versionDescription")
    version_id: Optional[StrictStr] = Field(default=None, description="Output only. Immutable. The version ID of the model. A new version is committed when a new model version is uploaded or trained under an existing model id. It is an auto-incrementing decimal number in string representation.", alias="versionId")
    version_update_time: Optional[StrictStr] = Field(default=None, description="Output only. Timestamp when this version was most recently updated.", alias="versionUpdateTime")
    __properties: ClassVar[List[str]] = ["artifactUri", "containerSpec", "createTime", "dataStats", "deployedModels", "description", "displayName", "encryptionSpec", "etag", "explanationSpec", "labels", "metadata", "metadataArtifact", "metadataSchemaUri", "modelSourceInfo", "name", "originalModelInfo", "pipelineJob", "predictSchemata", "supportedDeploymentResourcesTypes", "supportedExportFormats", "supportedInputStorageFormats", "supportedOutputStorageFormats", "trainingPipeline", "updateTime", "versionAliases", "versionCreateTime", "versionDescription", "versionId", "versionUpdateTime"]

    @field_validator('supported_deployment_resources_types')
    def supported_deployment_resources_types_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        for i in value:
            if i not in set(['DEPLOYMENT_RESOURCES_TYPE_UNSPECIFIED', 'DEDICATED_RESOURCES', 'AUTOMATIC_RESOURCES', 'SHARED_RESOURCES']):
                raise ValueError("each list item must be one of ('DEPLOYMENT_RESOURCES_TYPE_UNSPECIFIED', 'DEDICATED_RESOURCES', 'AUTOMATIC_RESOURCES', 'SHARED_RESOURCES')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of GoogleCloudAiplatformV1Model from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        """
        excluded_fields: Set[str] = set([
            "create_time",
            "deployed_models",
            "metadata_artifact",
            "supported_deployment_resources_types",
            "supported_export_formats",
            "supported_input_storage_formats",
            "supported_output_storage_formats",
            "training_pipeline",
            "update_time",
            "version_create_time",
            "version_id",
            "version_update_time",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of container_spec
        if self.container_spec:
            _dict['containerSpec'] = self.container_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of data_stats
        if self.data_stats:
            _dict['dataStats'] = self.data_stats.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in deployed_models (list)
        _items = []
        if self.deployed_models:
            for _item_deployed_models in self.deployed_models:
                if _item_deployed_models:
                    _items.append(_item_deployed_models.to_dict())
            _dict['deployedModels'] = _items
        # override the default output from pydantic by calling `to_dict()` of encryption_spec
        if self.encryption_spec:
            _dict['encryptionSpec'] = self.encryption_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of explanation_spec
        if self.explanation_spec:
            _dict['explanationSpec'] = self.explanation_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of model_source_info
        if self.model_source_info:
            _dict['modelSourceInfo'] = self.model_source_info.to_dict()
        # override the default output from pydantic by calling `to_dict()` of original_model_info
        if self.original_model_info:
            _dict['originalModelInfo'] = self.original_model_info.to_dict()
        # override the default output from pydantic by calling `to_dict()` of predict_schemata
        if self.predict_schemata:
            _dict['predictSchemata'] = self.predict_schemata.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in supported_export_formats (list)
        _items = []
        if self.supported_export_formats:
            for _item_supported_export_formats in self.supported_export_formats:
                if _item_supported_export_formats:
                    _items.append(_item_supported_export_formats.to_dict())
            _dict['supportedExportFormats'] = _items
        # set to None if metadata (nullable) is None
        # and model_fields_set contains the field
        if self.metadata is None and "metadata" in self.model_fields_set:
            _dict['metadata'] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of GoogleCloudAiplatformV1Model from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "artifactUri": obj.get("artifactUri"),
            "containerSpec": GoogleCloudAiplatformV1ModelContainerSpec.from_dict(obj["containerSpec"]) if obj.get("containerSpec") is not None else None,
            "createTime": obj.get("createTime"),
            "dataStats": GoogleCloudAiplatformV1ModelDataStats.from_dict(obj["dataStats"]) if obj.get("dataStats") is not None else None,
            "deployedModels": [GoogleCloudAiplatformV1DeployedModelRef.from_dict(_item) for _item in obj["deployedModels"]] if obj.get("deployedModels") is not None else None,
            "description": obj.get("description"),
            "displayName": obj.get("displayName"),
            "encryptionSpec": GoogleCloudAiplatformV1EncryptionSpec.from_dict(obj["encryptionSpec"]) if obj.get("encryptionSpec") is not None else None,
            "etag": obj.get("etag"),
            "explanationSpec": GoogleCloudAiplatformV1ExplanationSpec.from_dict(obj["explanationSpec"]) if obj.get("explanationSpec") is not None else None,
            "labels": obj.get("labels"),
            "metadata": obj.get("metadata"),
            "metadataArtifact": obj.get("metadataArtifact"),
            "metadataSchemaUri": obj.get("metadataSchemaUri"),
            "modelSourceInfo": GoogleCloudAiplatformV1ModelSourceInfo.from_dict(obj["modelSourceInfo"]) if obj.get("modelSourceInfo") is not None else None,
            "name": obj.get("name"),
            "originalModelInfo": GoogleCloudAiplatformV1ModelOriginalModelInfo.from_dict(obj["originalModelInfo"]) if obj.get("originalModelInfo") is not None else None,
            "pipelineJob": obj.get("pipelineJob"),
            "predictSchemata": GoogleCloudAiplatformV1PredictSchemata.from_dict(obj["predictSchemata"]) if obj.get("predictSchemata") is not None else None,
            "supportedDeploymentResourcesTypes": obj.get("supportedDeploymentResourcesTypes"),
            "supportedExportFormats": [GoogleCloudAiplatformV1ModelExportFormat.from_dict(_item) for _item in obj["supportedExportFormats"]] if obj.get("supportedExportFormats") is not None else None,
            "supportedInputStorageFormats": obj.get("supportedInputStorageFormats"),
            "supportedOutputStorageFormats": obj.get("supportedOutputStorageFormats"),
            "trainingPipeline": obj.get("trainingPipeline"),
            "updateTime": obj.get("updateTime"),
            "versionAliases": obj.get("versionAliases"),
            "versionCreateTime": obj.get("versionCreateTime"),
            "versionDescription": obj.get("versionDescription"),
            "versionId": obj.get("versionId"),
            "versionUpdateTime": obj.get("versionUpdateTime")
        })
        return _obj


