# coding: utf-8

"""
    Vertex AI API

    Train high-quality custom machine learning models with minimal machine learning expertise and effort.

    The version of the OpenAPI document: v1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.google_cloud_aiplatform_v1_create_pipeline_job_request import GoogleCloudAiplatformV1CreatePipelineJobRequest
from openapi_client.models.google_cloud_aiplatform_v1_schedule_run_response import GoogleCloudAiplatformV1ScheduleRunResponse
from typing import Optional, Set
from typing_extensions import Self

class GoogleCloudAiplatformV1Schedule(BaseModel):
    """
    An instance of a Schedule periodically schedules runs to make API calls based on user specified time specification and API request type.
    """ # noqa: E501
    allow_queueing: Optional[StrictBool] = Field(default=None, description="Optional. Whether new scheduled runs can be queued when max_concurrent_runs limit is reached. If set to true, new runs will be queued instead of skipped. Default to false.", alias="allowQueueing")
    catch_up: Optional[StrictBool] = Field(default=None, description="Output only. Whether to backfill missed runs when the schedule is resumed from PAUSED state. If set to true, all missed runs will be scheduled. New runs will be scheduled after the backfill is complete. Default to false.", alias="catchUp")
    create_pipeline_job_request: Optional[GoogleCloudAiplatformV1CreatePipelineJobRequest] = Field(default=None, alias="createPipelineJobRequest")
    create_time: Optional[StrictStr] = Field(default=None, description="Output only. Timestamp when this Schedule was created.", alias="createTime")
    cron: Optional[StrictStr] = Field(default=None, description="Cron schedule (https://en.wikipedia.org/wiki/Cron) to launch scheduled runs. To explicitly set a timezone to the cron tab, apply a prefix in the cron tab: \"CRON_TZ=${IANA_TIME_ZONE}\" or \"TZ=${IANA_TIME_ZONE}\". The ${IANA_TIME_ZONE} may only be a valid string from IANA time zone database. For example, \"CRON_TZ=America/New_York 1 * * * *\", or \"TZ=America/New_York 1 * * * *\".")
    display_name: Optional[StrictStr] = Field(default=None, description="Required. User provided name of the Schedule. The name can be up to 128 characters long and can consist of any UTF-8 characters.", alias="displayName")
    end_time: Optional[StrictStr] = Field(default=None, description="Optional. Timestamp after which no new runs can be scheduled. If specified, The schedule will be completed when either end_time is reached or when scheduled_run_count >= max_run_count. If not specified, new runs will keep getting scheduled until this Schedule is paused or deleted. Already scheduled runs will be allowed to complete. Unset if not specified.", alias="endTime")
    last_pause_time: Optional[StrictStr] = Field(default=None, description="Output only. Timestamp when this Schedule was last paused. Unset if never paused.", alias="lastPauseTime")
    last_resume_time: Optional[StrictStr] = Field(default=None, description="Output only. Timestamp when this Schedule was last resumed. Unset if never resumed from pause.", alias="lastResumeTime")
    last_scheduled_run_response: Optional[GoogleCloudAiplatformV1ScheduleRunResponse] = Field(default=None, alias="lastScheduledRunResponse")
    max_concurrent_run_count: Optional[StrictStr] = Field(default=None, description="Required. Maximum number of runs that can be started concurrently for this Schedule. This is the limit for starting the scheduled requests and not the execution of the operations/jobs created by the requests (if applicable).", alias="maxConcurrentRunCount")
    max_run_count: Optional[StrictStr] = Field(default=None, description="Optional. Maximum run count of the schedule. If specified, The schedule will be completed when either started_run_count >= max_run_count or when end_time is reached. If not specified, new runs will keep getting scheduled until this Schedule is paused or deleted. Already scheduled runs will be allowed to complete. Unset if not specified.", alias="maxRunCount")
    name: Optional[StrictStr] = Field(default=None, description="Immutable. The resource name of the Schedule.")
    next_run_time: Optional[StrictStr] = Field(default=None, description="Output only. Timestamp when this Schedule should schedule the next run. Having a next_run_time in the past means the runs are being started behind schedule.", alias="nextRunTime")
    start_time: Optional[StrictStr] = Field(default=None, description="Optional. Timestamp after which the first run can be scheduled. Default to Schedule create time if not specified.", alias="startTime")
    started_run_count: Optional[StrictStr] = Field(default=None, description="Output only. The number of runs started by this schedule.", alias="startedRunCount")
    state: Optional[StrictStr] = Field(default=None, description="Output only. The state of this Schedule.")
    update_time: Optional[StrictStr] = Field(default=None, description="Output only. Timestamp when this Schedule was updated.", alias="updateTime")
    __properties: ClassVar[List[str]] = ["allowQueueing", "catchUp", "createPipelineJobRequest", "createTime", "cron", "displayName", "endTime", "lastPauseTime", "lastResumeTime", "lastScheduledRunResponse", "maxConcurrentRunCount", "maxRunCount", "name", "nextRunTime", "startTime", "startedRunCount", "state", "updateTime"]

    @field_validator('state')
    def state_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['STATE_UNSPECIFIED', 'ACTIVE', 'PAUSED', 'COMPLETED']):
            raise ValueError("must be one of enum values ('STATE_UNSPECIFIED', 'ACTIVE', 'PAUSED', 'COMPLETED')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of GoogleCloudAiplatformV1Schedule from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        """
        excluded_fields: Set[str] = set([
            "catch_up",
            "create_time",
            "last_pause_time",
            "last_resume_time",
            "next_run_time",
            "started_run_count",
            "state",
            "update_time",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of create_pipeline_job_request
        if self.create_pipeline_job_request:
            _dict['createPipelineJobRequest'] = self.create_pipeline_job_request.to_dict()
        # override the default output from pydantic by calling `to_dict()` of last_scheduled_run_response
        if self.last_scheduled_run_response:
            _dict['lastScheduledRunResponse'] = self.last_scheduled_run_response.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of GoogleCloudAiplatformV1Schedule from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "allowQueueing": obj.get("allowQueueing"),
            "catchUp": obj.get("catchUp"),
            "createPipelineJobRequest": GoogleCloudAiplatformV1CreatePipelineJobRequest.from_dict(obj["createPipelineJobRequest"]) if obj.get("createPipelineJobRequest") is not None else None,
            "createTime": obj.get("createTime"),
            "cron": obj.get("cron"),
            "displayName": obj.get("displayName"),
            "endTime": obj.get("endTime"),
            "lastPauseTime": obj.get("lastPauseTime"),
            "lastResumeTime": obj.get("lastResumeTime"),
            "lastScheduledRunResponse": GoogleCloudAiplatformV1ScheduleRunResponse.from_dict(obj["lastScheduledRunResponse"]) if obj.get("lastScheduledRunResponse") is not None else None,
            "maxConcurrentRunCount": obj.get("maxConcurrentRunCount"),
            "maxRunCount": obj.get("maxRunCount"),
            "name": obj.get("name"),
            "nextRunTime": obj.get("nextRunTime"),
            "startTime": obj.get("startTime"),
            "startedRunCount": obj.get("startedRunCount"),
            "state": obj.get("state"),
            "updateTime": obj.get("updateTime")
        })
        return _obj


