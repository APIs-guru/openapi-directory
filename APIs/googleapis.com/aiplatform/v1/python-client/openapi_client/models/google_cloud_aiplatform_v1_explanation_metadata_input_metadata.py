# coding: utf-8

"""
    Vertex AI API

    Train high-quality custom machine learning models with minimal machine learning expertise and effort.

    The version of the OpenAPI document: v1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.google_cloud_aiplatform_v1_explanation_metadata_input_metadata_feature_value_domain import GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain
from openapi_client.models.google_cloud_aiplatform_v1_explanation_metadata_input_metadata_visualization import GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization
from typing import Optional, Set
from typing_extensions import Self

class GoogleCloudAiplatformV1ExplanationMetadataInputMetadata(BaseModel):
    """
    Metadata of the input of a feature. Fields other than InputMetadata.input_baselines are applicable only for Models that are using Vertex AI-provided images for Tensorflow.
    """ # noqa: E501
    dense_shape_tensor_name: Optional[StrictStr] = Field(default=None, description="Specifies the shape of the values of the input if the input is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.", alias="denseShapeTensorName")
    encoded_baselines: Optional[List[Any]] = Field(default=None, description="A list of baselines for the encoded tensor. The shape of each baseline should match the shape of the encoded tensor. If a scalar is provided, Vertex AI broadcasts to the same shape as the encoded tensor.", alias="encodedBaselines")
    encoded_tensor_name: Optional[StrictStr] = Field(default=None, description="Encoded tensor is a transformation of the input tensor. Must be provided if choosing Integrated Gradients attribution or XRAI attribution and the input tensor is not differentiable. An encoded tensor is generated if the input tensor is encoded by a lookup table.", alias="encodedTensorName")
    encoding: Optional[StrictStr] = Field(default=None, description="Defines how the feature is encoded into the input tensor. Defaults to IDENTITY.")
    feature_value_domain: Optional[GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain] = Field(default=None, alias="featureValueDomain")
    group_name: Optional[StrictStr] = Field(default=None, description="Name of the group that the input belongs to. Features with the same group name will be treated as one feature when computing attributions. Features grouped together can have different shapes in value. If provided, there will be one single attribution generated in Attribution.feature_attributions, keyed by the group name.", alias="groupName")
    index_feature_mapping: Optional[List[StrictStr]] = Field(default=None, description="A list of feature names for each index in the input tensor. Required when the input InputMetadata.encoding is BAG_OF_FEATURES, BAG_OF_FEATURES_SPARSE, INDICATOR.", alias="indexFeatureMapping")
    indices_tensor_name: Optional[StrictStr] = Field(default=None, description="Specifies the index of the values of the input tensor. Required when the input tensor is a sparse representation. Refer to Tensorflow documentation for more details: https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor.", alias="indicesTensorName")
    input_baselines: Optional[List[Any]] = Field(default=None, description="Baseline inputs for this feature. If no baseline is specified, Vertex AI chooses the baseline for this feature. If multiple baselines are specified, Vertex AI returns the average attributions across them in Attribution.feature_attributions. For Vertex AI-provided Tensorflow images (both 1.x and 2.x), the shape of each baseline must match the shape of the input tensor. If a scalar is provided, we broadcast to the same shape as the input tensor. For custom images, the element of the baselines must be in the same format as the feature's input in the instance[]. The schema of any single instance may be specified via Endpoint's DeployedModels' Model's PredictSchemata's instance_schema_uri.", alias="inputBaselines")
    input_tensor_name: Optional[StrictStr] = Field(default=None, description="Name of the input tensor for this feature. Required and is only applicable to Vertex AI-provided images for Tensorflow.", alias="inputTensorName")
    modality: Optional[StrictStr] = Field(default=None, description="Modality of the feature. Valid values are: numeric, image. Defaults to numeric.")
    visualization: Optional[GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization] = None
    __properties: ClassVar[List[str]] = ["denseShapeTensorName", "encodedBaselines", "encodedTensorName", "encoding", "featureValueDomain", "groupName", "indexFeatureMapping", "indicesTensorName", "inputBaselines", "inputTensorName", "modality", "visualization"]

    @field_validator('encoding')
    def encoding_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['ENCODING_UNSPECIFIED', 'IDENTITY', 'BAG_OF_FEATURES', 'BAG_OF_FEATURES_SPARSE', 'INDICATOR', 'COMBINED_EMBEDDING', 'CONCAT_EMBEDDING']):
            raise ValueError("must be one of enum values ('ENCODING_UNSPECIFIED', 'IDENTITY', 'BAG_OF_FEATURES', 'BAG_OF_FEATURES_SPARSE', 'INDICATOR', 'COMBINED_EMBEDDING', 'CONCAT_EMBEDDING')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of GoogleCloudAiplatformV1ExplanationMetadataInputMetadata from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of feature_value_domain
        if self.feature_value_domain:
            _dict['featureValueDomain'] = self.feature_value_domain.to_dict()
        # override the default output from pydantic by calling `to_dict()` of visualization
        if self.visualization:
            _dict['visualization'] = self.visualization.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of GoogleCloudAiplatformV1ExplanationMetadataInputMetadata from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "denseShapeTensorName": obj.get("denseShapeTensorName"),
            "encodedBaselines": obj.get("encodedBaselines"),
            "encodedTensorName": obj.get("encodedTensorName"),
            "encoding": obj.get("encoding"),
            "featureValueDomain": GoogleCloudAiplatformV1ExplanationMetadataInputMetadataFeatureValueDomain.from_dict(obj["featureValueDomain"]) if obj.get("featureValueDomain") is not None else None,
            "groupName": obj.get("groupName"),
            "indexFeatureMapping": obj.get("indexFeatureMapping"),
            "indicesTensorName": obj.get("indicesTensorName"),
            "inputBaselines": obj.get("inputBaselines"),
            "inputTensorName": obj.get("inputTensorName"),
            "modality": obj.get("modality"),
            "visualization": GoogleCloudAiplatformV1ExplanationMetadataInputMetadataVisualization.from_dict(obj["visualization"]) if obj.get("visualization") is not None else None
        })
        return _obj


