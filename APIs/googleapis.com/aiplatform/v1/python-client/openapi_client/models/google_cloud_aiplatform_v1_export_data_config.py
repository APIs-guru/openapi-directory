# coding: utf-8

"""
    Vertex AI API

    Train high-quality custom machine learning models with minimal machine learning expertise and effort.

    The version of the OpenAPI document: v1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.google_cloud_aiplatform_v1_export_filter_split import GoogleCloudAiplatformV1ExportFilterSplit
from openapi_client.models.google_cloud_aiplatform_v1_export_fraction_split import GoogleCloudAiplatformV1ExportFractionSplit
from openapi_client.models.google_cloud_aiplatform_v1_gcs_destination import GoogleCloudAiplatformV1GcsDestination
from typing import Optional, Set
from typing_extensions import Self

class GoogleCloudAiplatformV1ExportDataConfig(BaseModel):
    """
    Describes what part of the Dataset is to be exported, the destination of the export and how to export.
    """ # noqa: E501
    annotation_schema_uri: Optional[StrictStr] = Field(default=None, description="The Cloud Storage URI that points to a YAML file describing the annotation schema. The schema is defined as an OpenAPI 3.0.2 [Schema Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject). The schema files that can be used here are found in gs://google-cloud-aiplatform/schema/dataset/annotation/, note that the chosen schema must be consistent with metadata of the Dataset specified by dataset_id. Only used for custom training data export use cases. Only applicable to Datasets that have DataItems and Annotations. Only Annotations that both match this schema and belong to DataItems not ignored by the split method are used in respectively training, validation or test role, depending on the role of the DataItem they are on. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both annotations_filter and annotation_schema_uri.", alias="annotationSchemaUri")
    annotations_filter: Optional[StrictStr] = Field(default=None, description="An expression for filtering what part of the Dataset is to be exported. Only Annotations that match this filter will be exported. The filter syntax is the same as in ListAnnotations.", alias="annotationsFilter")
    export_use: Optional[StrictStr] = Field(default=None, description="Indicates the usage of the exported files.", alias="exportUse")
    filter_split: Optional[GoogleCloudAiplatformV1ExportFilterSplit] = Field(default=None, alias="filterSplit")
    fraction_split: Optional[GoogleCloudAiplatformV1ExportFractionSplit] = Field(default=None, alias="fractionSplit")
    gcs_destination: Optional[GoogleCloudAiplatformV1GcsDestination] = Field(default=None, alias="gcsDestination")
    saved_query_id: Optional[StrictStr] = Field(default=None, description="The ID of a SavedQuery (annotation set) under the Dataset specified by dataset_id used for filtering Annotations for training. Only used for custom training data export use cases. Only applicable to Datasets that have SavedQueries. Only Annotations that are associated with this SavedQuery are used in respectively training. When used in conjunction with annotations_filter, the Annotations used for training are filtered by both saved_query_id and annotations_filter. Only one of saved_query_id and annotation_schema_uri should be specified as both of them represent the same thing: problem type.", alias="savedQueryId")
    __properties: ClassVar[List[str]] = ["annotationSchemaUri", "annotationsFilter", "exportUse", "filterSplit", "fractionSplit", "gcsDestination", "savedQueryId"]

    @field_validator('export_use')
    def export_use_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['EXPORT_USE_UNSPECIFIED', 'CUSTOM_CODE_TRAINING']):
            raise ValueError("must be one of enum values ('EXPORT_USE_UNSPECIFIED', 'CUSTOM_CODE_TRAINING')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of GoogleCloudAiplatformV1ExportDataConfig from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of filter_split
        if self.filter_split:
            _dict['filterSplit'] = self.filter_split.to_dict()
        # override the default output from pydantic by calling `to_dict()` of fraction_split
        if self.fraction_split:
            _dict['fractionSplit'] = self.fraction_split.to_dict()
        # override the default output from pydantic by calling `to_dict()` of gcs_destination
        if self.gcs_destination:
            _dict['gcsDestination'] = self.gcs_destination.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of GoogleCloudAiplatformV1ExportDataConfig from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "annotationSchemaUri": obj.get("annotationSchemaUri"),
            "annotationsFilter": obj.get("annotationsFilter"),
            "exportUse": obj.get("exportUse"),
            "filterSplit": GoogleCloudAiplatformV1ExportFilterSplit.from_dict(obj["filterSplit"]) if obj.get("filterSplit") is not None else None,
            "fractionSplit": GoogleCloudAiplatformV1ExportFractionSplit.from_dict(obj["fractionSplit"]) if obj.get("fractionSplit") is not None else None,
            "gcsDestination": GoogleCloudAiplatformV1GcsDestination.from_dict(obj["gcsDestination"]) if obj.get("gcsDestination") is not None else None,
            "savedQueryId": obj.get("savedQueryId")
        })
        return _obj


