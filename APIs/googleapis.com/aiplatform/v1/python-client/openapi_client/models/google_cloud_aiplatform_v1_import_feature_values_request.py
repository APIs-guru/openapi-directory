# coding: utf-8

"""
    Vertex AI API

    Train high-quality custom machine learning models with minimal machine learning expertise and effort.

    The version of the OpenAPI document: v1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictInt, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.google_cloud_aiplatform_v1_avro_source import GoogleCloudAiplatformV1AvroSource
from openapi_client.models.google_cloud_aiplatform_v1_big_query_source import GoogleCloudAiplatformV1BigQuerySource
from openapi_client.models.google_cloud_aiplatform_v1_csv_source import GoogleCloudAiplatformV1CsvSource
from openapi_client.models.google_cloud_aiplatform_v1_import_feature_values_request_feature_spec import GoogleCloudAiplatformV1ImportFeatureValuesRequestFeatureSpec
from typing import Optional, Set
from typing_extensions import Self

class GoogleCloudAiplatformV1ImportFeatureValuesRequest(BaseModel):
    """
    Request message for FeaturestoreService.ImportFeatureValues.
    """ # noqa: E501
    avro_source: Optional[GoogleCloudAiplatformV1AvroSource] = Field(default=None, alias="avroSource")
    bigquery_source: Optional[GoogleCloudAiplatformV1BigQuerySource] = Field(default=None, alias="bigquerySource")
    csv_source: Optional[GoogleCloudAiplatformV1CsvSource] = Field(default=None, alias="csvSource")
    disable_ingestion_analysis: Optional[StrictBool] = Field(default=None, description="If true, API doesn't start ingestion analysis pipeline.", alias="disableIngestionAnalysis")
    disable_online_serving: Optional[StrictBool] = Field(default=None, description="If set, data will not be imported for online serving. This is typically used for backfilling, where Feature generation timestamps are not in the timestamp range needed for online serving.", alias="disableOnlineServing")
    entity_id_field: Optional[StrictStr] = Field(default=None, description="Source column that holds entity IDs. If not provided, entity IDs are extracted from the column named entity_id.", alias="entityIdField")
    feature_specs: Optional[List[GoogleCloudAiplatformV1ImportFeatureValuesRequestFeatureSpec]] = Field(default=None, description="Required. Specifications defining which Feature values to import from the entity. The request fails if no feature_specs are provided, and having multiple feature_specs for one Feature is not allowed.", alias="featureSpecs")
    feature_time: Optional[StrictStr] = Field(default=None, description="Single Feature timestamp for all entities being imported. The timestamp must not have higher than millisecond precision.", alias="featureTime")
    feature_time_field: Optional[StrictStr] = Field(default=None, description="Source column that holds the Feature timestamp for all Feature values in each entity.", alias="featureTimeField")
    worker_count: Optional[StrictInt] = Field(default=None, description="Specifies the number of workers that are used to write data to the Featurestore. Consider the online serving capacity that you require to achieve the desired import throughput without interfering with online serving. The value must be positive, and less than or equal to 100. If not set, defaults to using 1 worker. The low count ensures minimal impact on online serving performance.", alias="workerCount")
    __properties: ClassVar[List[str]] = ["avroSource", "bigquerySource", "csvSource", "disableIngestionAnalysis", "disableOnlineServing", "entityIdField", "featureSpecs", "featureTime", "featureTimeField", "workerCount"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of GoogleCloudAiplatformV1ImportFeatureValuesRequest from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of avro_source
        if self.avro_source:
            _dict['avroSource'] = self.avro_source.to_dict()
        # override the default output from pydantic by calling `to_dict()` of bigquery_source
        if self.bigquery_source:
            _dict['bigquerySource'] = self.bigquery_source.to_dict()
        # override the default output from pydantic by calling `to_dict()` of csv_source
        if self.csv_source:
            _dict['csvSource'] = self.csv_source.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in feature_specs (list)
        _items = []
        if self.feature_specs:
            for _item_feature_specs in self.feature_specs:
                if _item_feature_specs:
                    _items.append(_item_feature_specs.to_dict())
            _dict['featureSpecs'] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of GoogleCloudAiplatformV1ImportFeatureValuesRequest from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "avroSource": GoogleCloudAiplatformV1AvroSource.from_dict(obj["avroSource"]) if obj.get("avroSource") is not None else None,
            "bigquerySource": GoogleCloudAiplatformV1BigQuerySource.from_dict(obj["bigquerySource"]) if obj.get("bigquerySource") is not None else None,
            "csvSource": GoogleCloudAiplatformV1CsvSource.from_dict(obj["csvSource"]) if obj.get("csvSource") is not None else None,
            "disableIngestionAnalysis": obj.get("disableIngestionAnalysis"),
            "disableOnlineServing": obj.get("disableOnlineServing"),
            "entityIdField": obj.get("entityIdField"),
            "featureSpecs": [GoogleCloudAiplatformV1ImportFeatureValuesRequestFeatureSpec.from_dict(_item) for _item in obj["featureSpecs"]] if obj.get("featureSpecs") is not None else None,
            "featureTime": obj.get("featureTime"),
            "featureTimeField": obj.get("featureTimeField"),
            "workerCount": obj.get("workerCount")
        })
        return _obj


