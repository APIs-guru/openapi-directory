# coding: utf-8

"""
    Vertex AI API

    Train high-quality custom machine learning models with minimal machine learning expertise and effort.

    The version of the OpenAPI document: v1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.google_cloud_aiplatform_v1_encryption_spec import GoogleCloudAiplatformV1EncryptionSpec
from openapi_client.models.google_cloud_aiplatform_v1_pipeline_job_detail import GoogleCloudAiplatformV1PipelineJobDetail
from openapi_client.models.google_cloud_aiplatform_v1_pipeline_job_runtime_config import GoogleCloudAiplatformV1PipelineJobRuntimeConfig
from openapi_client.models.google_cloud_aiplatform_v1_pipeline_template_metadata import GoogleCloudAiplatformV1PipelineTemplateMetadata
from openapi_client.models.google_rpc_status import GoogleRpcStatus
from typing import Optional, Set
from typing_extensions import Self

class GoogleCloudAiplatformV1PipelineJob(BaseModel):
    """
    An instance of a machine learning PipelineJob.
    """ # noqa: E501
    create_time: Optional[StrictStr] = Field(default=None, description="Output only. Pipeline creation time.", alias="createTime")
    display_name: Optional[StrictStr] = Field(default=None, description="The display name of the Pipeline. The name can be up to 128 characters long and can consist of any UTF-8 characters.", alias="displayName")
    encryption_spec: Optional[GoogleCloudAiplatformV1EncryptionSpec] = Field(default=None, alias="encryptionSpec")
    end_time: Optional[StrictStr] = Field(default=None, description="Output only. Pipeline end time.", alias="endTime")
    error: Optional[GoogleRpcStatus] = None
    job_detail: Optional[GoogleCloudAiplatformV1PipelineJobDetail] = Field(default=None, alias="jobDetail")
    labels: Optional[Dict[str, StrictStr]] = Field(default=None, description="The labels with user-defined metadata to organize PipelineJob. Label keys and values can be no longer than 64 characters (Unicode codepoints), can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. See https://goo.gl/xmQnxf for more information and examples of labels. Note there is some reserved label key for Vertex AI Pipelines. - `vertex-ai-pipelines-run-billing-id`, user set value will get overrided.")
    name: Optional[StrictStr] = Field(default=None, description="Output only. The resource name of the PipelineJob.")
    network: Optional[StrictStr] = Field(default=None, description="The full name of the Compute Engine [network](/compute/docs/networks-and-firewalls#networks) to which the Pipeline Job's workload should be peered. For example, `projects/12345/global/networks/myVPC`. [Format](/compute/docs/reference/rest/v1/networks/insert) is of the form `projects/{project}/global/networks/{network}`. Where {project} is a project number, as in `12345`, and {network} is a network name. Private services access must already be configured for the network. Pipeline job will apply the network configuration to the Google Cloud resources being launched, if applied, such as Vertex AI Training or Dataflow job. If left unspecified, the workload is not peered with any network.")
    pipeline_spec: Optional[Dict[str, Any]] = Field(default=None, description="The spec of the pipeline.", alias="pipelineSpec")
    reserved_ip_ranges: Optional[List[StrictStr]] = Field(default=None, description="A list of names for the reserved ip ranges under the VPC network that can be used for this Pipeline Job's workload. If set, we will deploy the Pipeline Job's workload within the provided ip ranges. Otherwise, the job will be deployed to any ip ranges under the provided VPC network. Example: ['vertex-ai-ip-range'].", alias="reservedIpRanges")
    runtime_config: Optional[GoogleCloudAiplatformV1PipelineJobRuntimeConfig] = Field(default=None, alias="runtimeConfig")
    schedule_name: Optional[StrictStr] = Field(default=None, description="Output only. The schedule resource name. Only returned if the Pipeline is created by Schedule API.", alias="scheduleName")
    service_account: Optional[StrictStr] = Field(default=None, description="The service account that the pipeline workload runs as. If not specified, the Compute Engine default service account in the project will be used. See https://cloud.google.com/compute/docs/access/service-accounts#default_service_account Users starting the pipeline must have the `iam.serviceAccounts.actAs` permission on this service account.", alias="serviceAccount")
    start_time: Optional[StrictStr] = Field(default=None, description="Output only. Pipeline start time.", alias="startTime")
    state: Optional[StrictStr] = Field(default=None, description="Output only. The detailed state of the job.")
    template_metadata: Optional[GoogleCloudAiplatformV1PipelineTemplateMetadata] = Field(default=None, alias="templateMetadata")
    template_uri: Optional[StrictStr] = Field(default=None, description="A template uri from where the PipelineJob.pipeline_spec, if empty, will be downloaded. Currently, only uri from Vertex Template Registry & Gallery is supported. Reference to https://cloud.google.com/vertex-ai/docs/pipelines/create-pipeline-template.", alias="templateUri")
    update_time: Optional[StrictStr] = Field(default=None, description="Output only. Timestamp when this PipelineJob was most recently updated.", alias="updateTime")
    __properties: ClassVar[List[str]] = ["createTime", "displayName", "encryptionSpec", "endTime", "error", "jobDetail", "labels", "name", "network", "pipelineSpec", "reservedIpRanges", "runtimeConfig", "scheduleName", "serviceAccount", "startTime", "state", "templateMetadata", "templateUri", "updateTime"]

    @field_validator('state')
    def state_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['PIPELINE_STATE_UNSPECIFIED', 'PIPELINE_STATE_QUEUED', 'PIPELINE_STATE_PENDING', 'PIPELINE_STATE_RUNNING', 'PIPELINE_STATE_SUCCEEDED', 'PIPELINE_STATE_FAILED', 'PIPELINE_STATE_CANCELLING', 'PIPELINE_STATE_CANCELLED', 'PIPELINE_STATE_PAUSED']):
            raise ValueError("must be one of enum values ('PIPELINE_STATE_UNSPECIFIED', 'PIPELINE_STATE_QUEUED', 'PIPELINE_STATE_PENDING', 'PIPELINE_STATE_RUNNING', 'PIPELINE_STATE_SUCCEEDED', 'PIPELINE_STATE_FAILED', 'PIPELINE_STATE_CANCELLING', 'PIPELINE_STATE_CANCELLED', 'PIPELINE_STATE_PAUSED')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of GoogleCloudAiplatformV1PipelineJob from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        """
        excluded_fields: Set[str] = set([
            "create_time",
            "end_time",
            "name",
            "schedule_name",
            "start_time",
            "state",
            "update_time",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of encryption_spec
        if self.encryption_spec:
            _dict['encryptionSpec'] = self.encryption_spec.to_dict()
        # override the default output from pydantic by calling `to_dict()` of error
        if self.error:
            _dict['error'] = self.error.to_dict()
        # override the default output from pydantic by calling `to_dict()` of job_detail
        if self.job_detail:
            _dict['jobDetail'] = self.job_detail.to_dict()
        # override the default output from pydantic by calling `to_dict()` of runtime_config
        if self.runtime_config:
            _dict['runtimeConfig'] = self.runtime_config.to_dict()
        # override the default output from pydantic by calling `to_dict()` of template_metadata
        if self.template_metadata:
            _dict['templateMetadata'] = self.template_metadata.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of GoogleCloudAiplatformV1PipelineJob from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "createTime": obj.get("createTime"),
            "displayName": obj.get("displayName"),
            "encryptionSpec": GoogleCloudAiplatformV1EncryptionSpec.from_dict(obj["encryptionSpec"]) if obj.get("encryptionSpec") is not None else None,
            "endTime": obj.get("endTime"),
            "error": GoogleRpcStatus.from_dict(obj["error"]) if obj.get("error") is not None else None,
            "jobDetail": GoogleCloudAiplatformV1PipelineJobDetail.from_dict(obj["jobDetail"]) if obj.get("jobDetail") is not None else None,
            "labels": obj.get("labels"),
            "name": obj.get("name"),
            "network": obj.get("network"),
            "pipelineSpec": obj.get("pipelineSpec"),
            "reservedIpRanges": obj.get("reservedIpRanges"),
            "runtimeConfig": GoogleCloudAiplatformV1PipelineJobRuntimeConfig.from_dict(obj["runtimeConfig"]) if obj.get("runtimeConfig") is not None else None,
            "scheduleName": obj.get("scheduleName"),
            "serviceAccount": obj.get("serviceAccount"),
            "startTime": obj.get("startTime"),
            "state": obj.get("state"),
            "templateMetadata": GoogleCloudAiplatformV1PipelineTemplateMetadata.from_dict(obj["templateMetadata"]) if obj.get("templateMetadata") is not None else None,
            "templateUri": obj.get("templateUri"),
            "updateTime": obj.get("updateTime")
        })
        return _obj


