# coding: utf-8

"""
    Vertex AI API

    Train high-quality custom machine learning models with minimal machine learning expertise and effort.

    The version of the OpenAPI document: v1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.google_cloud_aiplatform_v1_pipeline_job_runtime_config_input_artifact import GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifact
from openapi_client.models.google_cloud_aiplatform_v1_value import GoogleCloudAiplatformV1Value
from typing import Optional, Set
from typing_extensions import Self

class GoogleCloudAiplatformV1PipelineJobRuntimeConfig(BaseModel):
    """
    The runtime config of a PipelineJob.
    """ # noqa: E501
    failure_policy: Optional[StrictStr] = Field(default=None, description="Represents the failure policy of a pipeline. Currently, the default of a pipeline is that the pipeline will continue to run until no more tasks can be executed, also known as PIPELINE_FAILURE_POLICY_FAIL_SLOW. However, if a pipeline is set to PIPELINE_FAILURE_POLICY_FAIL_FAST, it will stop scheduling any new tasks when a task has failed. Any scheduled tasks will continue to completion.", alias="failurePolicy")
    gcs_output_directory: Optional[StrictStr] = Field(default=None, description="Required. A path in a Cloud Storage bucket, which will be treated as the root output directory of the pipeline. It is used by the system to generate the paths of output artifacts. The artifact paths are generated with a sub-path pattern `{job_id}/{task_id}/{output_key}` under the specified output directory. The service account specified in this pipeline must have the `storage.objects.get` and `storage.objects.create` permissions for this bucket.", alias="gcsOutputDirectory")
    input_artifacts: Optional[Dict[str, GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifact]] = Field(default=None, description="The runtime artifacts of the PipelineJob. The key will be the input artifact name and the value would be one of the InputArtifact.", alias="inputArtifacts")
    parameter_values: Optional[Dict[str, Any]] = Field(default=None, description="The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.1.0, such as pipelines built using Kubeflow Pipelines SDK 1.9 or higher and the v2 DSL.", alias="parameterValues")
    parameters: Optional[Dict[str, GoogleCloudAiplatformV1Value]] = Field(default=None, description="Deprecated. Use RuntimeConfig.parameter_values instead. The runtime parameters of the PipelineJob. The parameters will be passed into PipelineJob.pipeline_spec to replace the placeholders at runtime. This field is used by pipelines built using `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as pipelines built using Kubeflow Pipelines SDK 1.8 or lower.")
    __properties: ClassVar[List[str]] = ["failurePolicy", "gcsOutputDirectory", "inputArtifacts", "parameterValues", "parameters"]

    @field_validator('failure_policy')
    def failure_policy_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['PIPELINE_FAILURE_POLICY_UNSPECIFIED', 'PIPELINE_FAILURE_POLICY_FAIL_SLOW', 'PIPELINE_FAILURE_POLICY_FAIL_FAST']):
            raise ValueError("must be one of enum values ('PIPELINE_FAILURE_POLICY_UNSPECIFIED', 'PIPELINE_FAILURE_POLICY_FAIL_SLOW', 'PIPELINE_FAILURE_POLICY_FAIL_FAST')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of GoogleCloudAiplatformV1PipelineJobRuntimeConfig from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each value in input_artifacts (dict)
        _field_dict = {}
        if self.input_artifacts:
            for _key_input_artifacts in self.input_artifacts:
                if self.input_artifacts[_key_input_artifacts]:
                    _field_dict[_key_input_artifacts] = self.input_artifacts[_key_input_artifacts].to_dict()
            _dict['inputArtifacts'] = _field_dict
        # override the default output from pydantic by calling `to_dict()` of each value in parameters (dict)
        _field_dict = {}
        if self.parameters:
            for _key_parameters in self.parameters:
                if self.parameters[_key_parameters]:
                    _field_dict[_key_parameters] = self.parameters[_key_parameters].to_dict()
            _dict['parameters'] = _field_dict
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of GoogleCloudAiplatformV1PipelineJobRuntimeConfig from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "failurePolicy": obj.get("failurePolicy"),
            "gcsOutputDirectory": obj.get("gcsOutputDirectory"),
            "inputArtifacts": dict(
                (_k, GoogleCloudAiplatformV1PipelineJobRuntimeConfigInputArtifact.from_dict(_v))
                for _k, _v in obj["inputArtifacts"].items()
            )
            if obj.get("inputArtifacts") is not None
            else None,
            "parameterValues": obj.get("parameterValues"),
            "parameters": dict(
                (_k, GoogleCloudAiplatformV1Value.from_dict(_v))
                for _k, _v in obj["parameters"].items()
            )
            if obj.get("parameters") is not None
            else None
        })
        return _obj


