# coding: utf-8

"""
    Vertex AI API

    Train high-quality custom machine learning models with minimal machine learning expertise and effort.

    The version of the OpenAPI document: v1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.nlp_saft_language_span import NlpSaftLanguageSpan
from openapi_client.models.nlp_saft_language_span_sequence import NlpSaftLanguageSpanSequence
from typing import Optional, Set
from typing_extensions import Self

class NlpSaftLangIdResult(BaseModel):
    """
    NlpSaftLangIdResult
    """ # noqa: E501
    model_version: Optional[StrictStr] = Field(default=None, description="The version of the model used to create these annotations.", alias="modelVersion")
    predictions: Optional[List[NlpSaftLanguageSpan]] = Field(default=None, description="This field stores the n-best list of possible BCP 47 language code strings for a given input sorted in descending order according to each code's respective probability.")
    span_predictions: Optional[List[NlpSaftLanguageSpanSequence]] = Field(default=None, description="This field stores language predictions of subspans of the input, when available. Each LanguageSpanSequence is a sequence of LanguageSpans. A particular sequence of LanguageSpans has an associated probability, and need not necessarily cover the entire input. If no language could be predicted for any span, then this field may be empty.", alias="spanPredictions")
    __properties: ClassVar[List[str]] = ["modelVersion", "predictions", "spanPredictions"]

    @field_validator('model_version')
    def model_version_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['VERSION_UNSPECIFIED', 'INDEXING_20181017', 'INDEXING_20191206', 'INDEXING_20200313', 'INDEXING_20210618', 'STANDARD_20220516']):
            raise ValueError("must be one of enum values ('VERSION_UNSPECIFIED', 'INDEXING_20181017', 'INDEXING_20191206', 'INDEXING_20200313', 'INDEXING_20210618', 'STANDARD_20220516')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of NlpSaftLangIdResult from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in predictions (list)
        _items = []
        if self.predictions:
            for _item_predictions in self.predictions:
                if _item_predictions:
                    _items.append(_item_predictions.to_dict())
            _dict['predictions'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in span_predictions (list)
        _items = []
        if self.span_predictions:
            for _item_span_predictions in self.span_predictions:
                if _item_span_predictions:
                    _items.append(_item_span_predictions.to_dict())
            _dict['spanPredictions'] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of NlpSaftLangIdResult from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "modelVersion": obj.get("modelVersion"),
            "predictions": [NlpSaftLanguageSpan.from_dict(_item) for _item in obj["predictions"]] if obj.get("predictions") is not None else None,
            "spanPredictions": [NlpSaftLanguageSpanSequence.from_dict(_item) for _item in obj["spanPredictions"]] if obj.get("spanPredictions") is not None else None
        })
        return _obj


