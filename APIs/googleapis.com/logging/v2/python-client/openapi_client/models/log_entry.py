# coding: utf-8

"""
    Cloud Logging API

    Writes log entries and manages your Cloud Logging configuration.

    The version of the OpenAPI document: v2
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.http_request import HttpRequest
from openapi_client.models.log_entry_operation import LogEntryOperation
from openapi_client.models.log_entry_source_location import LogEntrySourceLocation
from openapi_client.models.log_error_group import LogErrorGroup
from openapi_client.models.log_split import LogSplit
from openapi_client.models.monitored_resource import MonitoredResource
from openapi_client.models.monitored_resource_metadata import MonitoredResourceMetadata
from typing import Optional, Set
from typing_extensions import Self

class LogEntry(BaseModel):
    """
    An individual entry in a log.
    """ # noqa: E501
    error_groups: Optional[List[LogErrorGroup]] = Field(default=None, description="Output only. The Error Reporting (https://cloud.google.com/error-reporting) error groups associated with this LogEntry. Error Reporting sets the values for this field during error group creation.For more information, see View error details( https://cloud.google.com/error-reporting/docs/viewing-errors#view_error_details)This field isn't available during log routing (https://cloud.google.com/logging/docs/routing/overview)", alias="errorGroups")
    http_request: Optional[HttpRequest] = Field(default=None, alias="httpRequest")
    insert_id: Optional[StrictStr] = Field(default=None, description="Optional. A unique identifier for the log entry. If you provide a value, then Logging considers other log entries in the same project, with the same timestamp, and with the same insert_id to be duplicates which are removed in a single query result. However, there are no guarantees of de-duplication in the export of logs.If the insert_id is omitted when writing a log entry, the Logging API assigns its own unique identifier in this field.In queries, the insert_id is also used to order log entries that have the same log_name and timestamp values.", alias="insertId")
    json_payload: Optional[Dict[str, Any]] = Field(default=None, description="The log entry payload, represented as a structure that is expressed as a JSON object.", alias="jsonPayload")
    labels: Optional[Dict[str, StrictStr]] = Field(default=None, description="Optional. A map of key, value pairs that provides additional information about the log entry. The labels can be user-defined or system-defined.User-defined labels are arbitrary key, value pairs that you can use to classify logs.System-defined labels are defined by GCP services for platform logs. They have two components - a service namespace component and the attribute name. For example: compute.googleapis.com/resource_name.Cloud Logging truncates label keys that exceed 512 B and label values that exceed 64 KB upon their associated log entry being written. The truncation is indicated by an ellipsis at the end of the character string.")
    log_name: Optional[StrictStr] = Field(default=None, description="Required. The resource name of the log to which this log entry belongs: \"projects/[PROJECT_ID]/logs/[LOG_ID]\" \"organizations/[ORGANIZATION_ID]/logs/[LOG_ID]\" \"billingAccounts/[BILLING_ACCOUNT_ID]/logs/[LOG_ID]\" \"folders/[FOLDER_ID]/logs/[LOG_ID]\" A project number may be used in place of PROJECT_ID. The project number is translated to its corresponding PROJECT_ID internally and the log_name field will contain PROJECT_ID in queries and exports.[LOG_ID] must be URL-encoded within log_name. Example: \"organizations/1234567890/logs/cloudresourcemanager.googleapis.com%2Factivity\".[LOG_ID] must be less than 512 characters long and can only include the following characters: upper and lower case alphanumeric characters, forward-slash, underscore, hyphen, and period.For backward compatibility, if log_name begins with a forward-slash, such as /projects/..., then the log entry is processed as usual, but the forward-slash is removed. Listing the log entry will not show the leading slash and filtering for a log name with a leading slash will never return any results.", alias="logName")
    metadata: Optional[MonitoredResourceMetadata] = None
    operation: Optional[LogEntryOperation] = None
    proto_payload: Optional[Dict[str, Any]] = Field(default=None, description="The log entry payload, represented as a protocol buffer. Some Google Cloud Platform services use this field for their log entry payloads.The following protocol buffer types are supported; user-defined types are not supported:\"type.googleapis.com/google.cloud.audit.AuditLog\" \"type.googleapis.com/google.appengine.logging.v1.RequestLog\"", alias="protoPayload")
    receive_timestamp: Optional[StrictStr] = Field(default=None, description="Output only. The time the log entry was received by Logging.", alias="receiveTimestamp")
    resource: Optional[MonitoredResource] = None
    severity: Optional[StrictStr] = Field(default=None, description="Optional. The severity of the log entry. The default value is LogSeverity.DEFAULT.")
    source_location: Optional[LogEntrySourceLocation] = Field(default=None, alias="sourceLocation")
    span_id: Optional[StrictStr] = Field(default=None, description="Optional. The ID of the Cloud Trace (https://cloud.google.com/trace) span associated with the current operation in which the log is being written. For example, if a span has the REST resource name of \"projects/some-project/traces/some-trace/spans/some-span-id\", then the span_id field is \"some-span-id\".A Span (https://cloud.google.com/trace/docs/reference/v2/rest/v2/projects.traces/batchWrite#Span) represents a single operation within a trace. Whereas a trace may involve multiple different microservices running on multiple different machines, a span generally corresponds to a single logical operation being performed in a single instance of a microservice on one specific machine. Spans are the nodes within the tree that is a trace.Applications that are instrumented for tracing (https://cloud.google.com/trace/docs/setup) will generally assign a new, unique span ID on each incoming request. It is also common to create and record additional spans corresponding to internal processing elements as well as issuing requests to dependencies.The span ID is expected to be a 16-character, hexadecimal encoding of an 8-byte array and should not be zero. It should be unique within the trace and should, ideally, be generated in a manner that is uniformly random.Example values: 000000000000004a 7a2190356c3fc94b 0000f00300090021 d39223e101960076", alias="spanId")
    split: Optional[LogSplit] = None
    text_payload: Optional[StrictStr] = Field(default=None, description="The log entry payload, represented as a Unicode string (UTF-8).", alias="textPayload")
    timestamp: Optional[StrictStr] = Field(default=None, description="Optional. The time the event described by the log entry occurred. This time is used to compute the log entry's age and to enforce the logs retention period. If this field is omitted in a new log entry, then Logging assigns it the current time. Timestamps have nanosecond accuracy, but trailing zeros in the fractional seconds might be omitted when the timestamp is displayed.Incoming log entries must have timestamps that don't exceed the logs retention period (https://cloud.google.com/logging/quotas#logs_retention_periods) in the past, and that don't exceed 24 hours in the future. Log entries outside those time boundaries are rejected by Logging.")
    trace: Optional[StrictStr] = Field(default=None, description="Optional. The REST resource name of the trace being written to Cloud Trace (https://cloud.google.com/trace) in association with this log entry. For example, if your trace data is stored in the Cloud project \"my-trace-project\" and if the service that is creating the log entry receives a trace header that includes the trace ID \"12345\", then the service should use \"projects/my-trace-project/traces/12345\".The trace field provides the link between logs and traces. By using this field, you can navigate from a log entry to a trace.")
    trace_sampled: Optional[StrictBool] = Field(default=None, description="Optional. The sampling decision of the span associated with the log entry at the time the log entry was created. This field corresponds to the sampled flag in the W3C trace-context specification (https://www.w3.org/TR/trace-context/#sampled-flag). A non-sampled trace value is still useful as a request correlation identifier. The default is False.", alias="traceSampled")
    __properties: ClassVar[List[str]] = ["errorGroups", "httpRequest", "insertId", "jsonPayload", "labels", "logName", "metadata", "operation", "protoPayload", "receiveTimestamp", "resource", "severity", "sourceLocation", "spanId", "split", "textPayload", "timestamp", "trace", "traceSampled"]

    @field_validator('severity')
    def severity_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['DEFAULT', 'DEBUG', 'INFO', 'NOTICE', 'WARNING', 'ERROR', 'CRITICAL', 'ALERT', 'EMERGENCY']):
            raise ValueError("must be one of enum values ('DEFAULT', 'DEBUG', 'INFO', 'NOTICE', 'WARNING', 'ERROR', 'CRITICAL', 'ALERT', 'EMERGENCY')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of LogEntry from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        """
        excluded_fields: Set[str] = set([
            "error_groups",
            "receive_timestamp",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in error_groups (list)
        _items = []
        if self.error_groups:
            for _item_error_groups in self.error_groups:
                if _item_error_groups:
                    _items.append(_item_error_groups.to_dict())
            _dict['errorGroups'] = _items
        # override the default output from pydantic by calling `to_dict()` of http_request
        if self.http_request:
            _dict['httpRequest'] = self.http_request.to_dict()
        # override the default output from pydantic by calling `to_dict()` of metadata
        if self.metadata:
            _dict['metadata'] = self.metadata.to_dict()
        # override the default output from pydantic by calling `to_dict()` of operation
        if self.operation:
            _dict['operation'] = self.operation.to_dict()
        # override the default output from pydantic by calling `to_dict()` of resource
        if self.resource:
            _dict['resource'] = self.resource.to_dict()
        # override the default output from pydantic by calling `to_dict()` of source_location
        if self.source_location:
            _dict['sourceLocation'] = self.source_location.to_dict()
        # override the default output from pydantic by calling `to_dict()` of split
        if self.split:
            _dict['split'] = self.split.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of LogEntry from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "errorGroups": [LogErrorGroup.from_dict(_item) for _item in obj["errorGroups"]] if obj.get("errorGroups") is not None else None,
            "httpRequest": HttpRequest.from_dict(obj["httpRequest"]) if obj.get("httpRequest") is not None else None,
            "insertId": obj.get("insertId"),
            "jsonPayload": obj.get("jsonPayload"),
            "labels": obj.get("labels"),
            "logName": obj.get("logName"),
            "metadata": MonitoredResourceMetadata.from_dict(obj["metadata"]) if obj.get("metadata") is not None else None,
            "operation": LogEntryOperation.from_dict(obj["operation"]) if obj.get("operation") is not None else None,
            "protoPayload": obj.get("protoPayload"),
            "receiveTimestamp": obj.get("receiveTimestamp"),
            "resource": MonitoredResource.from_dict(obj["resource"]) if obj.get("resource") is not None else None,
            "severity": obj.get("severity"),
            "sourceLocation": LogEntrySourceLocation.from_dict(obj["sourceLocation"]) if obj.get("sourceLocation") is not None else None,
            "spanId": obj.get("spanId"),
            "split": LogSplit.from_dict(obj["split"]) if obj.get("split") is not None else None,
            "textPayload": obj.get("textPayload"),
            "timestamp": obj.get("timestamp"),
            "trace": obj.get("trace"),
            "traceSampled": obj.get("traceSampled")
        })
        return _obj


