# coding: utf-8

"""
    Application Integration API

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)

    The version of the OpenAPI document: v1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.enterprise_crm_eventbus_proto_cloud_scheduler_config import EnterpriseCrmEventbusProtoCloudSchedulerConfig
from openapi_client.models.enterprise_crm_eventbus_proto_coordinate import EnterpriseCrmEventbusProtoCoordinate
from openapi_client.models.enterprise_crm_eventbus_proto_next_task import EnterpriseCrmEventbusProtoNextTask
from openapi_client.models.enterprise_crm_eventbus_proto_trigger_criteria import EnterpriseCrmEventbusProtoTriggerCriteria
from openapi_client.models.enterprise_crm_eventbus_proto_workflow_alert_config import EnterpriseCrmEventbusProtoWorkflowAlertConfig
from typing import Optional, Set
from typing_extensions import Self

class EnterpriseCrmFrontendsEventbusProtoTriggerConfig(BaseModel):
    """
    Configuration detail of a trigger. Next available id: 20
    """ # noqa: E501
    alert_config: Optional[List[EnterpriseCrmEventbusProtoWorkflowAlertConfig]] = Field(default=None, description="An alert threshold configuration for the [trigger + client + workflow] tuple. If these values are not specified in the trigger config, default values will be populated by the system. Note that there must be exactly one alert threshold configured per [client + trigger + workflow] when published.", alias="alertConfig")
    cloud_scheduler_config: Optional[EnterpriseCrmEventbusProtoCloudSchedulerConfig] = Field(default=None, alias="cloudSchedulerConfig")
    description: Optional[StrictStr] = Field(default=None, description="User-provided description intended to give more business context about the task.")
    enabled_clients: Optional[List[StrictStr]] = Field(default=None, description="Required. The list of client ids which are enabled to execute the workflow using this trigger. In other words, these clients have the workflow execution privledges for this trigger. For API trigger, the client id in the incoming request is validated against the list of enabled clients. For non-API triggers, one workflow execution is triggered on behalf of each enabled client.", alias="enabledClients")
    error_catcher_id: Optional[StrictStr] = Field(default=None, description="Optional Error catcher id of the error catch flow which will be executed when execution error happens in the task", alias="errorCatcherId")
    label: Optional[StrictStr] = Field(default=None, description="The user created label for a particular trigger.")
    next_tasks_execution_policy: Optional[StrictStr] = Field(default=None, description="Dictates how next tasks will be executed.", alias="nextTasksExecutionPolicy")
    pause_workflow_executions: Optional[StrictBool] = Field(default=None, description="Optional. If set to true, any upcoming requests for this trigger config will be paused and the executions will be resumed later when the flag is reset. The workflow to which this trigger config belongs has to be in ACTIVE status for the executions to be paused or resumed.", alias="pauseWorkflowExecutions")
    position: Optional[EnterpriseCrmEventbusProtoCoordinate] = None
    properties: Optional[Dict[str, StrictStr]] = Field(default=None, description="Configurable properties of the trigger, not to be confused with workflow parameters. E.g. \"name\" is a property for API triggers and \"subscription\" is a property for Cloud Pubsub triggers.")
    start_tasks: Optional[List[EnterpriseCrmEventbusProtoNextTask]] = Field(default=None, description="Set of tasks numbers from where the workflow execution is started by this trigger. If this is empty, then workflow is executed with default start tasks. In the list of start tasks, none of two tasks can have direct ancestor-descendant relationships (i.e. in a same workflow execution graph).", alias="startTasks")
    trigger_criteria: Optional[EnterpriseCrmEventbusProtoTriggerCriteria] = Field(default=None, alias="triggerCriteria")
    trigger_id: Optional[StrictStr] = Field(default=None, description="The backend trigger ID.", alias="triggerId")
    trigger_name: Optional[StrictStr] = Field(default=None, description="Optional. Name of the trigger This is added to identify the type of trigger. This is avoid the logic on triggerId to identify the trigger_type and push the same to monitoring.", alias="triggerName")
    trigger_number: Optional[StrictStr] = Field(default=None, description="Required. A number to uniquely identify each trigger config within the workflow on UI.", alias="triggerNumber")
    trigger_type: Optional[StrictStr] = Field(default=None, alias="triggerType")
    __properties: ClassVar[List[str]] = ["alertConfig", "cloudSchedulerConfig", "description", "enabledClients", "errorCatcherId", "label", "nextTasksExecutionPolicy", "pauseWorkflowExecutions", "position", "properties", "startTasks", "triggerCriteria", "triggerId", "triggerName", "triggerNumber", "triggerType"]

    @field_validator('next_tasks_execution_policy')
    def next_tasks_execution_policy_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['UNSPECIFIED', 'RUN_ALL_MATCH', 'RUN_FIRST_MATCH']):
            raise ValueError("must be one of enum values ('UNSPECIFIED', 'RUN_ALL_MATCH', 'RUN_FIRST_MATCH')")
        return value

    @field_validator('trigger_type')
    def trigger_type_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['UNKNOWN', 'CLOUD_PUBSUB', 'GOOPS', 'SFDC_SYNC', 'CRON', 'API', 'MANIFOLD_TRIGGER', 'DATALAYER_DATA_CHANGE', 'SFDC_CHANNEL', 'CLOUD_PUBSUB_EXTERNAL', 'SFDC_CDC_CHANNEL', 'SFDC_PLATFORM_EVENTS_CHANNEL', 'CLOUD_SCHEDULER', 'INTEGRATION_CONNECTOR_TRIGGER']):
            raise ValueError("must be one of enum values ('UNKNOWN', 'CLOUD_PUBSUB', 'GOOPS', 'SFDC_SYNC', 'CRON', 'API', 'MANIFOLD_TRIGGER', 'DATALAYER_DATA_CHANGE', 'SFDC_CHANNEL', 'CLOUD_PUBSUB_EXTERNAL', 'SFDC_CDC_CHANNEL', 'SFDC_PLATFORM_EVENTS_CHANNEL', 'CLOUD_SCHEDULER', 'INTEGRATION_CONNECTOR_TRIGGER')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of EnterpriseCrmFrontendsEventbusProtoTriggerConfig from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in alert_config (list)
        _items = []
        if self.alert_config:
            for _item_alert_config in self.alert_config:
                if _item_alert_config:
                    _items.append(_item_alert_config.to_dict())
            _dict['alertConfig'] = _items
        # override the default output from pydantic by calling `to_dict()` of cloud_scheduler_config
        if self.cloud_scheduler_config:
            _dict['cloudSchedulerConfig'] = self.cloud_scheduler_config.to_dict()
        # override the default output from pydantic by calling `to_dict()` of position
        if self.position:
            _dict['position'] = self.position.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in start_tasks (list)
        _items = []
        if self.start_tasks:
            for _item_start_tasks in self.start_tasks:
                if _item_start_tasks:
                    _items.append(_item_start_tasks.to_dict())
            _dict['startTasks'] = _items
        # override the default output from pydantic by calling `to_dict()` of trigger_criteria
        if self.trigger_criteria:
            _dict['triggerCriteria'] = self.trigger_criteria.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of EnterpriseCrmFrontendsEventbusProtoTriggerConfig from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "alertConfig": [EnterpriseCrmEventbusProtoWorkflowAlertConfig.from_dict(_item) for _item in obj["alertConfig"]] if obj.get("alertConfig") is not None else None,
            "cloudSchedulerConfig": EnterpriseCrmEventbusProtoCloudSchedulerConfig.from_dict(obj["cloudSchedulerConfig"]) if obj.get("cloudSchedulerConfig") is not None else None,
            "description": obj.get("description"),
            "enabledClients": obj.get("enabledClients"),
            "errorCatcherId": obj.get("errorCatcherId"),
            "label": obj.get("label"),
            "nextTasksExecutionPolicy": obj.get("nextTasksExecutionPolicy"),
            "pauseWorkflowExecutions": obj.get("pauseWorkflowExecutions"),
            "position": EnterpriseCrmEventbusProtoCoordinate.from_dict(obj["position"]) if obj.get("position") is not None else None,
            "properties": obj.get("properties"),
            "startTasks": [EnterpriseCrmEventbusProtoNextTask.from_dict(_item) for _item in obj["startTasks"]] if obj.get("startTasks") is not None else None,
            "triggerCriteria": EnterpriseCrmEventbusProtoTriggerCriteria.from_dict(obj["triggerCriteria"]) if obj.get("triggerCriteria") is not None else None,
            "triggerId": obj.get("triggerId"),
            "triggerName": obj.get("triggerName"),
            "triggerNumber": obj.get("triggerNumber"),
            "triggerType": obj.get("triggerType")
        })
        return _obj


