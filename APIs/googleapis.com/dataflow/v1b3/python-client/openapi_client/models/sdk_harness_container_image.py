# coding: utf-8

"""
    Dataflow API

    Manages Google Cloud Dataflow projects on Google Cloud Platform.

    The version of the OpenAPI document: v1b3
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from typing import Optional, Set
from typing_extensions import Self

class SdkHarnessContainerImage(BaseModel):
    """
    Defines an SDK harness container for executing Dataflow pipelines.
    """ # noqa: E501
    capabilities: Optional[List[StrictStr]] = Field(default=None, description="The set of capabilities enumerated in the above Environment proto. See also [beam_runner_api.proto](https://github.com/apache/beam/blob/master/model/pipeline/src/main/proto/org/apache/beam/model/pipeline/v1/beam_runner_api.proto)")
    container_image: Optional[StrictStr] = Field(default=None, description="A docker container image that resides in Google Container Registry.", alias="containerImage")
    environment_id: Optional[StrictStr] = Field(default=None, description="Environment ID for the Beam runner API proto Environment that corresponds to the current SDK Harness.", alias="environmentId")
    use_single_core_per_container: Optional[StrictBool] = Field(default=None, description="If true, recommends the Dataflow service to use only one core per SDK container instance with this image. If false (or unset) recommends using more than one core per SDK container instance with this image for efficiency. Note that Dataflow service may choose to override this property if needed.", alias="useSingleCorePerContainer")
    __properties: ClassVar[List[str]] = ["capabilities", "containerImage", "environmentId", "useSingleCorePerContainer"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of SdkHarnessContainerImage from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of SdkHarnessContainerImage from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "capabilities": obj.get("capabilities"),
            "containerImage": obj.get("containerImage"),
            "environmentId": obj.get("environmentId"),
            "useSingleCorePerContainer": obj.get("useSingleCorePerContainer")
        })
        return _obj


