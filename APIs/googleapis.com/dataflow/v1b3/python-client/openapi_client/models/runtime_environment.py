# coding: utf-8

"""
    Dataflow API

    Manages Google Cloud Dataflow projects on Google Cloud Platform.

    The version of the OpenAPI document: v1b3
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictInt, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from typing import Optional, Set
from typing_extensions import Self

class RuntimeEnvironment(BaseModel):
    """
    The environment values to set at runtime.
    """ # noqa: E501
    additional_experiments: Optional[List[StrictStr]] = Field(default=None, description="Optional. Additional experiment flags for the job, specified with the `--experiments` option.", alias="additionalExperiments")
    additional_user_labels: Optional[Dict[str, StrictStr]] = Field(default=None, description="Optional. Additional user labels to be specified for the job. Keys and values should follow the restrictions specified in the [labeling restrictions](https://cloud.google.com/compute/docs/labeling-resources#restrictions) page. An object containing a list of \"key\": value pairs. Example: { \"name\": \"wrench\", \"mass\": \"1kg\", \"count\": \"3\" }.", alias="additionalUserLabels")
    bypass_temp_dir_validation: Optional[StrictBool] = Field(default=None, description="Optional. Whether to bypass the safety checks for the job's temporary directory. Use with caution.", alias="bypassTempDirValidation")
    disk_size_gb: Optional[StrictInt] = Field(default=None, description="Optional. The disk size, in gigabytes, to use on each remote Compute Engine worker instance.", alias="diskSizeGb")
    enable_streaming_engine: Optional[StrictBool] = Field(default=None, description="Optional. Whether to enable Streaming Engine for the job.", alias="enableStreamingEngine")
    ip_configuration: Optional[StrictStr] = Field(default=None, description="Optional. Configuration for VM IPs.", alias="ipConfiguration")
    kms_key_name: Optional[StrictStr] = Field(default=None, description="Optional. Name for the Cloud KMS key for the job. Key format is: projects//locations//keyRings//cryptoKeys/", alias="kmsKeyName")
    machine_type: Optional[StrictStr] = Field(default=None, description="Optional. The machine type to use for the job. Defaults to the value from the template if not specified.", alias="machineType")
    max_workers: Optional[StrictInt] = Field(default=None, description="Optional. The maximum number of Google Compute Engine instances to be made available to your pipeline during execution, from 1 to 1000. The default value is 1.", alias="maxWorkers")
    network: Optional[StrictStr] = Field(default=None, description="Optional. Network to which VMs will be assigned. If empty or unspecified, the service will use the network \"default\".")
    num_workers: Optional[StrictInt] = Field(default=None, description="Optional. The initial number of Google Compute Engine instances for the job. The default value is 11.", alias="numWorkers")
    service_account_email: Optional[StrictStr] = Field(default=None, description="Optional. The email address of the service account to run the job as.", alias="serviceAccountEmail")
    streaming_mode: Optional[StrictStr] = Field(default=None, description="Optional. Specifies the Streaming Engine message processing guarantees. Reduces cost and latency but might result in duplicate messages committed to storage. Designed to run simple mapping streaming ETL jobs at the lowest cost. For example, Change Data Capture (CDC) to BigQuery is a canonical use case.", alias="streamingMode")
    subnetwork: Optional[StrictStr] = Field(default=None, description="Optional. Subnetwork to which VMs will be assigned, if desired. You can specify a subnetwork using either a complete URL or an abbreviated path. Expected to be of the form \"https://www.googleapis.com/compute/v1/projects/HOST_PROJECT_ID/regions/REGION/subnetworks/SUBNETWORK\" or \"regions/REGION/subnetworks/SUBNETWORK\". If the subnetwork is located in a Shared VPC network, you must use the complete URL.")
    temp_location: Optional[StrictStr] = Field(default=None, description="Required. The Cloud Storage path to use for temporary files. Must be a valid Cloud Storage URL, beginning with `gs://`.", alias="tempLocation")
    worker_region: Optional[StrictStr] = Field(default=None, description="Required. The Compute Engine region (https://cloud.google.com/compute/docs/regions-zones/regions-zones) in which worker processing should occur, e.g. \"us-west1\". Mutually exclusive with worker_zone. If neither worker_region nor worker_zone is specified, default to the control plane's region.", alias="workerRegion")
    worker_zone: Optional[StrictStr] = Field(default=None, description="Optional. The Compute Engine zone (https://cloud.google.com/compute/docs/regions-zones/regions-zones) in which worker processing should occur, e.g. \"us-west1-a\". Mutually exclusive with worker_region. If neither worker_region nor worker_zone is specified, a zone in the control plane's region is chosen based on available capacity. If both `worker_zone` and `zone` are set, `worker_zone` takes precedence.", alias="workerZone")
    zone: Optional[StrictStr] = Field(default=None, description="Optional. The Compute Engine [availability zone](https://cloud.google.com/compute/docs/regions-zones/regions-zones) for launching worker instances to run your pipeline. In the future, worker_zone will take precedence.")
    __properties: ClassVar[List[str]] = ["additionalExperiments", "additionalUserLabels", "bypassTempDirValidation", "diskSizeGb", "enableStreamingEngine", "ipConfiguration", "kmsKeyName", "machineType", "maxWorkers", "network", "numWorkers", "serviceAccountEmail", "streamingMode", "subnetwork", "tempLocation", "workerRegion", "workerZone", "zone"]

    @field_validator('ip_configuration')
    def ip_configuration_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['WORKER_IP_UNSPECIFIED', 'WORKER_IP_PUBLIC', 'WORKER_IP_PRIVATE']):
            raise ValueError("must be one of enum values ('WORKER_IP_UNSPECIFIED', 'WORKER_IP_PUBLIC', 'WORKER_IP_PRIVATE')")
        return value

    @field_validator('streaming_mode')
    def streaming_mode_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['STREAMING_MODE_UNSPECIFIED', 'STREAMING_MODE_EXACTLY_ONCE', 'STREAMING_MODE_AT_LEAST_ONCE']):
            raise ValueError("must be one of enum values ('STREAMING_MODE_UNSPECIFIED', 'STREAMING_MODE_EXACTLY_ONCE', 'STREAMING_MODE_AT_LEAST_ONCE')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of RuntimeEnvironment from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of RuntimeEnvironment from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "additionalExperiments": obj.get("additionalExperiments"),
            "additionalUserLabels": obj.get("additionalUserLabels"),
            "bypassTempDirValidation": obj.get("bypassTempDirValidation"),
            "diskSizeGb": obj.get("diskSizeGb"),
            "enableStreamingEngine": obj.get("enableStreamingEngine"),
            "ipConfiguration": obj.get("ipConfiguration"),
            "kmsKeyName": obj.get("kmsKeyName"),
            "machineType": obj.get("machineType"),
            "maxWorkers": obj.get("maxWorkers"),
            "network": obj.get("network"),
            "numWorkers": obj.get("numWorkers"),
            "serviceAccountEmail": obj.get("serviceAccountEmail"),
            "streamingMode": obj.get("streamingMode"),
            "subnetwork": obj.get("subnetwork"),
            "tempLocation": obj.get("tempLocation"),
            "workerRegion": obj.get("workerRegion"),
            "workerZone": obj.get("workerZone"),
            "zone": obj.get("zone")
        })
        return _obj


