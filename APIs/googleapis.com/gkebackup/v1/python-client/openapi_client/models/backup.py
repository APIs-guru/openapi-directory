# coding: utf-8

"""
    Backup for GKE API

    Backup for GKE is a managed Kubernetes workload backup and restore service for GKE clusters.

    The version of the OpenAPI document: v1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictInt, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.cluster_metadata import ClusterMetadata
from openapi_client.models.encryption_key import EncryptionKey
from openapi_client.models.namespaced_names import NamespacedNames
from openapi_client.models.namespaces import Namespaces
from typing import Optional, Set
from typing_extensions import Self

class Backup(BaseModel):
    """
    Represents a request to perform a single point-in-time capture of some portion of the state of a GKE cluster, the record of the backup operation itself, and an anchor for the underlying artifacts that comprise the Backup (the config backup and VolumeBackups). Next id: 29
    """ # noqa: E501
    all_namespaces: Optional[StrictBool] = Field(default=None, description="Output only. If True, all namespaces were included in the Backup.", alias="allNamespaces")
    cluster_metadata: Optional[ClusterMetadata] = Field(default=None, alias="clusterMetadata")
    complete_time: Optional[StrictStr] = Field(default=None, description="Output only. Completion time of the Backup", alias="completeTime")
    config_backup_size_bytes: Optional[StrictStr] = Field(default=None, description="Output only. The size of the config backup in bytes.", alias="configBackupSizeBytes")
    contains_secrets: Optional[StrictBool] = Field(default=None, description="Output only. Whether or not the Backup contains Kubernetes Secrets. Controlled by the parent BackupPlan's include_secrets value.", alias="containsSecrets")
    contains_volume_data: Optional[StrictBool] = Field(default=None, description="Output only. Whether or not the Backup contains volume data. Controlled by the parent BackupPlan's include_volume_data value.", alias="containsVolumeData")
    create_time: Optional[StrictStr] = Field(default=None, description="Output only. The timestamp when this Backup resource was created.", alias="createTime")
    delete_lock_days: Optional[StrictInt] = Field(default=None, description="Optional. Minimum age for this Backup (in days). If this field is set to a non-zero value, the Backup will be \"locked\" against deletion (either manual or automatic deletion) for the number of days provided (measured from the creation time of the Backup). MUST be an integer value between 0-90 (inclusive). Defaults to parent BackupPlan's backup_delete_lock_days setting and may only be increased (either at creation time or in a subsequent update).", alias="deleteLockDays")
    delete_lock_expire_time: Optional[StrictStr] = Field(default=None, description="Output only. The time at which an existing delete lock will expire for this backup (calculated from create_time + delete_lock_days).", alias="deleteLockExpireTime")
    description: Optional[StrictStr] = Field(default=None, description="Optional. User specified descriptive string for this Backup.")
    encryption_key: Optional[EncryptionKey] = Field(default=None, alias="encryptionKey")
    etag: Optional[StrictStr] = Field(default=None, description="Output only. `etag` is used for optimistic concurrency control as a way to help prevent simultaneous updates of a backup from overwriting each other. It is strongly suggested that systems make use of the `etag` in the read-modify-write cycle to perform backup updates in order to avoid race conditions: An `etag` is returned in the response to `GetBackup`, and systems are expected to put that etag in the request to `UpdateBackup` or `DeleteBackup` to ensure that their change will be applied to the same version of the resource.")
    labels: Optional[Dict[str, StrictStr]] = Field(default=None, description="Optional. A set of custom labels supplied by user.")
    manual: Optional[StrictBool] = Field(default=None, description="Output only. This flag indicates whether this Backup resource was created manually by a user or via a schedule in the BackupPlan. A value of True means that the Backup was created manually.")
    name: Optional[StrictStr] = Field(default=None, description="Output only. The fully qualified name of the Backup. `projects/*/locations/*/backupPlans/*/backups/*`")
    pod_count: Optional[StrictInt] = Field(default=None, description="Output only. The total number of Kubernetes Pods contained in the Backup.", alias="podCount")
    resource_count: Optional[StrictInt] = Field(default=None, description="Output only. The total number of Kubernetes resources included in the Backup.", alias="resourceCount")
    retain_days: Optional[StrictInt] = Field(default=None, description="Optional. The age (in days) after which this Backup will be automatically deleted. Must be an integer value >= 0: - If 0, no automatic deletion will occur for this Backup. - If not 0, this must be >= delete_lock_days and <= 365. Once a Backup is created, this value may only be increased. Defaults to the parent BackupPlan's backup_retain_days value.", alias="retainDays")
    retain_expire_time: Optional[StrictStr] = Field(default=None, description="Output only. The time at which this Backup will be automatically deleted (calculated from create_time + retain_days).", alias="retainExpireTime")
    selected_applications: Optional[NamespacedNames] = Field(default=None, alias="selectedApplications")
    selected_namespaces: Optional[Namespaces] = Field(default=None, alias="selectedNamespaces")
    size_bytes: Optional[StrictStr] = Field(default=None, description="Output only. The total size of the Backup in bytes = config backup size + sum(volume backup sizes)", alias="sizeBytes")
    state: Optional[StrictStr] = Field(default=None, description="Output only. Current state of the Backup")
    state_reason: Optional[StrictStr] = Field(default=None, description="Output only. Human-readable description of why the backup is in the current `state`.", alias="stateReason")
    uid: Optional[StrictStr] = Field(default=None, description="Output only. Server generated global unique identifier of [UUID4](https://en.wikipedia.org/wiki/Universally_unique_identifier)")
    update_time: Optional[StrictStr] = Field(default=None, description="Output only. The timestamp when this Backup resource was last updated.", alias="updateTime")
    volume_count: Optional[StrictInt] = Field(default=None, description="Output only. The total number of volume backups contained in the Backup.", alias="volumeCount")
    __properties: ClassVar[List[str]] = ["allNamespaces", "clusterMetadata", "completeTime", "configBackupSizeBytes", "containsSecrets", "containsVolumeData", "createTime", "deleteLockDays", "deleteLockExpireTime", "description", "encryptionKey", "etag", "labels", "manual", "name", "podCount", "resourceCount", "retainDays", "retainExpireTime", "selectedApplications", "selectedNamespaces", "sizeBytes", "state", "stateReason", "uid", "updateTime", "volumeCount"]

    @field_validator('state')
    def state_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['STATE_UNSPECIFIED', 'CREATING', 'IN_PROGRESS', 'SUCCEEDED', 'FAILED', 'DELETING']):
            raise ValueError("must be one of enum values ('STATE_UNSPECIFIED', 'CREATING', 'IN_PROGRESS', 'SUCCEEDED', 'FAILED', 'DELETING')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of Backup from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        """
        excluded_fields: Set[str] = set([
            "all_namespaces",
            "complete_time",
            "config_backup_size_bytes",
            "contains_secrets",
            "contains_volume_data",
            "create_time",
            "delete_lock_expire_time",
            "etag",
            "manual",
            "name",
            "pod_count",
            "resource_count",
            "retain_expire_time",
            "size_bytes",
            "state",
            "state_reason",
            "uid",
            "update_time",
            "volume_count",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of cluster_metadata
        if self.cluster_metadata:
            _dict['clusterMetadata'] = self.cluster_metadata.to_dict()
        # override the default output from pydantic by calling `to_dict()` of encryption_key
        if self.encryption_key:
            _dict['encryptionKey'] = self.encryption_key.to_dict()
        # override the default output from pydantic by calling `to_dict()` of selected_applications
        if self.selected_applications:
            _dict['selectedApplications'] = self.selected_applications.to_dict()
        # override the default output from pydantic by calling `to_dict()` of selected_namespaces
        if self.selected_namespaces:
            _dict['selectedNamespaces'] = self.selected_namespaces.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of Backup from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "allNamespaces": obj.get("allNamespaces"),
            "clusterMetadata": ClusterMetadata.from_dict(obj["clusterMetadata"]) if obj.get("clusterMetadata") is not None else None,
            "completeTime": obj.get("completeTime"),
            "configBackupSizeBytes": obj.get("configBackupSizeBytes"),
            "containsSecrets": obj.get("containsSecrets"),
            "containsVolumeData": obj.get("containsVolumeData"),
            "createTime": obj.get("createTime"),
            "deleteLockDays": obj.get("deleteLockDays"),
            "deleteLockExpireTime": obj.get("deleteLockExpireTime"),
            "description": obj.get("description"),
            "encryptionKey": EncryptionKey.from_dict(obj["encryptionKey"]) if obj.get("encryptionKey") is not None else None,
            "etag": obj.get("etag"),
            "labels": obj.get("labels"),
            "manual": obj.get("manual"),
            "name": obj.get("name"),
            "podCount": obj.get("podCount"),
            "resourceCount": obj.get("resourceCount"),
            "retainDays": obj.get("retainDays"),
            "retainExpireTime": obj.get("retainExpireTime"),
            "selectedApplications": NamespacedNames.from_dict(obj["selectedApplications"]) if obj.get("selectedApplications") is not None else None,
            "selectedNamespaces": Namespaces.from_dict(obj["selectedNamespaces"]) if obj.get("selectedNamespaces") is not None else None,
            "sizeBytes": obj.get("sizeBytes"),
            "state": obj.get("state"),
            "stateReason": obj.get("stateReason"),
            "uid": obj.get("uid"),
            "updateTime": obj.get("updateTime"),
            "volumeCount": obj.get("volumeCount")
        })
        return _obj


