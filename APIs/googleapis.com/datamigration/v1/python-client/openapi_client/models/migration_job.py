# coding: utf-8

"""
    Database Migration API

    Manage Cloud Database Migration Service resources on Google Cloud Platform.

    The version of the OpenAPI document: v1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.conversion_workspace_info import ConversionWorkspaceInfo
from openapi_client.models.database_type import DatabaseType
from openapi_client.models.dump_flags import DumpFlags
from openapi_client.models.performance_config import PerformanceConfig
from openapi_client.models.reverse_ssh_connectivity import ReverseSshConnectivity
from openapi_client.models.status import Status
from openapi_client.models.vpc_peering_connectivity import VpcPeeringConnectivity
from typing import Optional, Set
from typing_extensions import Self

class MigrationJob(BaseModel):
    """
    Represents a Database Migration Service migration job object.
    """ # noqa: E501
    cmek_key_name: Optional[StrictStr] = Field(default=None, description="The CMEK (customer-managed encryption key) fully qualified key name used for the migration job. This field supports all migration jobs types except for: * Mysql to Mysql (use the cmek field in the cloudsql connection profile instead). * PostrgeSQL to PostgreSQL (use the cmek field in the cloudsql connection profile instead). * PostgreSQL to AlloyDB (use the kms_key_name field in the alloydb connection profile instead). Each Cloud CMEK key has the following format: projects/[PROJECT]/locations/[REGION]/keyRings/[RING]/cryptoKeys/[KEY_NAME]", alias="cmekKeyName")
    conversion_workspace: Optional[ConversionWorkspaceInfo] = Field(default=None, alias="conversionWorkspace")
    create_time: Optional[StrictStr] = Field(default=None, description="Output only. The timestamp when the migration job resource was created. A timestamp in RFC3339 UTC \"Zulu\" format, accurate to nanoseconds. Example: \"2014-10-02T15:01:23.045123456Z\".", alias="createTime")
    destination: Optional[StrictStr] = Field(default=None, description="Required. The resource name (URI) of the destination connection profile.")
    destination_database: Optional[DatabaseType] = Field(default=None, alias="destinationDatabase")
    display_name: Optional[StrictStr] = Field(default=None, description="The migration job display name.", alias="displayName")
    dump_flags: Optional[DumpFlags] = Field(default=None, alias="dumpFlags")
    dump_path: Optional[StrictStr] = Field(default=None, description="The path to the dump file in Google Cloud Storage, in the format: (gs://[BUCKET_NAME]/[OBJECT_NAME]). This field and the \"dump_flags\" field are mutually exclusive.", alias="dumpPath")
    duration: Optional[StrictStr] = Field(default=None, description="Output only. The duration of the migration job (in seconds). A duration in seconds with up to nine fractional digits, terminated by 's'. Example: \"3.5s\".")
    end_time: Optional[StrictStr] = Field(default=None, description="Output only. If the migration job is completed, the time when it was completed.", alias="endTime")
    error: Optional[Status] = None
    filter: Optional[StrictStr] = Field(default=None, description="This field can be used to select the entities to migrate as part of the migration job. It uses AIP-160 notation to select a subset of the entities configured on the associated conversion-workspace. This field should not be set on migration-jobs that are not associated with a conversion workspace.")
    labels: Optional[Dict[str, StrictStr]] = Field(default=None, description="The resource labels for migration job to use to annotate any related underlying resources such as Compute Engine VMs. An object containing a list of \"key\": \"value\" pairs. Example: `{ \"name\": \"wrench\", \"mass\": \"1.3kg\", \"count\": \"3\" }`.")
    name: Optional[StrictStr] = Field(default=None, description="The name (URI) of this migration job resource, in the form of: projects/{project}/locations/{location}/migrationJobs/{migrationJob}.")
    performance_config: Optional[PerformanceConfig] = Field(default=None, alias="performanceConfig")
    phase: Optional[StrictStr] = Field(default=None, description="Output only. The current migration job phase.")
    reverse_ssh_connectivity: Optional[ReverseSshConnectivity] = Field(default=None, alias="reverseSshConnectivity")
    source: Optional[StrictStr] = Field(default=None, description="Required. The resource name (URI) of the source connection profile.")
    source_database: Optional[DatabaseType] = Field(default=None, alias="sourceDatabase")
    state: Optional[StrictStr] = Field(default=None, description="The current migration job state.")
    static_ip_connectivity: Optional[Dict[str, Any]] = Field(default=None, description="The source database will allow incoming connections from the public IP of the destination database. You can retrieve the public IP of the Cloud SQL instance from the Cloud SQL console or using Cloud SQL APIs. No additional configuration is required.", alias="staticIpConnectivity")
    type: Optional[StrictStr] = Field(default=None, description="Required. The migration job type.")
    update_time: Optional[StrictStr] = Field(default=None, description="Output only. The timestamp when the migration job resource was last updated. A timestamp in RFC3339 UTC \"Zulu\" format, accurate to nanoseconds. Example: \"2014-10-02T15:01:23.045123456Z\".", alias="updateTime")
    vpc_peering_connectivity: Optional[VpcPeeringConnectivity] = Field(default=None, alias="vpcPeeringConnectivity")
    __properties: ClassVar[List[str]] = ["cmekKeyName", "conversionWorkspace", "createTime", "destination", "destinationDatabase", "displayName", "dumpFlags", "dumpPath", "duration", "endTime", "error", "filter", "labels", "name", "performanceConfig", "phase", "reverseSshConnectivity", "source", "sourceDatabase", "state", "staticIpConnectivity", "type", "updateTime", "vpcPeeringConnectivity"]

    @field_validator('phase')
    def phase_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['PHASE_UNSPECIFIED', 'FULL_DUMP', 'CDC', 'PROMOTE_IN_PROGRESS', 'WAITING_FOR_SOURCE_WRITES_TO_STOP', 'PREPARING_THE_DUMP']):
            raise ValueError("must be one of enum values ('PHASE_UNSPECIFIED', 'FULL_DUMP', 'CDC', 'PROMOTE_IN_PROGRESS', 'WAITING_FOR_SOURCE_WRITES_TO_STOP', 'PREPARING_THE_DUMP')")
        return value

    @field_validator('state')
    def state_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['STATE_UNSPECIFIED', 'MAINTENANCE', 'DRAFT', 'CREATING', 'NOT_STARTED', 'RUNNING', 'FAILED', 'COMPLETED', 'DELETING', 'STOPPING', 'STOPPED', 'DELETED', 'UPDATING', 'STARTING', 'RESTARTING', 'RESUMING']):
            raise ValueError("must be one of enum values ('STATE_UNSPECIFIED', 'MAINTENANCE', 'DRAFT', 'CREATING', 'NOT_STARTED', 'RUNNING', 'FAILED', 'COMPLETED', 'DELETING', 'STOPPING', 'STOPPED', 'DELETED', 'UPDATING', 'STARTING', 'RESTARTING', 'RESUMING')")
        return value

    @field_validator('type')
    def type_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['TYPE_UNSPECIFIED', 'ONE_TIME', 'CONTINUOUS']):
            raise ValueError("must be one of enum values ('TYPE_UNSPECIFIED', 'ONE_TIME', 'CONTINUOUS')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of MigrationJob from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        """
        excluded_fields: Set[str] = set([
            "create_time",
            "duration",
            "end_time",
            "phase",
            "update_time",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of conversion_workspace
        if self.conversion_workspace:
            _dict['conversionWorkspace'] = self.conversion_workspace.to_dict()
        # override the default output from pydantic by calling `to_dict()` of destination_database
        if self.destination_database:
            _dict['destinationDatabase'] = self.destination_database.to_dict()
        # override the default output from pydantic by calling `to_dict()` of dump_flags
        if self.dump_flags:
            _dict['dumpFlags'] = self.dump_flags.to_dict()
        # override the default output from pydantic by calling `to_dict()` of error
        if self.error:
            _dict['error'] = self.error.to_dict()
        # override the default output from pydantic by calling `to_dict()` of performance_config
        if self.performance_config:
            _dict['performanceConfig'] = self.performance_config.to_dict()
        # override the default output from pydantic by calling `to_dict()` of reverse_ssh_connectivity
        if self.reverse_ssh_connectivity:
            _dict['reverseSshConnectivity'] = self.reverse_ssh_connectivity.to_dict()
        # override the default output from pydantic by calling `to_dict()` of source_database
        if self.source_database:
            _dict['sourceDatabase'] = self.source_database.to_dict()
        # override the default output from pydantic by calling `to_dict()` of vpc_peering_connectivity
        if self.vpc_peering_connectivity:
            _dict['vpcPeeringConnectivity'] = self.vpc_peering_connectivity.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of MigrationJob from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "cmekKeyName": obj.get("cmekKeyName"),
            "conversionWorkspace": ConversionWorkspaceInfo.from_dict(obj["conversionWorkspace"]) if obj.get("conversionWorkspace") is not None else None,
            "createTime": obj.get("createTime"),
            "destination": obj.get("destination"),
            "destinationDatabase": DatabaseType.from_dict(obj["destinationDatabase"]) if obj.get("destinationDatabase") is not None else None,
            "displayName": obj.get("displayName"),
            "dumpFlags": DumpFlags.from_dict(obj["dumpFlags"]) if obj.get("dumpFlags") is not None else None,
            "dumpPath": obj.get("dumpPath"),
            "duration": obj.get("duration"),
            "endTime": obj.get("endTime"),
            "error": Status.from_dict(obj["error"]) if obj.get("error") is not None else None,
            "filter": obj.get("filter"),
            "labels": obj.get("labels"),
            "name": obj.get("name"),
            "performanceConfig": PerformanceConfig.from_dict(obj["performanceConfig"]) if obj.get("performanceConfig") is not None else None,
            "phase": obj.get("phase"),
            "reverseSshConnectivity": ReverseSshConnectivity.from_dict(obj["reverseSshConnectivity"]) if obj.get("reverseSshConnectivity") is not None else None,
            "source": obj.get("source"),
            "sourceDatabase": DatabaseType.from_dict(obj["sourceDatabase"]) if obj.get("sourceDatabase") is not None else None,
            "state": obj.get("state"),
            "staticIpConnectivity": obj.get("staticIpConnectivity"),
            "type": obj.get("type"),
            "updateTime": obj.get("updateTime"),
            "vpcPeeringConnectivity": VpcPeeringConnectivity.from_dict(obj["vpcPeeringConnectivity"]) if obj.get("vpcPeeringConnectivity") is not None else None
        })
        return _obj


