# coding: utf-8

"""
    Database Migration API

    Manage Cloud Database Migration Service resources on Google Cloud Platform.

    The version of the OpenAPI document: v1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictInt, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.source_numeric_filter import SourceNumericFilter
from openapi_client.models.source_text_filter import SourceTextFilter
from typing import Optional, Set
from typing_extensions import Self

class MultiColumnDatatypeChange(BaseModel):
    """
    Options to configure rule type MultiColumnDatatypeChange. The rule is used to change the data type and associated properties of multiple columns at once. The rule filter field can refer to one or more entities. The rule scope can be one of:Column. This rule requires additional filters to be specified beyond the basic rule filter field, which is the source data type, but the rule supports additional filtering capabilities such as the minimum and maximum field length. All additional filters which are specified are required to be met in order for the rule to be applied (logical AND between the fields).
    """ # noqa: E501
    custom_features: Optional[Dict[str, Any]] = Field(default=None, description="Optional. Custom engine specific features.", alias="customFeatures")
    new_data_type: Optional[StrictStr] = Field(default=None, description="Required. New data type.", alias="newDataType")
    override_fractional_seconds_precision: Optional[StrictInt] = Field(default=None, description="Optional. Column fractional seconds precision - used only for timestamp based datatypes - if not specified and relevant uses the source column fractional seconds precision.", alias="overrideFractionalSecondsPrecision")
    override_length: Optional[StrictStr] = Field(default=None, description="Optional. Column length - e.g. varchar (50) - if not specified and relevant uses the source column length.", alias="overrideLength")
    override_precision: Optional[StrictInt] = Field(default=None, description="Optional. Column precision - when relevant - if not specified and relevant uses the source column precision.", alias="overridePrecision")
    override_scale: Optional[StrictInt] = Field(default=None, description="Optional. Column scale - when relevant - if not specified and relevant uses the source column scale.", alias="overrideScale")
    source_data_type_filter: Optional[StrictStr] = Field(default=None, description="Required. Filter on source data type.", alias="sourceDataTypeFilter")
    source_numeric_filter: Optional[SourceNumericFilter] = Field(default=None, alias="sourceNumericFilter")
    source_text_filter: Optional[SourceTextFilter] = Field(default=None, alias="sourceTextFilter")
    __properties: ClassVar[List[str]] = ["customFeatures", "newDataType", "overrideFractionalSecondsPrecision", "overrideLength", "overridePrecision", "overrideScale", "sourceDataTypeFilter", "sourceNumericFilter", "sourceTextFilter"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of MultiColumnDatatypeChange from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of source_numeric_filter
        if self.source_numeric_filter:
            _dict['sourceNumericFilter'] = self.source_numeric_filter.to_dict()
        # override the default output from pydantic by calling `to_dict()` of source_text_filter
        if self.source_text_filter:
            _dict['sourceTextFilter'] = self.source_text_filter.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of MultiColumnDatatypeChange from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "customFeatures": obj.get("customFeatures"),
            "newDataType": obj.get("newDataType"),
            "overrideFractionalSecondsPrecision": obj.get("overrideFractionalSecondsPrecision"),
            "overrideLength": obj.get("overrideLength"),
            "overridePrecision": obj.get("overridePrecision"),
            "overrideScale": obj.get("overrideScale"),
            "sourceDataTypeFilter": obj.get("sourceDataTypeFilter"),
            "sourceNumericFilter": SourceNumericFilter.from_dict(obj["sourceNumericFilter"]) if obj.get("sourceNumericFilter") is not None else None,
            "sourceTextFilter": SourceTextFilter.from_dict(obj["sourceTextFilter"]) if obj.get("sourceTextFilter") is not None else None
        })
        return _obj


