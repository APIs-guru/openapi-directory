# coding: utf-8

"""
    Cloud Tasks API

    Manages the execution of large numbers of distributed requests.

    The version of the OpenAPI document: v2beta3
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.app_engine_http_queue import AppEngineHttpQueue
from openapi_client.models.http_target import HttpTarget
from openapi_client.models.queue_stats import QueueStats
from openapi_client.models.rate_limits import RateLimits
from openapi_client.models.retry_config import RetryConfig
from openapi_client.models.stackdriver_logging_config import StackdriverLoggingConfig
from typing import Optional, Set
from typing_extensions import Self

class Queue(BaseModel):
    """
    A queue is a container of related tasks. Queues are configured to manage how those tasks are dispatched. Configurable properties include rate limits, retry options, queue types, and others.
    """ # noqa: E501
    app_engine_http_queue: Optional[AppEngineHttpQueue] = Field(default=None, alias="appEngineHttpQueue")
    http_target: Optional[HttpTarget] = Field(default=None, alias="httpTarget")
    name: Optional[StrictStr] = Field(default=None, description="Caller-specified and required in CreateQueue, after which it becomes output only. The queue name. The queue name must have the following format: `projects/PROJECT_ID/locations/LOCATION_ID/queues/QUEUE_ID` * `PROJECT_ID` can contain letters ([A-Za-z]), numbers ([0-9]), hyphens (-), colons (:), or periods (.). For more information, see [Identifying projects](https://cloud.google.com/resource-manager/docs/creating-managing-projects#identifying_projects) * `LOCATION_ID` is the canonical ID for the queue's location. The list of available locations can be obtained by calling ListLocations. For more information, see https://cloud.google.com/about/locations/. * `QUEUE_ID` can contain letters ([A-Za-z]), numbers ([0-9]), or hyphens (-). The maximum length is 100 characters.")
    purge_time: Optional[StrictStr] = Field(default=None, description="Output only. The last time this queue was purged. All tasks that were created before this time were purged. A queue can be purged using PurgeQueue, the [App Engine Task Queue SDK, or the Cloud Console](https://cloud.google.com/appengine/docs/standard/python/taskqueue/push/deleting-tasks-and-queues#purging_all_tasks_from_a_queue). Purge time will be truncated to the nearest microsecond. Purge time will be unset if the queue has never been purged.", alias="purgeTime")
    rate_limits: Optional[RateLimits] = Field(default=None, alias="rateLimits")
    retry_config: Optional[RetryConfig] = Field(default=None, alias="retryConfig")
    stackdriver_logging_config: Optional[StackdriverLoggingConfig] = Field(default=None, alias="stackdriverLoggingConfig")
    state: Optional[StrictStr] = Field(default=None, description="Output only. The state of the queue. `state` can only be changed by called PauseQueue, ResumeQueue, or uploading [queue.yaml/xml](https://cloud.google.com/appengine/docs/python/config/queueref). UpdateQueue cannot be used to change `state`.")
    stats: Optional[QueueStats] = None
    task_ttl: Optional[StrictStr] = Field(default=None, description="The maximum amount of time that a task will be retained in this queue. After a task has lived for `task_ttl`, the task will be deleted regardless of whether it was dispatched or not. The minimum value is 10 days. The maximum value is 10 years. The value must be given as a string that indicates the length of time (in seconds) followed by `s` (for \"seconds\"). For more information on the format, see the documentation for [Duration](https://protobuf.dev/reference/protobuf/google.protobuf/#duration). Queues created by Cloud Tasks have a default `task_ttl` of 31 days. . Queues created by queue.yaml/xml have a fixed `task_ttl` of the maximum duration, because there is a [storage quota](https://cloud.google.com/appengine/quotas#Task_Queue) for these queues.", alias="taskTtl")
    tombstone_ttl: Optional[StrictStr] = Field(default=None, description="The task tombstone time to live (TTL). After a task is deleted or executed, the task's tombstone is retained for the length of time specified by `tombstone_ttl`. The tombstone is used by task de-duplication; another task with the same name can't be created until the tombstone has expired. For more information about task de-duplication, see the documentation for CreateTaskRequest. The minimum value is 1 hour. The maximum value is 9 days. The value must be given as a string that indicates the length of time (in seconds) followed by `s` (for \"seconds\"). For more information on the format, see the documentation for [Duration](https://protobuf.dev/reference/protobuf/google.protobuf/#duration). Queues created by Cloud Tasks have a default `tombstone_ttl` of 1 hour.", alias="tombstoneTtl")
    type: Optional[StrictStr] = Field(default=None, description="Immutable. The type of a queue (push or pull). `Queue.type` is an immutable property of the queue that is set at the queue creation time. When left unspecified, the default value of `PUSH` is selected.")
    __properties: ClassVar[List[str]] = ["appEngineHttpQueue", "httpTarget", "name", "purgeTime", "rateLimits", "retryConfig", "stackdriverLoggingConfig", "state", "stats", "taskTtl", "tombstoneTtl", "type"]

    @field_validator('state')
    def state_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['STATE_UNSPECIFIED', 'RUNNING', 'PAUSED', 'DISABLED']):
            raise ValueError("must be one of enum values ('STATE_UNSPECIFIED', 'RUNNING', 'PAUSED', 'DISABLED')")
        return value

    @field_validator('type')
    def type_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['TYPE_UNSPECIFIED', 'PULL', 'PUSH']):
            raise ValueError("must be one of enum values ('TYPE_UNSPECIFIED', 'PULL', 'PUSH')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of Queue from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of app_engine_http_queue
        if self.app_engine_http_queue:
            _dict['appEngineHttpQueue'] = self.app_engine_http_queue.to_dict()
        # override the default output from pydantic by calling `to_dict()` of http_target
        if self.http_target:
            _dict['httpTarget'] = self.http_target.to_dict()
        # override the default output from pydantic by calling `to_dict()` of rate_limits
        if self.rate_limits:
            _dict['rateLimits'] = self.rate_limits.to_dict()
        # override the default output from pydantic by calling `to_dict()` of retry_config
        if self.retry_config:
            _dict['retryConfig'] = self.retry_config.to_dict()
        # override the default output from pydantic by calling `to_dict()` of stackdriver_logging_config
        if self.stackdriver_logging_config:
            _dict['stackdriverLoggingConfig'] = self.stackdriver_logging_config.to_dict()
        # override the default output from pydantic by calling `to_dict()` of stats
        if self.stats:
            _dict['stats'] = self.stats.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of Queue from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "appEngineHttpQueue": AppEngineHttpQueue.from_dict(obj["appEngineHttpQueue"]) if obj.get("appEngineHttpQueue") is not None else None,
            "httpTarget": HttpTarget.from_dict(obj["httpTarget"]) if obj.get("httpTarget") is not None else None,
            "name": obj.get("name"),
            "purgeTime": obj.get("purgeTime"),
            "rateLimits": RateLimits.from_dict(obj["rateLimits"]) if obj.get("rateLimits") is not None else None,
            "retryConfig": RetryConfig.from_dict(obj["retryConfig"]) if obj.get("retryConfig") is not None else None,
            "stackdriverLoggingConfig": StackdriverLoggingConfig.from_dict(obj["stackdriverLoggingConfig"]) if obj.get("stackdriverLoggingConfig") is not None else None,
            "state": obj.get("state"),
            "stats": QueueStats.from_dict(obj["stats"]) if obj.get("stats") is not None else None,
            "taskTtl": obj.get("taskTtl"),
            "tombstoneTtl": obj.get("tombstoneTtl"),
            "type": obj.get("type")
        })
        return _obj


