# coding: utf-8

"""
    Google Sheets API

    Reads and writes Google Sheets.

    The version of the OpenAPI document: v4
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.data_execution_status import DataExecutionStatus
from openapi_client.models.grid_range import GridRange
from openapi_client.models.pivot_filter_criteria import PivotFilterCriteria
from openapi_client.models.pivot_filter_spec import PivotFilterSpec
from openapi_client.models.pivot_group import PivotGroup
from openapi_client.models.pivot_value import PivotValue
from typing import Optional, Set
from typing_extensions import Self

class PivotTable(BaseModel):
    """
    A pivot table.
    """ # noqa: E501
    columns: Optional[List[PivotGroup]] = Field(default=None, description="Each column grouping in the pivot table.")
    criteria: Optional[Dict[str, PivotFilterCriteria]] = Field(default=None, description="An optional mapping of filters per source column offset. The filters are applied before aggregating data into the pivot table. The map's key is the column offset of the source range that you want to filter, and the value is the criteria for that column. For example, if the source was `C10:E15`, a key of `0` will have the filter for column `C`, whereas the key `1` is for column `D`. This field is deprecated in favor of filter_specs.")
    data_execution_status: Optional[DataExecutionStatus] = Field(default=None, alias="dataExecutionStatus")
    data_source_id: Optional[StrictStr] = Field(default=None, description="The ID of the data source the pivot table is reading data from.", alias="dataSourceId")
    filter_specs: Optional[List[PivotFilterSpec]] = Field(default=None, description="The filters applied to the source columns before aggregating data for the pivot table. Both criteria and filter_specs are populated in responses. If both fields are specified in an update request, this field takes precedence.", alias="filterSpecs")
    rows: Optional[List[PivotGroup]] = Field(default=None, description="Each row grouping in the pivot table.")
    source: Optional[GridRange] = None
    value_layout: Optional[StrictStr] = Field(default=None, description="Whether values should be listed horizontally (as columns) or vertically (as rows).", alias="valueLayout")
    values: Optional[List[PivotValue]] = Field(default=None, description="A list of values to include in the pivot table.")
    __properties: ClassVar[List[str]] = ["columns", "criteria", "dataExecutionStatus", "dataSourceId", "filterSpecs", "rows", "source", "valueLayout", "values"]

    @field_validator('value_layout')
    def value_layout_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['HORIZONTAL', 'VERTICAL']):
            raise ValueError("must be one of enum values ('HORIZONTAL', 'VERTICAL')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of PivotTable from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in columns (list)
        _items = []
        if self.columns:
            for _item_columns in self.columns:
                if _item_columns:
                    _items.append(_item_columns.to_dict())
            _dict['columns'] = _items
        # override the default output from pydantic by calling `to_dict()` of each value in criteria (dict)
        _field_dict = {}
        if self.criteria:
            for _key_criteria in self.criteria:
                if self.criteria[_key_criteria]:
                    _field_dict[_key_criteria] = self.criteria[_key_criteria].to_dict()
            _dict['criteria'] = _field_dict
        # override the default output from pydantic by calling `to_dict()` of data_execution_status
        if self.data_execution_status:
            _dict['dataExecutionStatus'] = self.data_execution_status.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in filter_specs (list)
        _items = []
        if self.filter_specs:
            for _item_filter_specs in self.filter_specs:
                if _item_filter_specs:
                    _items.append(_item_filter_specs.to_dict())
            _dict['filterSpecs'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in rows (list)
        _items = []
        if self.rows:
            for _item_rows in self.rows:
                if _item_rows:
                    _items.append(_item_rows.to_dict())
            _dict['rows'] = _items
        # override the default output from pydantic by calling `to_dict()` of source
        if self.source:
            _dict['source'] = self.source.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in values (list)
        _items = []
        if self.values:
            for _item_values in self.values:
                if _item_values:
                    _items.append(_item_values.to_dict())
            _dict['values'] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of PivotTable from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "columns": [PivotGroup.from_dict(_item) for _item in obj["columns"]] if obj.get("columns") is not None else None,
            "criteria": dict(
                (_k, PivotFilterCriteria.from_dict(_v))
                for _k, _v in obj["criteria"].items()
            )
            if obj.get("criteria") is not None
            else None,
            "dataExecutionStatus": DataExecutionStatus.from_dict(obj["dataExecutionStatus"]) if obj.get("dataExecutionStatus") is not None else None,
            "dataSourceId": obj.get("dataSourceId"),
            "filterSpecs": [PivotFilterSpec.from_dict(_item) for _item in obj["filterSpecs"]] if obj.get("filterSpecs") is not None else None,
            "rows": [PivotGroup.from_dict(_item) for _item in obj["rows"]] if obj.get("rows") is not None else None,
            "source": GridRange.from_dict(obj["source"]) if obj.get("source") is not None else None,
            "valueLayout": obj.get("valueLayout"),
            "values": [PivotValue.from_dict(_item) for _item in obj["values"]] if obj.get("values") is not None else None
        })
        return _obj


