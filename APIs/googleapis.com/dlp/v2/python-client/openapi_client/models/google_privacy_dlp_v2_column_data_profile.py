# coding: utf-8

"""
    Sensitive Data Protection (DLP)

    Discover and protect your sensitive data. A fully managed service designed to help you discover, classify, and protect your valuable data assets with ease.

    The version of the OpenAPI document: v2
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictFloat, StrictInt, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional, Union
from openapi_client.models.google_privacy_dlp_v2_data_risk_level import GooglePrivacyDlpV2DataRiskLevel
from openapi_client.models.google_privacy_dlp_v2_info_type_summary import GooglePrivacyDlpV2InfoTypeSummary
from openapi_client.models.google_privacy_dlp_v2_other_info_type_summary import GooglePrivacyDlpV2OtherInfoTypeSummary
from openapi_client.models.google_privacy_dlp_v2_profile_status import GooglePrivacyDlpV2ProfileStatus
from openapi_client.models.google_privacy_dlp_v2_sensitivity_score import GooglePrivacyDlpV2SensitivityScore
from typing import Optional, Set
from typing_extensions import Self

class GooglePrivacyDlpV2ColumnDataProfile(BaseModel):
    """
    The profile for a scanned column within a table.
    """ # noqa: E501
    column: Optional[StrictStr] = Field(default=None, description="The name of the column.")
    column_info_type: Optional[GooglePrivacyDlpV2InfoTypeSummary] = Field(default=None, alias="columnInfoType")
    column_type: Optional[StrictStr] = Field(default=None, description="The data type of a given column.", alias="columnType")
    data_risk_level: Optional[GooglePrivacyDlpV2DataRiskLevel] = Field(default=None, alias="dataRiskLevel")
    dataset_id: Optional[StrictStr] = Field(default=None, description="The BigQuery dataset ID.", alias="datasetId")
    dataset_location: Optional[StrictStr] = Field(default=None, description="The BigQuery location where the dataset's data is stored. See https://cloud.google.com/bigquery/docs/locations for supported locations.", alias="datasetLocation")
    dataset_project_id: Optional[StrictStr] = Field(default=None, description="The Google Cloud project ID that owns the profiled resource.", alias="datasetProjectId")
    estimated_null_percentage: Optional[StrictStr] = Field(default=None, description="Approximate percentage of entries being null in the column.", alias="estimatedNullPercentage")
    estimated_uniqueness_score: Optional[StrictStr] = Field(default=None, description="Approximate uniqueness of the column.", alias="estimatedUniquenessScore")
    free_text_score: Optional[Union[StrictFloat, StrictInt]] = Field(default=None, description="The likelihood that this column contains free-form text. A value close to 1 may indicate the column is likely to contain free-form or natural language text. Range in 0-1.", alias="freeTextScore")
    name: Optional[StrictStr] = Field(default=None, description="The name of the profile.")
    other_matches: Optional[List[GooglePrivacyDlpV2OtherInfoTypeSummary]] = Field(default=None, description="Other types found within this column. List will be unordered.", alias="otherMatches")
    policy_state: Optional[StrictStr] = Field(default=None, description="Indicates if a policy tag has been applied to the column.", alias="policyState")
    profile_last_generated: Optional[StrictStr] = Field(default=None, description="The last time the profile was generated.", alias="profileLastGenerated")
    profile_status: Optional[GooglePrivacyDlpV2ProfileStatus] = Field(default=None, alias="profileStatus")
    sensitivity_score: Optional[GooglePrivacyDlpV2SensitivityScore] = Field(default=None, alias="sensitivityScore")
    state: Optional[StrictStr] = Field(default=None, description="State of a profile.")
    table_data_profile: Optional[StrictStr] = Field(default=None, description="The resource name of the table data profile.", alias="tableDataProfile")
    table_full_resource: Optional[StrictStr] = Field(default=None, description="The resource name of the resource this column is within.", alias="tableFullResource")
    table_id: Optional[StrictStr] = Field(default=None, description="The BigQuery table ID.", alias="tableId")
    __properties: ClassVar[List[str]] = ["column", "columnInfoType", "columnType", "dataRiskLevel", "datasetId", "datasetLocation", "datasetProjectId", "estimatedNullPercentage", "estimatedUniquenessScore", "freeTextScore", "name", "otherMatches", "policyState", "profileLastGenerated", "profileStatus", "sensitivityScore", "state", "tableDataProfile", "tableFullResource", "tableId"]

    @field_validator('column_type')
    def column_type_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['COLUMN_DATA_TYPE_UNSPECIFIED', 'TYPE_INT64', 'TYPE_BOOL', 'TYPE_FLOAT64', 'TYPE_STRING', 'TYPE_BYTES', 'TYPE_TIMESTAMP', 'TYPE_DATE', 'TYPE_TIME', 'TYPE_DATETIME', 'TYPE_GEOGRAPHY', 'TYPE_NUMERIC', 'TYPE_RECORD', 'TYPE_BIGNUMERIC', 'TYPE_JSON']):
            raise ValueError("must be one of enum values ('COLUMN_DATA_TYPE_UNSPECIFIED', 'TYPE_INT64', 'TYPE_BOOL', 'TYPE_FLOAT64', 'TYPE_STRING', 'TYPE_BYTES', 'TYPE_TIMESTAMP', 'TYPE_DATE', 'TYPE_TIME', 'TYPE_DATETIME', 'TYPE_GEOGRAPHY', 'TYPE_NUMERIC', 'TYPE_RECORD', 'TYPE_BIGNUMERIC', 'TYPE_JSON')")
        return value

    @field_validator('estimated_null_percentage')
    def estimated_null_percentage_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['NULL_PERCENTAGE_LEVEL_UNSPECIFIED', 'NULL_PERCENTAGE_VERY_LOW', 'NULL_PERCENTAGE_LOW', 'NULL_PERCENTAGE_MEDIUM', 'NULL_PERCENTAGE_HIGH']):
            raise ValueError("must be one of enum values ('NULL_PERCENTAGE_LEVEL_UNSPECIFIED', 'NULL_PERCENTAGE_VERY_LOW', 'NULL_PERCENTAGE_LOW', 'NULL_PERCENTAGE_MEDIUM', 'NULL_PERCENTAGE_HIGH')")
        return value

    @field_validator('estimated_uniqueness_score')
    def estimated_uniqueness_score_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['UNIQUENESS_SCORE_LEVEL_UNSPECIFIED', 'UNIQUENESS_SCORE_LOW', 'UNIQUENESS_SCORE_MEDIUM', 'UNIQUENESS_SCORE_HIGH']):
            raise ValueError("must be one of enum values ('UNIQUENESS_SCORE_LEVEL_UNSPECIFIED', 'UNIQUENESS_SCORE_LOW', 'UNIQUENESS_SCORE_MEDIUM', 'UNIQUENESS_SCORE_HIGH')")
        return value

    @field_validator('policy_state')
    def policy_state_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['COLUMN_POLICY_STATE_UNSPECIFIED', 'COLUMN_POLICY_TAGGED']):
            raise ValueError("must be one of enum values ('COLUMN_POLICY_STATE_UNSPECIFIED', 'COLUMN_POLICY_TAGGED')")
        return value

    @field_validator('state')
    def state_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['STATE_UNSPECIFIED', 'RUNNING', 'DONE']):
            raise ValueError("must be one of enum values ('STATE_UNSPECIFIED', 'RUNNING', 'DONE')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of GooglePrivacyDlpV2ColumnDataProfile from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of column_info_type
        if self.column_info_type:
            _dict['columnInfoType'] = self.column_info_type.to_dict()
        # override the default output from pydantic by calling `to_dict()` of data_risk_level
        if self.data_risk_level:
            _dict['dataRiskLevel'] = self.data_risk_level.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in other_matches (list)
        _items = []
        if self.other_matches:
            for _item_other_matches in self.other_matches:
                if _item_other_matches:
                    _items.append(_item_other_matches.to_dict())
            _dict['otherMatches'] = _items
        # override the default output from pydantic by calling `to_dict()` of profile_status
        if self.profile_status:
            _dict['profileStatus'] = self.profile_status.to_dict()
        # override the default output from pydantic by calling `to_dict()` of sensitivity_score
        if self.sensitivity_score:
            _dict['sensitivityScore'] = self.sensitivity_score.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of GooglePrivacyDlpV2ColumnDataProfile from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "column": obj.get("column"),
            "columnInfoType": GooglePrivacyDlpV2InfoTypeSummary.from_dict(obj["columnInfoType"]) if obj.get("columnInfoType") is not None else None,
            "columnType": obj.get("columnType"),
            "dataRiskLevel": GooglePrivacyDlpV2DataRiskLevel.from_dict(obj["dataRiskLevel"]) if obj.get("dataRiskLevel") is not None else None,
            "datasetId": obj.get("datasetId"),
            "datasetLocation": obj.get("datasetLocation"),
            "datasetProjectId": obj.get("datasetProjectId"),
            "estimatedNullPercentage": obj.get("estimatedNullPercentage"),
            "estimatedUniquenessScore": obj.get("estimatedUniquenessScore"),
            "freeTextScore": obj.get("freeTextScore"),
            "name": obj.get("name"),
            "otherMatches": [GooglePrivacyDlpV2OtherInfoTypeSummary.from_dict(_item) for _item in obj["otherMatches"]] if obj.get("otherMatches") is not None else None,
            "policyState": obj.get("policyState"),
            "profileLastGenerated": obj.get("profileLastGenerated"),
            "profileStatus": GooglePrivacyDlpV2ProfileStatus.from_dict(obj["profileStatus"]) if obj.get("profileStatus") is not None else None,
            "sensitivityScore": GooglePrivacyDlpV2SensitivityScore.from_dict(obj["sensitivityScore"]) if obj.get("sensitivityScore") is not None else None,
            "state": obj.get("state"),
            "tableDataProfile": obj.get("tableDataProfile"),
            "tableFullResource": obj.get("tableFullResource"),
            "tableId": obj.get("tableId")
        })
        return _obj


