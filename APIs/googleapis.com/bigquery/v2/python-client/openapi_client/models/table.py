# coding: utf-8

"""
    BigQuery API

    A data platform for customers to create, manage, share and query data.

    The version of the OpenAPI document: v2
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.big_lake_configuration import BigLakeConfiguration
from openapi_client.models.clone_definition import CloneDefinition
from openapi_client.models.clustering import Clustering
from openapi_client.models.encryption_configuration import EncryptionConfiguration
from openapi_client.models.external_data_configuration import ExternalDataConfiguration
from openapi_client.models.materialized_view_definition import MaterializedViewDefinition
from openapi_client.models.materialized_view_status import MaterializedViewStatus
from openapi_client.models.model_definition import ModelDefinition
from openapi_client.models.range_partitioning import RangePartitioning
from openapi_client.models.snapshot_definition import SnapshotDefinition
from openapi_client.models.streamingbuffer import Streamingbuffer
from openapi_client.models.table_constraints import TableConstraints
from openapi_client.models.table_reference import TableReference
from openapi_client.models.table_replication_info import TableReplicationInfo
from openapi_client.models.table_schema import TableSchema
from openapi_client.models.time_partitioning import TimePartitioning
from openapi_client.models.view_definition import ViewDefinition
from typing import Optional, Set
from typing_extensions import Self

class Table(BaseModel):
    """
    Table
    """ # noqa: E501
    biglake_configuration: Optional[BigLakeConfiguration] = Field(default=None, alias="biglakeConfiguration")
    clone_definition: Optional[CloneDefinition] = Field(default=None, alias="cloneDefinition")
    clustering: Optional[Clustering] = None
    creation_time: Optional[StrictStr] = Field(default=None, description="Output only. The time when this table was created, in milliseconds since the epoch.", alias="creationTime")
    default_collation: Optional[StrictStr] = Field(default=None, description="Optional. Defines the default collation specification of new STRING fields in the table. During table creation or update, if a STRING field is added to this table without explicit collation specified, then the table inherits the table default collation. A change to this field affects only fields added afterwards, and does not alter the existing fields. The following values are supported: * 'und:ci': undetermined locale, case insensitive. * '': empty string. Default to case-sensitive behavior.", alias="defaultCollation")
    default_rounding_mode: Optional[StrictStr] = Field(default=None, description="Optional. Defines the default rounding mode specification of new decimal fields (NUMERIC OR BIGNUMERIC) in the table. During table creation or update, if a decimal field is added to this table without an explicit rounding mode specified, then the field inherits the table default rounding mode. Changing this field doesn't affect existing fields.", alias="defaultRoundingMode")
    description: Optional[StrictStr] = Field(default=None, description="Optional. A user-friendly description of this table.")
    encryption_configuration: Optional[EncryptionConfiguration] = Field(default=None, alias="encryptionConfiguration")
    etag: Optional[StrictStr] = Field(default=None, description="Output only. A hash of this resource.")
    expiration_time: Optional[StrictStr] = Field(default=None, description="Optional. The time when this table expires, in milliseconds since the epoch. If not present, the table will persist indefinitely. Expired tables will be deleted and their storage reclaimed. The defaultTableExpirationMs property of the encapsulating dataset can be used to set a default expirationTime on newly created tables.", alias="expirationTime")
    external_data_configuration: Optional[ExternalDataConfiguration] = Field(default=None, alias="externalDataConfiguration")
    friendly_name: Optional[StrictStr] = Field(default=None, description="Optional. A descriptive name for this table.", alias="friendlyName")
    id: Optional[StrictStr] = Field(default=None, description="Output only. An opaque ID uniquely identifying the table.")
    kind: Optional[StrictStr] = Field(default='bigquery#table', description="The type of resource ID.")
    labels: Optional[Dict[str, StrictStr]] = Field(default=None, description="The labels associated with this table. You can use these to organize and group your tables. Label keys and values can be no longer than 63 characters, can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. Label values are optional. Label keys must start with a letter and each label in the list must have a different key.")
    last_modified_time: Optional[StrictStr] = Field(default=None, description="Output only. The time when this table was last modified, in milliseconds since the epoch.", alias="lastModifiedTime")
    location: Optional[StrictStr] = Field(default=None, description="Output only. The geographic location where the table resides. This value is inherited from the dataset.")
    materialized_view: Optional[MaterializedViewDefinition] = Field(default=None, alias="materializedView")
    materialized_view_status: Optional[MaterializedViewStatus] = Field(default=None, alias="materializedViewStatus")
    max_staleness: Optional[StrictStr] = Field(default=None, description="Optional. The maximum staleness of data that could be returned when the table (or stale MV) is queried. Staleness encoded as a string encoding of sql IntervalValue type.", alias="maxStaleness")
    model: Optional[ModelDefinition] = None
    num_active_logical_bytes: Optional[StrictStr] = Field(default=None, description="Output only. Number of logical bytes that are less than 90 days old.", alias="numActiveLogicalBytes")
    num_active_physical_bytes: Optional[StrictStr] = Field(default=None, description="Output only. Number of physical bytes less than 90 days old. This data is not kept in real time, and might be delayed by a few seconds to a few minutes.", alias="numActivePhysicalBytes")
    num_bytes: Optional[StrictStr] = Field(default=None, description="Output only. The size of this table in logical bytes, excluding any data in the streaming buffer.", alias="numBytes")
    num_long_term_bytes: Optional[StrictStr] = Field(default=None, description="Output only. The number of logical bytes in the table that are considered \"long-term storage\".", alias="numLongTermBytes")
    num_long_term_logical_bytes: Optional[StrictStr] = Field(default=None, description="Output only. Number of logical bytes that are more than 90 days old.", alias="numLongTermLogicalBytes")
    num_long_term_physical_bytes: Optional[StrictStr] = Field(default=None, description="Output only. Number of physical bytes more than 90 days old. This data is not kept in real time, and might be delayed by a few seconds to a few minutes.", alias="numLongTermPhysicalBytes")
    num_partitions: Optional[StrictStr] = Field(default=None, description="Output only. The number of partitions present in the table or materialized view. This data is not kept in real time, and might be delayed by a few seconds to a few minutes.", alias="numPartitions")
    num_physical_bytes: Optional[StrictStr] = Field(default=None, description="Output only. The physical size of this table in bytes. This includes storage used for time travel.", alias="numPhysicalBytes")
    num_rows: Optional[StrictStr] = Field(default=None, description="Output only. The number of rows of data in this table, excluding any data in the streaming buffer.", alias="numRows")
    num_time_travel_physical_bytes: Optional[StrictStr] = Field(default=None, description="Output only. Number of physical bytes used by time travel storage (deleted or changed data). This data is not kept in real time, and might be delayed by a few seconds to a few minutes.", alias="numTimeTravelPhysicalBytes")
    num_total_logical_bytes: Optional[StrictStr] = Field(default=None, description="Output only. Total number of logical bytes in the table or materialized view.", alias="numTotalLogicalBytes")
    num_total_physical_bytes: Optional[StrictStr] = Field(default=None, description="Output only. The physical size of this table in bytes. This also includes storage used for time travel. This data is not kept in real time, and might be delayed by a few seconds to a few minutes.", alias="numTotalPhysicalBytes")
    range_partitioning: Optional[RangePartitioning] = Field(default=None, alias="rangePartitioning")
    replicas: Optional[List[TableReference]] = Field(default=None, description="Optional. Output only. Table references of all replicas currently active on the table.")
    require_partition_filter: Optional[StrictBool] = Field(default=False, description="Optional. If set to true, queries over this table require a partition filter that can be used for partition elimination to be specified.", alias="requirePartitionFilter")
    resource_tags: Optional[Dict[str, StrictStr]] = Field(default=None, description="[Optional] The tags associated with this table. Tag keys are globally unique. See additional information on [tags](https://cloud.google.com/iam/docs/tags-access-control#definitions). An object containing a list of \"key\": value pairs. The key is the namespaced friendly name of the tag key, e.g. \"12345/environment\" where 12345 is parent id. The value is the friendly short name of the tag value, e.g. \"production\".", alias="resourceTags")
    var_schema: Optional[TableSchema] = Field(default=None, alias="schema")
    self_link: Optional[StrictStr] = Field(default=None, description="Output only. A URL that can be used to access this resource again.", alias="selfLink")
    snapshot_definition: Optional[SnapshotDefinition] = Field(default=None, alias="snapshotDefinition")
    streaming_buffer: Optional[Streamingbuffer] = Field(default=None, alias="streamingBuffer")
    table_constraints: Optional[TableConstraints] = Field(default=None, alias="tableConstraints")
    table_reference: Optional[TableReference] = Field(default=None, alias="tableReference")
    table_replication_info: Optional[TableReplicationInfo] = Field(default=None, alias="tableReplicationInfo")
    time_partitioning: Optional[TimePartitioning] = Field(default=None, alias="timePartitioning")
    type: Optional[StrictStr] = Field(default=None, description="Output only. Describes the table type. The following values are supported: * `TABLE`: A normal BigQuery table. * `VIEW`: A virtual table defined by a SQL query. * `EXTERNAL`: A table that references data stored in an external storage system, such as Google Cloud Storage. * `MATERIALIZED_VIEW`: A precomputed view defined by a SQL query. * `SNAPSHOT`: An immutable BigQuery table that preserves the contents of a base table at a particular time. See additional information on [table snapshots](/bigquery/docs/table-snapshots-intro). The default value is `TABLE`.")
    view: Optional[ViewDefinition] = None
    __properties: ClassVar[List[str]] = ["biglakeConfiguration", "cloneDefinition", "clustering", "creationTime", "defaultCollation", "defaultRoundingMode", "description", "encryptionConfiguration", "etag", "expirationTime", "externalDataConfiguration", "friendlyName", "id", "kind", "labels", "lastModifiedTime", "location", "materializedView", "materializedViewStatus", "maxStaleness", "model", "numActiveLogicalBytes", "numActivePhysicalBytes", "numBytes", "numLongTermBytes", "numLongTermLogicalBytes", "numLongTermPhysicalBytes", "numPartitions", "numPhysicalBytes", "numRows", "numTimeTravelPhysicalBytes", "numTotalLogicalBytes", "numTotalPhysicalBytes", "rangePartitioning", "replicas", "requirePartitionFilter", "resourceTags", "schema", "selfLink", "snapshotDefinition", "streamingBuffer", "tableConstraints", "tableReference", "tableReplicationInfo", "timePartitioning", "type", "view"]

    @field_validator('default_rounding_mode')
    def default_rounding_mode_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['ROUNDING_MODE_UNSPECIFIED', 'ROUND_HALF_AWAY_FROM_ZERO', 'ROUND_HALF_EVEN']):
            raise ValueError("must be one of enum values ('ROUNDING_MODE_UNSPECIFIED', 'ROUND_HALF_AWAY_FROM_ZERO', 'ROUND_HALF_EVEN')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of Table from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        """
        excluded_fields: Set[str] = set([
            "creation_time",
            "etag",
            "id",
            "last_modified_time",
            "location",
            "num_active_logical_bytes",
            "num_active_physical_bytes",
            "num_bytes",
            "num_long_term_bytes",
            "num_long_term_logical_bytes",
            "num_long_term_physical_bytes",
            "num_partitions",
            "num_physical_bytes",
            "num_rows",
            "num_time_travel_physical_bytes",
            "num_total_logical_bytes",
            "num_total_physical_bytes",
            "replicas",
            "self_link",
            "type",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of biglake_configuration
        if self.biglake_configuration:
            _dict['biglakeConfiguration'] = self.biglake_configuration.to_dict()
        # override the default output from pydantic by calling `to_dict()` of clone_definition
        if self.clone_definition:
            _dict['cloneDefinition'] = self.clone_definition.to_dict()
        # override the default output from pydantic by calling `to_dict()` of clustering
        if self.clustering:
            _dict['clustering'] = self.clustering.to_dict()
        # override the default output from pydantic by calling `to_dict()` of encryption_configuration
        if self.encryption_configuration:
            _dict['encryptionConfiguration'] = self.encryption_configuration.to_dict()
        # override the default output from pydantic by calling `to_dict()` of external_data_configuration
        if self.external_data_configuration:
            _dict['externalDataConfiguration'] = self.external_data_configuration.to_dict()
        # override the default output from pydantic by calling `to_dict()` of materialized_view
        if self.materialized_view:
            _dict['materializedView'] = self.materialized_view.to_dict()
        # override the default output from pydantic by calling `to_dict()` of materialized_view_status
        if self.materialized_view_status:
            _dict['materializedViewStatus'] = self.materialized_view_status.to_dict()
        # override the default output from pydantic by calling `to_dict()` of model
        if self.model:
            _dict['model'] = self.model.to_dict()
        # override the default output from pydantic by calling `to_dict()` of range_partitioning
        if self.range_partitioning:
            _dict['rangePartitioning'] = self.range_partitioning.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in replicas (list)
        _items = []
        if self.replicas:
            for _item_replicas in self.replicas:
                if _item_replicas:
                    _items.append(_item_replicas.to_dict())
            _dict['replicas'] = _items
        # override the default output from pydantic by calling `to_dict()` of var_schema
        if self.var_schema:
            _dict['schema'] = self.var_schema.to_dict()
        # override the default output from pydantic by calling `to_dict()` of snapshot_definition
        if self.snapshot_definition:
            _dict['snapshotDefinition'] = self.snapshot_definition.to_dict()
        # override the default output from pydantic by calling `to_dict()` of streaming_buffer
        if self.streaming_buffer:
            _dict['streamingBuffer'] = self.streaming_buffer.to_dict()
        # override the default output from pydantic by calling `to_dict()` of table_constraints
        if self.table_constraints:
            _dict['tableConstraints'] = self.table_constraints.to_dict()
        # override the default output from pydantic by calling `to_dict()` of table_reference
        if self.table_reference:
            _dict['tableReference'] = self.table_reference.to_dict()
        # override the default output from pydantic by calling `to_dict()` of table_replication_info
        if self.table_replication_info:
            _dict['tableReplicationInfo'] = self.table_replication_info.to_dict()
        # override the default output from pydantic by calling `to_dict()` of time_partitioning
        if self.time_partitioning:
            _dict['timePartitioning'] = self.time_partitioning.to_dict()
        # override the default output from pydantic by calling `to_dict()` of view
        if self.view:
            _dict['view'] = self.view.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of Table from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "biglakeConfiguration": BigLakeConfiguration.from_dict(obj["biglakeConfiguration"]) if obj.get("biglakeConfiguration") is not None else None,
            "cloneDefinition": CloneDefinition.from_dict(obj["cloneDefinition"]) if obj.get("cloneDefinition") is not None else None,
            "clustering": Clustering.from_dict(obj["clustering"]) if obj.get("clustering") is not None else None,
            "creationTime": obj.get("creationTime"),
            "defaultCollation": obj.get("defaultCollation"),
            "defaultRoundingMode": obj.get("defaultRoundingMode"),
            "description": obj.get("description"),
            "encryptionConfiguration": EncryptionConfiguration.from_dict(obj["encryptionConfiguration"]) if obj.get("encryptionConfiguration") is not None else None,
            "etag": obj.get("etag"),
            "expirationTime": obj.get("expirationTime"),
            "externalDataConfiguration": ExternalDataConfiguration.from_dict(obj["externalDataConfiguration"]) if obj.get("externalDataConfiguration") is not None else None,
            "friendlyName": obj.get("friendlyName"),
            "id": obj.get("id"),
            "kind": obj.get("kind") if obj.get("kind") is not None else 'bigquery#table',
            "labels": obj.get("labels"),
            "lastModifiedTime": obj.get("lastModifiedTime"),
            "location": obj.get("location"),
            "materializedView": MaterializedViewDefinition.from_dict(obj["materializedView"]) if obj.get("materializedView") is not None else None,
            "materializedViewStatus": MaterializedViewStatus.from_dict(obj["materializedViewStatus"]) if obj.get("materializedViewStatus") is not None else None,
            "maxStaleness": obj.get("maxStaleness"),
            "model": ModelDefinition.from_dict(obj["model"]) if obj.get("model") is not None else None,
            "numActiveLogicalBytes": obj.get("numActiveLogicalBytes"),
            "numActivePhysicalBytes": obj.get("numActivePhysicalBytes"),
            "numBytes": obj.get("numBytes"),
            "numLongTermBytes": obj.get("numLongTermBytes"),
            "numLongTermLogicalBytes": obj.get("numLongTermLogicalBytes"),
            "numLongTermPhysicalBytes": obj.get("numLongTermPhysicalBytes"),
            "numPartitions": obj.get("numPartitions"),
            "numPhysicalBytes": obj.get("numPhysicalBytes"),
            "numRows": obj.get("numRows"),
            "numTimeTravelPhysicalBytes": obj.get("numTimeTravelPhysicalBytes"),
            "numTotalLogicalBytes": obj.get("numTotalLogicalBytes"),
            "numTotalPhysicalBytes": obj.get("numTotalPhysicalBytes"),
            "rangePartitioning": RangePartitioning.from_dict(obj["rangePartitioning"]) if obj.get("rangePartitioning") is not None else None,
            "replicas": [TableReference.from_dict(_item) for _item in obj["replicas"]] if obj.get("replicas") is not None else None,
            "requirePartitionFilter": obj.get("requirePartitionFilter") if obj.get("requirePartitionFilter") is not None else False,
            "resourceTags": obj.get("resourceTags"),
            "schema": TableSchema.from_dict(obj["schema"]) if obj.get("schema") is not None else None,
            "selfLink": obj.get("selfLink"),
            "snapshotDefinition": SnapshotDefinition.from_dict(obj["snapshotDefinition"]) if obj.get("snapshotDefinition") is not None else None,
            "streamingBuffer": Streamingbuffer.from_dict(obj["streamingBuffer"]) if obj.get("streamingBuffer") is not None else None,
            "tableConstraints": TableConstraints.from_dict(obj["tableConstraints"]) if obj.get("tableConstraints") is not None else None,
            "tableReference": TableReference.from_dict(obj["tableReference"]) if obj.get("tableReference") is not None else None,
            "tableReplicationInfo": TableReplicationInfo.from_dict(obj["tableReplicationInfo"]) if obj.get("tableReplicationInfo") is not None else None,
            "timePartitioning": TimePartitioning.from_dict(obj["timePartitioning"]) if obj.get("timePartitioning") is not None else None,
            "type": obj.get("type"),
            "view": ViewDefinition.from_dict(obj["view"]) if obj.get("view") is not None else None
        })
        return _obj


