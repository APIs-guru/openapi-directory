# coding: utf-8

"""
    BigQuery API

    A data platform for customers to create, manage, share and query data.

    The version of the OpenAPI document: v2
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.query_timeline_sample import QueryTimelineSample
from typing import Optional, Set
from typing_extensions import Self

class JobStatistics3(BaseModel):
    """
    Statistics for a load job.
    """ # noqa: E501
    bad_records: Optional[StrictStr] = Field(default=None, description="Output only. The number of bad records encountered. Note that if the job has failed because of more bad records encountered than the maximum allowed in the load job configuration, then this number can be less than the total number of bad records present in the input data.", alias="badRecords")
    input_file_bytes: Optional[StrictStr] = Field(default=None, description="Output only. Number of bytes of source data in a load job.", alias="inputFileBytes")
    input_files: Optional[StrictStr] = Field(default=None, description="Output only. Number of source files in a load job.", alias="inputFiles")
    output_bytes: Optional[StrictStr] = Field(default=None, description="Output only. Size of the loaded data in bytes. Note that while a load job is in the running state, this value may change.", alias="outputBytes")
    output_rows: Optional[StrictStr] = Field(default=None, description="Output only. Number of rows imported in a load job. Note that while an import job is in the running state, this value may change.", alias="outputRows")
    timeline: Optional[List[QueryTimelineSample]] = Field(default=None, description="Output only. Describes a timeline of job execution.")
    __properties: ClassVar[List[str]] = ["badRecords", "inputFileBytes", "inputFiles", "outputBytes", "outputRows", "timeline"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of JobStatistics3 from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        """
        excluded_fields: Set[str] = set([
            "bad_records",
            "input_file_bytes",
            "input_files",
            "output_bytes",
            "output_rows",
            "timeline",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in timeline (list)
        _items = []
        if self.timeline:
            for _item_timeline in self.timeline:
                if _item_timeline:
                    _items.append(_item_timeline.to_dict())
            _dict['timeline'] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of JobStatistics3 from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "badRecords": obj.get("badRecords"),
            "inputFileBytes": obj.get("inputFileBytes"),
            "inputFiles": obj.get("inputFiles"),
            "outputBytes": obj.get("outputBytes"),
            "outputRows": obj.get("outputRows"),
            "timeline": [QueryTimelineSample.from_dict(_item) for _item in obj["timeline"]] if obj.get("timeline") is not None else None
        })
        return _obj


