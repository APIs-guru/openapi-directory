# coding: utf-8

"""
    BigQuery API

    A data platform for customers to create, manage, share and query data.

    The version of the OpenAPI document: v2
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.double_hparam_search_space import DoubleHparamSearchSpace
from openapi_client.models.int_array_hparam_search_space import IntArrayHparamSearchSpace
from openapi_client.models.int_hparam_search_space import IntHparamSearchSpace
from openapi_client.models.string_hparam_search_space import StringHparamSearchSpace
from typing import Optional, Set
from typing_extensions import Self

class HparamSearchSpaces(BaseModel):
    """
    Hyperparameter search spaces. These should be a subset of training_options.
    """ # noqa: E501
    activation_fn: Optional[StringHparamSearchSpace] = Field(default=None, alias="activationFn")
    batch_size: Optional[IntHparamSearchSpace] = Field(default=None, alias="batchSize")
    booster_type: Optional[StringHparamSearchSpace] = Field(default=None, alias="boosterType")
    colsample_bylevel: Optional[DoubleHparamSearchSpace] = Field(default=None, alias="colsampleBylevel")
    colsample_bynode: Optional[DoubleHparamSearchSpace] = Field(default=None, alias="colsampleBynode")
    colsample_bytree: Optional[DoubleHparamSearchSpace] = Field(default=None, alias="colsampleBytree")
    dart_normalize_type: Optional[StringHparamSearchSpace] = Field(default=None, alias="dartNormalizeType")
    dropout: Optional[DoubleHparamSearchSpace] = None
    hidden_units: Optional[IntArrayHparamSearchSpace] = Field(default=None, alias="hiddenUnits")
    l1_reg: Optional[DoubleHparamSearchSpace] = Field(default=None, alias="l1Reg")
    l2_reg: Optional[DoubleHparamSearchSpace] = Field(default=None, alias="l2Reg")
    learn_rate: Optional[DoubleHparamSearchSpace] = Field(default=None, alias="learnRate")
    max_tree_depth: Optional[IntHparamSearchSpace] = Field(default=None, alias="maxTreeDepth")
    min_split_loss: Optional[DoubleHparamSearchSpace] = Field(default=None, alias="minSplitLoss")
    min_tree_child_weight: Optional[IntHparamSearchSpace] = Field(default=None, alias="minTreeChildWeight")
    num_clusters: Optional[IntHparamSearchSpace] = Field(default=None, alias="numClusters")
    num_factors: Optional[IntHparamSearchSpace] = Field(default=None, alias="numFactors")
    num_parallel_tree: Optional[IntHparamSearchSpace] = Field(default=None, alias="numParallelTree")
    optimizer: Optional[StringHparamSearchSpace] = None
    subsample: Optional[DoubleHparamSearchSpace] = None
    tree_method: Optional[StringHparamSearchSpace] = Field(default=None, alias="treeMethod")
    wals_alpha: Optional[DoubleHparamSearchSpace] = Field(default=None, alias="walsAlpha")
    __properties: ClassVar[List[str]] = ["activationFn", "batchSize", "boosterType", "colsampleBylevel", "colsampleBynode", "colsampleBytree", "dartNormalizeType", "dropout", "hiddenUnits", "l1Reg", "l2Reg", "learnRate", "maxTreeDepth", "minSplitLoss", "minTreeChildWeight", "numClusters", "numFactors", "numParallelTree", "optimizer", "subsample", "treeMethod", "walsAlpha"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of HparamSearchSpaces from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of activation_fn
        if self.activation_fn:
            _dict['activationFn'] = self.activation_fn.to_dict()
        # override the default output from pydantic by calling `to_dict()` of batch_size
        if self.batch_size:
            _dict['batchSize'] = self.batch_size.to_dict()
        # override the default output from pydantic by calling `to_dict()` of booster_type
        if self.booster_type:
            _dict['boosterType'] = self.booster_type.to_dict()
        # override the default output from pydantic by calling `to_dict()` of colsample_bylevel
        if self.colsample_bylevel:
            _dict['colsampleBylevel'] = self.colsample_bylevel.to_dict()
        # override the default output from pydantic by calling `to_dict()` of colsample_bynode
        if self.colsample_bynode:
            _dict['colsampleBynode'] = self.colsample_bynode.to_dict()
        # override the default output from pydantic by calling `to_dict()` of colsample_bytree
        if self.colsample_bytree:
            _dict['colsampleBytree'] = self.colsample_bytree.to_dict()
        # override the default output from pydantic by calling `to_dict()` of dart_normalize_type
        if self.dart_normalize_type:
            _dict['dartNormalizeType'] = self.dart_normalize_type.to_dict()
        # override the default output from pydantic by calling `to_dict()` of dropout
        if self.dropout:
            _dict['dropout'] = self.dropout.to_dict()
        # override the default output from pydantic by calling `to_dict()` of hidden_units
        if self.hidden_units:
            _dict['hiddenUnits'] = self.hidden_units.to_dict()
        # override the default output from pydantic by calling `to_dict()` of l1_reg
        if self.l1_reg:
            _dict['l1Reg'] = self.l1_reg.to_dict()
        # override the default output from pydantic by calling `to_dict()` of l2_reg
        if self.l2_reg:
            _dict['l2Reg'] = self.l2_reg.to_dict()
        # override the default output from pydantic by calling `to_dict()` of learn_rate
        if self.learn_rate:
            _dict['learnRate'] = self.learn_rate.to_dict()
        # override the default output from pydantic by calling `to_dict()` of max_tree_depth
        if self.max_tree_depth:
            _dict['maxTreeDepth'] = self.max_tree_depth.to_dict()
        # override the default output from pydantic by calling `to_dict()` of min_split_loss
        if self.min_split_loss:
            _dict['minSplitLoss'] = self.min_split_loss.to_dict()
        # override the default output from pydantic by calling `to_dict()` of min_tree_child_weight
        if self.min_tree_child_weight:
            _dict['minTreeChildWeight'] = self.min_tree_child_weight.to_dict()
        # override the default output from pydantic by calling `to_dict()` of num_clusters
        if self.num_clusters:
            _dict['numClusters'] = self.num_clusters.to_dict()
        # override the default output from pydantic by calling `to_dict()` of num_factors
        if self.num_factors:
            _dict['numFactors'] = self.num_factors.to_dict()
        # override the default output from pydantic by calling `to_dict()` of num_parallel_tree
        if self.num_parallel_tree:
            _dict['numParallelTree'] = self.num_parallel_tree.to_dict()
        # override the default output from pydantic by calling `to_dict()` of optimizer
        if self.optimizer:
            _dict['optimizer'] = self.optimizer.to_dict()
        # override the default output from pydantic by calling `to_dict()` of subsample
        if self.subsample:
            _dict['subsample'] = self.subsample.to_dict()
        # override the default output from pydantic by calling `to_dict()` of tree_method
        if self.tree_method:
            _dict['treeMethod'] = self.tree_method.to_dict()
        # override the default output from pydantic by calling `to_dict()` of wals_alpha
        if self.wals_alpha:
            _dict['walsAlpha'] = self.wals_alpha.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of HparamSearchSpaces from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "activationFn": StringHparamSearchSpace.from_dict(obj["activationFn"]) if obj.get("activationFn") is not None else None,
            "batchSize": IntHparamSearchSpace.from_dict(obj["batchSize"]) if obj.get("batchSize") is not None else None,
            "boosterType": StringHparamSearchSpace.from_dict(obj["boosterType"]) if obj.get("boosterType") is not None else None,
            "colsampleBylevel": DoubleHparamSearchSpace.from_dict(obj["colsampleBylevel"]) if obj.get("colsampleBylevel") is not None else None,
            "colsampleBynode": DoubleHparamSearchSpace.from_dict(obj["colsampleBynode"]) if obj.get("colsampleBynode") is not None else None,
            "colsampleBytree": DoubleHparamSearchSpace.from_dict(obj["colsampleBytree"]) if obj.get("colsampleBytree") is not None else None,
            "dartNormalizeType": StringHparamSearchSpace.from_dict(obj["dartNormalizeType"]) if obj.get("dartNormalizeType") is not None else None,
            "dropout": DoubleHparamSearchSpace.from_dict(obj["dropout"]) if obj.get("dropout") is not None else None,
            "hiddenUnits": IntArrayHparamSearchSpace.from_dict(obj["hiddenUnits"]) if obj.get("hiddenUnits") is not None else None,
            "l1Reg": DoubleHparamSearchSpace.from_dict(obj["l1Reg"]) if obj.get("l1Reg") is not None else None,
            "l2Reg": DoubleHparamSearchSpace.from_dict(obj["l2Reg"]) if obj.get("l2Reg") is not None else None,
            "learnRate": DoubleHparamSearchSpace.from_dict(obj["learnRate"]) if obj.get("learnRate") is not None else None,
            "maxTreeDepth": IntHparamSearchSpace.from_dict(obj["maxTreeDepth"]) if obj.get("maxTreeDepth") is not None else None,
            "minSplitLoss": DoubleHparamSearchSpace.from_dict(obj["minSplitLoss"]) if obj.get("minSplitLoss") is not None else None,
            "minTreeChildWeight": IntHparamSearchSpace.from_dict(obj["minTreeChildWeight"]) if obj.get("minTreeChildWeight") is not None else None,
            "numClusters": IntHparamSearchSpace.from_dict(obj["numClusters"]) if obj.get("numClusters") is not None else None,
            "numFactors": IntHparamSearchSpace.from_dict(obj["numFactors"]) if obj.get("numFactors") is not None else None,
            "numParallelTree": IntHparamSearchSpace.from_dict(obj["numParallelTree"]) if obj.get("numParallelTree") is not None else None,
            "optimizer": StringHparamSearchSpace.from_dict(obj["optimizer"]) if obj.get("optimizer") is not None else None,
            "subsample": DoubleHparamSearchSpace.from_dict(obj["subsample"]) if obj.get("subsample") is not None else None,
            "treeMethod": StringHparamSearchSpace.from_dict(obj["treeMethod"]) if obj.get("treeMethod") is not None else None,
            "walsAlpha": DoubleHparamSearchSpace.from_dict(obj["walsAlpha"]) if obj.get("walsAlpha") is not None else None
        })
        return _obj


