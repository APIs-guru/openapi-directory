# coding: utf-8

"""
    BigQuery API

    A data platform for customers to create, manage, share and query data.

    The version of the OpenAPI document: v2
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.dml_statistics import DmlStatistics
from openapi_client.models.error_proto import ErrorProto
from openapi_client.models.job_creation_reason import JobCreationReason
from openapi_client.models.job_reference import JobReference
from openapi_client.models.session_info import SessionInfo
from openapi_client.models.table_row import TableRow
from openapi_client.models.table_schema import TableSchema
from typing import Optional, Set
from typing_extensions import Self

class QueryResponse(BaseModel):
    """
    QueryResponse
    """ # noqa: E501
    cache_hit: Optional[StrictBool] = Field(default=None, description="Whether the query result was fetched from the query cache.", alias="cacheHit")
    dml_stats: Optional[DmlStatistics] = Field(default=None, alias="dmlStats")
    errors: Optional[List[ErrorProto]] = Field(default=None, description="Output only. The first errors or warnings encountered during the running of the job. The final message includes the number of errors that caused the process to stop. Errors here do not necessarily mean that the job has completed or was unsuccessful. For more information about error messages, see [Error messages](https://cloud.google.com/bigquery/docs/error-messages).")
    job_complete: Optional[StrictBool] = Field(default=None, description="Whether the query has completed or not. If rows or totalRows are present, this will always be true. If this is false, totalRows will not be available.", alias="jobComplete")
    job_creation_reason: Optional[JobCreationReason] = Field(default=None, alias="jobCreationReason")
    job_reference: Optional[JobReference] = Field(default=None, alias="jobReference")
    kind: Optional[StrictStr] = Field(default='bigquery#queryResponse', description="The resource type.")
    num_dml_affected_rows: Optional[StrictStr] = Field(default=None, description="Output only. The number of rows affected by a DML statement. Present only for DML statements INSERT, UPDATE or DELETE.", alias="numDmlAffectedRows")
    page_token: Optional[StrictStr] = Field(default=None, description="A token used for paging results. A non-empty token indicates that additional results are available. To see additional results, query the [`jobs.getQueryResults`](https://cloud.google.com/bigquery/docs/reference/rest/v2/jobs/getQueryResults) method. For more information, see [Paging through table data](https://cloud.google.com/bigquery/docs/paging-results).", alias="pageToken")
    query_id: Optional[StrictStr] = Field(default=None, description="Query ID for the completed query. This ID will be auto-generated. This field is not yet available and it is currently not guaranteed to be populated.", alias="queryId")
    rows: Optional[List[TableRow]] = Field(default=None, description="An object with as many results as can be contained within the maximum permitted reply size. To get any additional rows, you can call GetQueryResults and specify the jobReference returned above.")
    var_schema: Optional[TableSchema] = Field(default=None, alias="schema")
    session_info: Optional[SessionInfo] = Field(default=None, alias="sessionInfo")
    total_bytes_processed: Optional[StrictStr] = Field(default=None, description="The total number of bytes processed for this query. If this query was a dry run, this is the number of bytes that would be processed if the query were run.", alias="totalBytesProcessed")
    total_rows: Optional[StrictStr] = Field(default=None, description="The total number of rows in the complete query result set, which can be more than the number of rows in this single page of results.", alias="totalRows")
    __properties: ClassVar[List[str]] = ["cacheHit", "dmlStats", "errors", "jobComplete", "jobCreationReason", "jobReference", "kind", "numDmlAffectedRows", "pageToken", "queryId", "rows", "schema", "sessionInfo", "totalBytesProcessed", "totalRows"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of QueryResponse from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * OpenAPI `readOnly` fields are excluded.
        * OpenAPI `readOnly` fields are excluded.
        """
        excluded_fields: Set[str] = set([
            "errors",
            "num_dml_affected_rows",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of dml_stats
        if self.dml_stats:
            _dict['dmlStats'] = self.dml_stats.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in errors (list)
        _items = []
        if self.errors:
            for _item_errors in self.errors:
                if _item_errors:
                    _items.append(_item_errors.to_dict())
            _dict['errors'] = _items
        # override the default output from pydantic by calling `to_dict()` of job_creation_reason
        if self.job_creation_reason:
            _dict['jobCreationReason'] = self.job_creation_reason.to_dict()
        # override the default output from pydantic by calling `to_dict()` of job_reference
        if self.job_reference:
            _dict['jobReference'] = self.job_reference.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in rows (list)
        _items = []
        if self.rows:
            for _item_rows in self.rows:
                if _item_rows:
                    _items.append(_item_rows.to_dict())
            _dict['rows'] = _items
        # override the default output from pydantic by calling `to_dict()` of var_schema
        if self.var_schema:
            _dict['schema'] = self.var_schema.to_dict()
        # override the default output from pydantic by calling `to_dict()` of session_info
        if self.session_info:
            _dict['sessionInfo'] = self.session_info.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of QueryResponse from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "cacheHit": obj.get("cacheHit"),
            "dmlStats": DmlStatistics.from_dict(obj["dmlStats"]) if obj.get("dmlStats") is not None else None,
            "errors": [ErrorProto.from_dict(_item) for _item in obj["errors"]] if obj.get("errors") is not None else None,
            "jobComplete": obj.get("jobComplete"),
            "jobCreationReason": JobCreationReason.from_dict(obj["jobCreationReason"]) if obj.get("jobCreationReason") is not None else None,
            "jobReference": JobReference.from_dict(obj["jobReference"]) if obj.get("jobReference") is not None else None,
            "kind": obj.get("kind") if obj.get("kind") is not None else 'bigquery#queryResponse',
            "numDmlAffectedRows": obj.get("numDmlAffectedRows"),
            "pageToken": obj.get("pageToken"),
            "queryId": obj.get("queryId"),
            "rows": [TableRow.from_dict(_item) for _item in obj["rows"]] if obj.get("rows") is not None else None,
            "schema": TableSchema.from_dict(obj["schema"]) if obj.get("schema") is not None else None,
            "sessionInfo": SessionInfo.from_dict(obj["sessionInfo"]) if obj.get("sessionInfo") is not None else None,
            "totalBytesProcessed": obj.get("totalBytesProcessed"),
            "totalRows": obj.get("totalRows")
        })
        return _obj


