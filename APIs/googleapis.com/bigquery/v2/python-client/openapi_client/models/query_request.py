# coding: utf-8

"""
    BigQuery API

    A data platform for customers to create, manage, share and query data.

    The version of the OpenAPI document: v2
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictInt, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.connection_property import ConnectionProperty
from openapi_client.models.data_format_options import DataFormatOptions
from openapi_client.models.dataset_reference import DatasetReference
from openapi_client.models.query_parameter import QueryParameter
from typing import Optional, Set
from typing_extensions import Self

class QueryRequest(BaseModel):
    """
    Describes the format of the jobs.query request.
    """ # noqa: E501
    connection_properties: Optional[List[ConnectionProperty]] = Field(default=None, description="Optional. Connection properties which can modify the query behavior.", alias="connectionProperties")
    continuous: Optional[StrictBool] = Field(default=None, description="[Optional] Specifies whether the query should be executed as a continuous query. The default value is false.")
    create_session: Optional[StrictBool] = Field(default=None, description="Optional. If true, creates a new session using a randomly generated session_id. If false, runs query with an existing session_id passed in ConnectionProperty, otherwise runs query in non-session mode. The session location will be set to QueryRequest.location if it is present, otherwise it's set to the default location based on existing routing logic.", alias="createSession")
    default_dataset: Optional[DatasetReference] = Field(default=None, alias="defaultDataset")
    dry_run: Optional[StrictBool] = Field(default=None, description="Optional. If set to true, BigQuery doesn't run the job. Instead, if the query is valid, BigQuery returns statistics about the job such as how many bytes would be processed. If the query is invalid, an error returns. The default value is false.", alias="dryRun")
    format_options: Optional[DataFormatOptions] = Field(default=None, alias="formatOptions")
    job_creation_mode: Optional[StrictStr] = Field(default=None, description="Optional. If not set, jobs are always required. If set, the query request will follow the behavior described JobCreationMode. This feature is not yet available. Jobs will always be created.", alias="jobCreationMode")
    kind: Optional[StrictStr] = Field(default='bigquery#queryRequest', description="The resource type of the request.")
    labels: Optional[Dict[str, StrictStr]] = Field(default=None, description="Optional. The labels associated with this query. Labels can be used to organize and group query jobs. Label keys and values can be no longer than 63 characters, can only contain lowercase letters, numeric characters, underscores and dashes. International characters are allowed. Label keys must start with a letter and each label in the list must have a different key.")
    location: Optional[StrictStr] = Field(default=None, description="The geographic location where the job should run. See details at https://cloud.google.com/bigquery/docs/locations#specifying_your_location.")
    max_results: Optional[StrictInt] = Field(default=None, description="Optional. The maximum number of rows of data to return per page of results. Setting this flag to a small value such as 1000 and then paging through results might improve reliability when the query result set is large. In addition to this limit, responses are also limited to 10 MB. By default, there is no maximum row count, and only the byte limit applies.", alias="maxResults")
    maximum_bytes_billed: Optional[StrictStr] = Field(default=None, description="Optional. Limits the bytes billed for this query. Queries with bytes billed above this limit will fail (without incurring a charge). If unspecified, the project default is used.", alias="maximumBytesBilled")
    parameter_mode: Optional[StrictStr] = Field(default=None, description="GoogleSQL only. Set to POSITIONAL to use positional (?) query parameters or to NAMED to use named (@myparam) query parameters in this query.", alias="parameterMode")
    preserve_nulls: Optional[StrictBool] = Field(default=None, description="This property is deprecated.", alias="preserveNulls")
    query: Optional[StrictStr] = Field(default=None, description="Required. A query string to execute, using Google Standard SQL or legacy SQL syntax. Example: \"SELECT COUNT(f1) FROM myProjectId.myDatasetId.myTableId\".")
    query_parameters: Optional[List[QueryParameter]] = Field(default=None, description="Query parameters for GoogleSQL queries.", alias="queryParameters")
    request_id: Optional[StrictStr] = Field(default=None, description="Optional. A unique user provided identifier to ensure idempotent behavior for queries. Note that this is different from the job_id. It has the following properties: 1. It is case-sensitive, limited to up to 36 ASCII characters. A UUID is recommended. 2. Read only queries can ignore this token since they are nullipotent by definition. 3. For the purposes of idempotency ensured by the request_id, a request is considered duplicate of another only if they have the same request_id and are actually duplicates. When determining whether a request is a duplicate of another request, all parameters in the request that may affect the result are considered. For example, query, connection_properties, query_parameters, use_legacy_sql are parameters that affect the result and are considered when determining whether a request is a duplicate, but properties like timeout_ms don't affect the result and are thus not considered. Dry run query requests are never considered duplicate of another request. 4. When a duplicate mutating query request is detected, it returns: a. the results of the mutation if it completes successfully within the timeout. b. the running operation if it is still in progress at the end of the timeout. 5. Its lifetime is limited to 15 minutes. In other words, if two requests are sent with the same request_id, but more than 15 minutes apart, idempotency is not guaranteed.", alias="requestId")
    timeout_ms: Optional[StrictInt] = Field(default=None, description="Optional. Optional: Specifies the maximum amount of time, in milliseconds, that the client is willing to wait for the query to complete. By default, this limit is 10 seconds (10,000 milliseconds). If the query is complete, the jobComplete field in the response is true. If the query has not yet completed, jobComplete is false. You can request a longer timeout period in the timeoutMs field. However, the call is not guaranteed to wait for the specified timeout; it typically returns after around 200 seconds (200,000 milliseconds), even if the query is not complete. If jobComplete is false, you can continue to wait for the query to complete by calling the getQueryResults method until the jobComplete field in the getQueryResults response is true.", alias="timeoutMs")
    use_legacy_sql: Optional[StrictBool] = Field(default=True, description="Specifies whether to use BigQuery's legacy SQL dialect for this query. The default value is true. If set to false, the query will use BigQuery's GoogleSQL: https://cloud.google.com/bigquery/sql-reference/ When useLegacySql is set to false, the value of flattenResults is ignored; query will be run as if flattenResults is false.", alias="useLegacySql")
    use_query_cache: Optional[StrictBool] = Field(default=True, description="Optional. Whether to look for the result in the query cache. The query cache is a best-effort cache that will be flushed whenever tables in the query are modified. The default value is true.", alias="useQueryCache")
    __properties: ClassVar[List[str]] = ["connectionProperties", "continuous", "createSession", "defaultDataset", "dryRun", "formatOptions", "jobCreationMode", "kind", "labels", "location", "maxResults", "maximumBytesBilled", "parameterMode", "preserveNulls", "query", "queryParameters", "requestId", "timeoutMs", "useLegacySql", "useQueryCache"]

    @field_validator('job_creation_mode')
    def job_creation_mode_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['JOB_CREATION_MODE_UNSPECIFIED', 'JOB_CREATION_REQUIRED', 'JOB_CREATION_OPTIONAL']):
            raise ValueError("must be one of enum values ('JOB_CREATION_MODE_UNSPECIFIED', 'JOB_CREATION_REQUIRED', 'JOB_CREATION_OPTIONAL')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of QueryRequest from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in connection_properties (list)
        _items = []
        if self.connection_properties:
            for _item_connection_properties in self.connection_properties:
                if _item_connection_properties:
                    _items.append(_item_connection_properties.to_dict())
            _dict['connectionProperties'] = _items
        # override the default output from pydantic by calling `to_dict()` of default_dataset
        if self.default_dataset:
            _dict['defaultDataset'] = self.default_dataset.to_dict()
        # override the default output from pydantic by calling `to_dict()` of format_options
        if self.format_options:
            _dict['formatOptions'] = self.format_options.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in query_parameters (list)
        _items = []
        if self.query_parameters:
            for _item_query_parameters in self.query_parameters:
                if _item_query_parameters:
                    _items.append(_item_query_parameters.to_dict())
            _dict['queryParameters'] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of QueryRequest from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "connectionProperties": [ConnectionProperty.from_dict(_item) for _item in obj["connectionProperties"]] if obj.get("connectionProperties") is not None else None,
            "continuous": obj.get("continuous"),
            "createSession": obj.get("createSession"),
            "defaultDataset": DatasetReference.from_dict(obj["defaultDataset"]) if obj.get("defaultDataset") is not None else None,
            "dryRun": obj.get("dryRun"),
            "formatOptions": DataFormatOptions.from_dict(obj["formatOptions"]) if obj.get("formatOptions") is not None else None,
            "jobCreationMode": obj.get("jobCreationMode"),
            "kind": obj.get("kind") if obj.get("kind") is not None else 'bigquery#queryRequest',
            "labels": obj.get("labels"),
            "location": obj.get("location"),
            "maxResults": obj.get("maxResults"),
            "maximumBytesBilled": obj.get("maximumBytesBilled"),
            "parameterMode": obj.get("parameterMode"),
            "preserveNulls": obj.get("preserveNulls"),
            "query": obj.get("query"),
            "queryParameters": [QueryParameter.from_dict(_item) for _item in obj["queryParameters"]] if obj.get("queryParameters") is not None else None,
            "requestId": obj.get("requestId"),
            "timeoutMs": obj.get("timeoutMs"),
            "useLegacySql": obj.get("useLegacySql") if obj.get("useLegacySql") is not None else True,
            "useQueryCache": obj.get("useQueryCache") if obj.get("useQueryCache") is not None else True
        })
        return _obj


