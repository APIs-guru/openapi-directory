# coding: utf-8

"""
    BigQuery API

    A data platform for customers to create, manage, share and query data.

    The version of the OpenAPI document: v2
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from typing_extensions import Annotated
from typing import Optional, Set
from typing_extensions import Self

class CsvOptions(BaseModel):
    """
    Information related to a CSV data source.
    """ # noqa: E501
    allow_jagged_rows: Optional[StrictBool] = Field(default=None, description="Optional. Indicates if BigQuery should accept rows that are missing trailing optional columns. If true, BigQuery treats missing trailing columns as null values. If false, records with missing trailing columns are treated as bad records, and if there are too many bad records, an invalid error is returned in the job result. The default value is false.", alias="allowJaggedRows")
    allow_quoted_newlines: Optional[StrictBool] = Field(default=None, description="Optional. Indicates if BigQuery should allow quoted data sections that contain newline characters in a CSV file. The default value is false.", alias="allowQuotedNewlines")
    encoding: Optional[StrictStr] = Field(default=None, description="Optional. The character encoding of the data. The supported values are UTF-8, ISO-8859-1, UTF-16BE, UTF-16LE, UTF-32BE, and UTF-32LE. The default value is UTF-8. BigQuery decodes the data after the raw, binary data has been split using the values of the quote and fieldDelimiter properties.")
    field_delimiter: Optional[StrictStr] = Field(default=None, description="Optional. The separator character for fields in a CSV file. The separator is interpreted as a single byte. For files encoded in ISO-8859-1, any single character can be used as a separator. For files encoded in UTF-8, characters represented in decimal range 1-127 (U+0001-U+007F) can be used without any modification. UTF-8 characters encoded with multiple bytes (i.e. U+0080 and above) will have only the first byte used for separating fields. The remaining bytes will be treated as a part of the field. BigQuery also supports the escape sequence \"\\t\" (U+0009) to specify a tab separator. The default value is comma (\",\", U+002C).", alias="fieldDelimiter")
    null_marker: Optional[StrictStr] = Field(default=None, description="[Optional] A custom string that will represent a NULL value in CSV import data.", alias="nullMarker")
    preserve_ascii_control_characters: Optional[StrictBool] = Field(default=None, description="Optional. Indicates if the embedded ASCII control characters (the first 32 characters in the ASCII-table, from '\\x00' to '\\x1F') are preserved.", alias="preserveAsciiControlCharacters")
    quote: Optional[Annotated[str, Field(strict=True)]] = Field(default='"', description="Optional. The value that is used to quote data sections in a CSV file. BigQuery converts the string to ISO-8859-1 encoding, and then uses the first byte of the encoded string to split the data in its raw, binary state. The default value is a double-quote (\"). If your data does not contain quoted sections, set the property value to an empty string. If your data contains quoted newline characters, you must also set the allowQuotedNewlines property to true. To include the specific quote character within a quoted value, precede it with an additional matching quote character. For example, if you want to escape the default character ' \" ', use ' \"\" '.")
    skip_leading_rows: Optional[StrictStr] = Field(default=None, description="Optional. The number of rows at the top of a CSV file that BigQuery will skip when reading the data. The default value is 0. This property is useful if you have header rows in the file that should be skipped. When autodetect is on, the behavior is the following: * skipLeadingRows unspecified - Autodetect tries to detect headers in the first row. If they are not detected, the row is read as data. Otherwise data is read starting from the second row. * skipLeadingRows is 0 - Instructs autodetect that there are no headers and data should be read starting from the first row. * skipLeadingRows = N > 0 - Autodetect skips N-1 rows and tries to detect headers in row N. If headers are not detected, row N is just skipped. Otherwise row N is used to extract column names for the detected schema.", alias="skipLeadingRows")
    __properties: ClassVar[List[str]] = ["allowJaggedRows", "allowQuotedNewlines", "encoding", "fieldDelimiter", "nullMarker", "preserveAsciiControlCharacters", "quote", "skipLeadingRows"]

    @field_validator('quote')
    def quote_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if value is None:
            return value

        if not re.match(r".?", value):
            raise ValueError(r"must validate the regular expression /.?/")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of CsvOptions from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of CsvOptions from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "allowJaggedRows": obj.get("allowJaggedRows"),
            "allowQuotedNewlines": obj.get("allowQuotedNewlines"),
            "encoding": obj.get("encoding"),
            "fieldDelimiter": obj.get("fieldDelimiter"),
            "nullMarker": obj.get("nullMarker"),
            "preserveAsciiControlCharacters": obj.get("preserveAsciiControlCharacters"),
            "quote": obj.get("quote") if obj.get("quote") is not None else '"',
            "skipLeadingRows": obj.get("skipLeadingRows")
        })
        return _obj


