# coding: utf-8

"""
    Cloud Dataplex API

    Dataplex API is used to manage the lifecycle of data lakes.

    The version of the OpenAPI document: v1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.google_cloud_dataplex_v1_data_scan_event_data_profile_applied_configs import GoogleCloudDataplexV1DataScanEventDataProfileAppliedConfigs
from openapi_client.models.google_cloud_dataplex_v1_data_scan_event_data_profile_result import GoogleCloudDataplexV1DataScanEventDataProfileResult
from openapi_client.models.google_cloud_dataplex_v1_data_scan_event_data_quality_applied_configs import GoogleCloudDataplexV1DataScanEventDataQualityAppliedConfigs
from openapi_client.models.google_cloud_dataplex_v1_data_scan_event_data_quality_result import GoogleCloudDataplexV1DataScanEventDataQualityResult
from openapi_client.models.google_cloud_dataplex_v1_data_scan_event_post_scan_actions_result import GoogleCloudDataplexV1DataScanEventPostScanActionsResult
from typing import Optional, Set
from typing_extensions import Self

class GoogleCloudDataplexV1DataScanEvent(BaseModel):
    """
    These messages contain information about the execution of a datascan. The monitored resource is 'DataScan' Next ID: 13
    """ # noqa: E501
    create_time: Optional[StrictStr] = Field(default=None, description="The time when the data scan job was created.", alias="createTime")
    data_profile: Optional[GoogleCloudDataplexV1DataScanEventDataProfileResult] = Field(default=None, alias="dataProfile")
    data_profile_configs: Optional[GoogleCloudDataplexV1DataScanEventDataProfileAppliedConfigs] = Field(default=None, alias="dataProfileConfigs")
    data_quality: Optional[GoogleCloudDataplexV1DataScanEventDataQualityResult] = Field(default=None, alias="dataQuality")
    data_quality_configs: Optional[GoogleCloudDataplexV1DataScanEventDataQualityAppliedConfigs] = Field(default=None, alias="dataQualityConfigs")
    data_source: Optional[StrictStr] = Field(default=None, description="The data source of the data scan", alias="dataSource")
    end_time: Optional[StrictStr] = Field(default=None, description="The time when the data scan job finished.", alias="endTime")
    job_id: Optional[StrictStr] = Field(default=None, description="The identifier of the specific data scan job this log entry is for.", alias="jobId")
    message: Optional[StrictStr] = Field(default=None, description="The message describing the data scan job event.")
    post_scan_actions_result: Optional[GoogleCloudDataplexV1DataScanEventPostScanActionsResult] = Field(default=None, alias="postScanActionsResult")
    scope: Optional[StrictStr] = Field(default=None, description="The scope of the data scan (e.g. full, incremental).")
    spec_version: Optional[StrictStr] = Field(default=None, description="A version identifier of the spec which was used to execute this job.", alias="specVersion")
    start_time: Optional[StrictStr] = Field(default=None, description="The time when the data scan job started to run.", alias="startTime")
    state: Optional[StrictStr] = Field(default=None, description="The status of the data scan job.")
    trigger: Optional[StrictStr] = Field(default=None, description="The trigger type of the data scan job.")
    type: Optional[StrictStr] = Field(default=None, description="The type of the data scan.")
    __properties: ClassVar[List[str]] = ["createTime", "dataProfile", "dataProfileConfigs", "dataQuality", "dataQualityConfigs", "dataSource", "endTime", "jobId", "message", "postScanActionsResult", "scope", "specVersion", "startTime", "state", "trigger", "type"]

    @field_validator('scope')
    def scope_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['SCOPE_UNSPECIFIED', 'FULL', 'INCREMENTAL']):
            raise ValueError("must be one of enum values ('SCOPE_UNSPECIFIED', 'FULL', 'INCREMENTAL')")
        return value

    @field_validator('state')
    def state_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['STATE_UNSPECIFIED', 'STARTED', 'SUCCEEDED', 'FAILED', 'CANCELLED', 'CREATED']):
            raise ValueError("must be one of enum values ('STATE_UNSPECIFIED', 'STARTED', 'SUCCEEDED', 'FAILED', 'CANCELLED', 'CREATED')")
        return value

    @field_validator('trigger')
    def trigger_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['TRIGGER_UNSPECIFIED', 'ON_DEMAND', 'SCHEDULE']):
            raise ValueError("must be one of enum values ('TRIGGER_UNSPECIFIED', 'ON_DEMAND', 'SCHEDULE')")
        return value

    @field_validator('type')
    def type_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['SCAN_TYPE_UNSPECIFIED', 'DATA_PROFILE', 'DATA_QUALITY']):
            raise ValueError("must be one of enum values ('SCAN_TYPE_UNSPECIFIED', 'DATA_PROFILE', 'DATA_QUALITY')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of GoogleCloudDataplexV1DataScanEvent from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of data_profile
        if self.data_profile:
            _dict['dataProfile'] = self.data_profile.to_dict()
        # override the default output from pydantic by calling `to_dict()` of data_profile_configs
        if self.data_profile_configs:
            _dict['dataProfileConfigs'] = self.data_profile_configs.to_dict()
        # override the default output from pydantic by calling `to_dict()` of data_quality
        if self.data_quality:
            _dict['dataQuality'] = self.data_quality.to_dict()
        # override the default output from pydantic by calling `to_dict()` of data_quality_configs
        if self.data_quality_configs:
            _dict['dataQualityConfigs'] = self.data_quality_configs.to_dict()
        # override the default output from pydantic by calling `to_dict()` of post_scan_actions_result
        if self.post_scan_actions_result:
            _dict['postScanActionsResult'] = self.post_scan_actions_result.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of GoogleCloudDataplexV1DataScanEvent from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "createTime": obj.get("createTime"),
            "dataProfile": GoogleCloudDataplexV1DataScanEventDataProfileResult.from_dict(obj["dataProfile"]) if obj.get("dataProfile") is not None else None,
            "dataProfileConfigs": GoogleCloudDataplexV1DataScanEventDataProfileAppliedConfigs.from_dict(obj["dataProfileConfigs"]) if obj.get("dataProfileConfigs") is not None else None,
            "dataQuality": GoogleCloudDataplexV1DataScanEventDataQualityResult.from_dict(obj["dataQuality"]) if obj.get("dataQuality") is not None else None,
            "dataQualityConfigs": GoogleCloudDataplexV1DataScanEventDataQualityAppliedConfigs.from_dict(obj["dataQualityConfigs"]) if obj.get("dataQualityConfigs") is not None else None,
            "dataSource": obj.get("dataSource"),
            "endTime": obj.get("endTime"),
            "jobId": obj.get("jobId"),
            "message": obj.get("message"),
            "postScanActionsResult": GoogleCloudDataplexV1DataScanEventPostScanActionsResult.from_dict(obj["postScanActionsResult"]) if obj.get("postScanActionsResult") is not None else None,
            "scope": obj.get("scope"),
            "specVersion": obj.get("specVersion"),
            "startTime": obj.get("startTime"),
            "state": obj.get("state"),
            "trigger": obj.get("trigger"),
            "type": obj.get("type")
        })
        return _obj


