# coding: utf-8

"""
    Cloud Dataplex API

    Dataplex API is used to manage the lifecycle of data lakes.

    The version of the OpenAPI document: v1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.google_cloud_dataplex_v1_schema_partition_field import GoogleCloudDataplexV1SchemaPartitionField
from openapi_client.models.google_cloud_dataplex_v1_schema_schema_field import GoogleCloudDataplexV1SchemaSchemaField
from typing import Optional, Set
from typing_extensions import Self

class GoogleCloudDataplexV1Schema(BaseModel):
    """
    Schema information describing the structure and layout of the data.
    """ # noqa: E501
    fields: Optional[List[GoogleCloudDataplexV1SchemaSchemaField]] = Field(default=None, description="Optional. The sequence of fields describing data in table entities. Note: BigQuery SchemaFields are immutable.")
    partition_fields: Optional[List[GoogleCloudDataplexV1SchemaPartitionField]] = Field(default=None, description="Optional. The sequence of fields describing the partition structure in entities. If this field is empty, there are no partitions within the data.", alias="partitionFields")
    partition_style: Optional[StrictStr] = Field(default=None, description="Optional. The structure of paths containing partition data within the entity.", alias="partitionStyle")
    user_managed: Optional[StrictBool] = Field(default=None, description="Required. Set to true if user-managed or false if managed by Dataplex. The default is false (managed by Dataplex). Set to falseto enable Dataplex discovery to update the schema. including new data discovery, schema inference, and schema evolution. Users retain the ability to input and edit the schema. Dataplex treats schema input by the user as though produced by a previous Dataplex discovery operation, and it will evolve the schema and take action based on that treatment. Set to true to fully manage the entity schema. This setting guarantees that Dataplex will not change schema fields.", alias="userManaged")
    __properties: ClassVar[List[str]] = ["fields", "partitionFields", "partitionStyle", "userManaged"]

    @field_validator('partition_style')
    def partition_style_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in set(['PARTITION_STYLE_UNSPECIFIED', 'HIVE_COMPATIBLE']):
            raise ValueError("must be one of enum values ('PARTITION_STYLE_UNSPECIFIED', 'HIVE_COMPATIBLE')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of GoogleCloudDataplexV1Schema from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in fields (list)
        _items = []
        if self.fields:
            for _item_fields in self.fields:
                if _item_fields:
                    _items.append(_item_fields.to_dict())
            _dict['fields'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in partition_fields (list)
        _items = []
        if self.partition_fields:
            for _item_partition_fields in self.partition_fields:
                if _item_partition_fields:
                    _items.append(_item_partition_fields.to_dict())
            _dict['partitionFields'] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of GoogleCloudDataplexV1Schema from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "fields": [GoogleCloudDataplexV1SchemaSchemaField.from_dict(_item) for _item in obj["fields"]] if obj.get("fields") is not None else None,
            "partitionFields": [GoogleCloudDataplexV1SchemaPartitionField.from_dict(_item) for _item in obj["partitionFields"]] if obj.get("partitionFields") is not None else None,
            "partitionStyle": obj.get("partitionStyle"),
            "userManaged": obj.get("userManaged")
        })
        return _obj


