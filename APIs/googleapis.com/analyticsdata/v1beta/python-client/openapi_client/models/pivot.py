# coding: utf-8

"""
    Google Analytics Data API

    Accesses report data in Google Analytics. Warning: Creating multiple Customer Applications, Accounts, or Projects to simulate or act as a single Customer Application, Account, or Project (respectively) or to circumvent Service-specific usage limits or quotas is a direct violation of Google Cloud Platform Terms of Service as well as Google APIs Terms of Service. These actions can result in immediate termination of your GCP project(s) without any warning. 

    The version of the OpenAPI document: v1beta
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from openapi_client.models.order_by import OrderBy
from typing import Optional, Set
from typing_extensions import Self

class Pivot(BaseModel):
    """
    Describes the visible dimension columns and rows in the report response.
    """ # noqa: E501
    field_names: Optional[List[StrictStr]] = Field(default=None, description="Dimension names for visible columns in the report response. Including \"dateRange\" produces a date range column; for each row in the response, dimension values in the date range column will indicate the corresponding date range from the request.", alias="fieldNames")
    limit: Optional[StrictStr] = Field(default=None, description="The number of unique combinations of dimension values to return in this pivot. The `limit` parameter is required. A `limit` of 10,000 is common for single pivot requests. The product of the `limit` for each `pivot` in a `RunPivotReportRequest` must not exceed 250,000. For example, a two pivot request with `limit: 1000` in each pivot will fail because the product is `1,000,000`.")
    metric_aggregations: Optional[List[StrictStr]] = Field(default=None, description="Aggregate the metrics by dimensions in this pivot using the specified metric_aggregations.", alias="metricAggregations")
    offset: Optional[StrictStr] = Field(default=None, description="The row count of the start row. The first row is counted as row 0.")
    order_bys: Optional[List[OrderBy]] = Field(default=None, description="Specifies how dimensions are ordered in the pivot. In the first Pivot, the OrderBys determine Row and PivotDimensionHeader ordering; in subsequent Pivots, the OrderBys determine only PivotDimensionHeader ordering. Dimensions specified in these OrderBys must be a subset of Pivot.field_names.", alias="orderBys")
    __properties: ClassVar[List[str]] = ["fieldNames", "limit", "metricAggregations", "offset", "orderBys"]

    @field_validator('metric_aggregations')
    def metric_aggregations_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        for i in value:
            if i not in set(['METRIC_AGGREGATION_UNSPECIFIED', 'TOTAL', 'MINIMUM', 'MAXIMUM', 'COUNT']):
                raise ValueError("each list item must be one of ('METRIC_AGGREGATION_UNSPECIFIED', 'TOTAL', 'MINIMUM', 'MAXIMUM', 'COUNT')")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of Pivot from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in order_bys (list)
        _items = []
        if self.order_bys:
            for _item_order_bys in self.order_bys:
                if _item_order_bys:
                    _items.append(_item_order_bys.to_dict())
            _dict['orderBys'] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of Pivot from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "fieldNames": obj.get("fieldNames"),
            "limit": obj.get("limit"),
            "metricAggregations": obj.get("metricAggregations"),
            "offset": obj.get("offset"),
            "orderBys": [OrderBy.from_dict(_item) for _item in obj["orderBys"]] if obj.get("orderBys") is not None else None
        })
        return _obj


