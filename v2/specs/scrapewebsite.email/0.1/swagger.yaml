swagger: "2.0"
schemes:
  - http
host: scrapewebsite.email
basePath: /
info:
  description: ScrapeWebsiteEmail is a service that exposes an api to fetch e-mails from a website.
  title: Scrape Website Email API
  version: "0.1"
  x-apisguru-categories:
    - email
    - tools
  x-origin:
    - converter:
        url: https://github.com/lucybot/api-spec-converter
        version: 2.6.0
      format: swagger
      url: http://scrapewebsite.email/v1/swagger_doc.json
      version: "1.2"
  x-providerName: scrapewebsite.email
  x-logo:
    url: https://api.apis.guru/v2/cache/logo/https_apis.guru_assets_images_no-logo.svg
produces:
  - application/json
tags:
  - name: ping
  - name: scrape_emails
  - name: scrape_store_links
paths:
  /v1/ping.json:
    get:
      description: |
        <p>Returns ‘pong’ if the site is up</p>
      operationId: GET-v1-ping---format-
      responses:
        "200":
          description: No response was specified
      summary: Returns whether the system is up.
      tags:
        - ping
  /v1/scrape_emails.json:
    get:
      operationId: GET-v1-scrape_emails---format-
      parameters:
        - description: |
            <p>The website (ie. www.soundflair.com)</p>
          in: query
          name: website
          required: true
          type: string
        - description: |
            <table>
              <tbody>
                <tr>
                  <td>Optional. The word(s) that the webpage must include (otherwise it will skip scraping that page). Good if you want to scrape only contact pages. Takes regex (ie. about</td>
                  <td>contact).</td>
                </tr>
              </tbody>
            </table>
          in: query
          name: must_include
          required: false
          type: string
      responses:
        "200":
          description: No response was specified
      summary: Returns a list of emails scraped by priority (ie. e-mails appear on top level pages are first). Please note that subsequent calls to the same url will be fetched from the <b>cache</b> (14 day flush). <br/><br/>Will also parse patterns such as hello[at]site.com, hello[at]site[dot]com, hello(at)site.com, hello(at)site(dot)com, hello @ site.com, hello @ site . com. <br/><br/>Please do note we cannot parse sites that require a login (for now), so for some Facebook pages it is not possible at the moment to fetch the e-mail.<br/><br/>Finally, please note that the api will fetch links for up to 2 minutes. After that time it will start analysing the pages which have been scraped. <b>Therefore</b> please ensure that your client has a timeout of at least <b>150 seconds</b> (2 mins to fetch and the rest to parse). <br/><br/><b>Please note</b> that due to the fact that the api goes out to fetch the pages, the server allows only 1 concurrent request/ip. Requests which are made while the 1 request is still processing will result in a 429 code.<br/><br/><b>Please note</b> that as of May 25, 2014, the main mechanism of tracking usage will be done via Mashape. You can get the free calls by signing up with the FREE plan.<br/><br/>Please visit <a href='https://www.mashape.com/tommytcchan/scrape-website-email'>https://www.mashape.com/tommytcchan/scrape-website-email</a>.<br/><br/><b>There is now a limit of 5 requests per day using this sample interface.</b><br/><br/>
      tags:
        - scrape_emails
  /v1/scrape_store_links.json:
    get:
      operationId: GET-v1-scrape_store_links---format-
      parameters:
        - description: |
            <p>The website (ie. www.soundflair.com)</p>
          in: query
          name: website
          required: true
          type: string
      responses:
        "200":
          description: No response was specified
      summary: Attempts to grab the google store url or the ios store url for a site, after searching through the site.
      tags:
        - scrape_store_links
